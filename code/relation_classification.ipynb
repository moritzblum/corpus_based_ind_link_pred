{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "#from datasets import IterableDataset\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import transformers\n",
    "#from datasets import Dataset\n",
    "transformers.logging.set_verbosity_error()\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('../data/wikidata5m_inductive/uri_to_id.json') as uri_to_id_in:\n",
    "    uri_to_id = json.load(uri_to_id_in)\n",
    "        \n",
    "with open('../data/wikidata5m_inductive/relation_uri_to_id.json') as uri_to_id_in:\n",
    "    relation_uri_to_id = json.load(uri_to_id_in)\n",
    "\n",
    "edge_index = []\n",
    "edge_type = []\n",
    "with open('../data/wikidata5m_inductive/wikidata5m_inductive_train.txt') as triples_in:\n",
    "    for line in triples_in:\n",
    "        head, relation, tail = line[:-1].split('\\t')\n",
    "        edge_index.append([uri_to_id[head], uri_to_id[tail]])\n",
    "        edge_type.append(relation_uri_to_id[relation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "with open('../data/wikidata5m_inductive/entity_description_first_sentence.txt') as sentences_in:\n",
    "    for line in sentences_in:\n",
    "        sentences.append(line[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = []\n",
    "for i in tqdm(range(len(edge_index))):\n",
    "    samples.append((sentences[edge_index[i][0]], sentences[edge_index[i][1]], edge_type[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "dataset = []\n",
    "for idx, (first_sentence, second_sentence, label) in enumerate(tqdm(samples)):\n",
    "    encoding = tokenizer(first_sentence, second_sentence, padding=\"max_length\", truncation=True)\n",
    "    encoding['idx'] = idx\n",
    "    encoding['labels'] = label\n",
    "    #encoding['sentence1'] = first_sentence\n",
    "    #encoding['sentence2'] = second_sentence\n",
    "    dataset.append(encoding)\n",
    "    if idx == 10000:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "d = Dataset.from_list(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "d.set_format(type=\"torch\", columns=[\"input_ids\", \"token_type_ids\", \"attention_mask\", \"labels\"])\n",
    "dataloader = torch.utils.data.DataLoader(d, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {0: \"relation\", 1: \"inverse_relation\"}\n",
    "label2id = {\"relation\": 0, \"inverse_relation\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=len(relation_uri_to_id.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_scheduler\n",
    "\n",
    "num_epochs = 10\n",
    "num_training_steps = num_epochs * len(dataloader)\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "model.train()\n",
    "\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    loss_total = 0\n",
    "    for batch in dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        loss_total += loss.detach().cpu()\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)\n",
    "    print('loss_total:', loss_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '../data/wikidata5m_inductive/relation_classification_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "model.eval()\n",
    "for batch in dataloader:\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "    metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "\n",
    "metric.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use model to make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=len(relation_uri_to_id.keys()))\n",
    "model.load_state_dict(torch.load('../data/wikidata5m_inductive/relation_classification_model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_links = torch.load('../data/wikidata5m_inductive/page_links.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = []\n",
    "for i in tqdm(range(page_links.size(0))):\n",
    "    head, tail = page_links[i]\n",
    "    samples.append((sentences[head], sentences[tail]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first try with manually constructed sentences\n",
    "germany = \"Germany, officially the Federal Republic of Germany, is a country in Central Europe.\"\n",
    "berlin = \"Berlin is the capital and largest city of Germany by both area and population.\"\n",
    "samples = []\n",
    "samples.append((berlin, germany))\n",
    "samples.append((germany, berlin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100109235 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 15\u001B[0m\n\u001B[1;32m     13\u001B[0m dataset\u001B[38;5;241m.\u001B[39mappend(encoding)\n\u001B[1;32m     14\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m idx \u001B[38;5;241m%\u001B[39m \u001B[38;5;241m1000\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m---> 15\u001B[0m     d \u001B[38;5;241m=\u001B[39m \u001B[43mDataset\u001B[49m\u001B[38;5;241m.\u001B[39mfrom_list(dataset)\n\u001B[1;32m     16\u001B[0m     d\u001B[38;5;241m.\u001B[39mset_format(\u001B[38;5;28mtype\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtorch\u001B[39m\u001B[38;5;124m\"\u001B[39m, columns\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minput_ids\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtoken_type_ids\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mattention_mask\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[1;32m     17\u001B[0m     dataloader \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mDataLoader(d, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m64\u001B[39m, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'Dataset' is not defined"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "model.to('cuda')\n",
    "model.eval()\n",
    "\n",
    "dataset = []\n",
    "batch_edge_index = []\n",
    "for idx in tqdm(range(page_links.size(0))):\n",
    "    head, tail = page_links[idx]\n",
    "    batch_edge_index.append([idx, head, tail])\n",
    "    encoding = tokenizer(sentences[head], sentences[tail], padding=\"max_length\", truncation=True)\n",
    "    encoding['idx'] = idx\n",
    "    dataset.append(encoding)\n",
    "    if idx % 1000 == 0:\n",
    "        d = Dataset.from_list(dataset)\n",
    "        d.set_format(type=\"torch\", columns=[\"input_ids\", \"token_type_ids\", \"attention_mask\"])\n",
    "        dataloader = torch.utils.data.DataLoader(d, batch_size=64, shuffle=False)\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(dataloader):\n",
    "                batch = {k: v.to('cuda') for k, v in batch.items()}\n",
    "                with torch.no_grad():\n",
    "                    outputs = model(**batch)\n",
    "                    predictions = torch.argmax(outputs.logits, dim=1)\n",
    "                    \n",
    "        with open('page_ling_graph.txt', 'a+') as triples_out:\n",
    "            for (idx, head, tail), relation in zip(batch_edge_index, predictions.tolist()):\n",
    "                triples_out.write('\\t'.join([str(idx), str(head), str(relation), str(tail)]) + '\\n')\n",
    "            \n",
    "        dataset = []\n",
    "        batch_edge_index = []\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(dataset, 'test.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Dataset.from_list(dataset)\n",
    "\n",
    "d.set_format(type=\"torch\", columns=[\"input_ids\", \"token_type_ids\", \"attention_mask\"])\n",
    "dataloader = torch.utils.data.DataLoader(d, batch_size=64, shuffle=False)\n",
    "\n",
    "model.to('cuda')\n",
    "model.eval()\n",
    "\n",
    "\n",
    "#for batch in dataloader:\n",
    "#    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(dataloader):\n",
    "        batch = {k: v.to('cuda') for k, v in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "            predictions = torch.argmax(outputs.logits, dim=1)\n",
    "\n",
    "\n",
    "#    logits = outputs.logits\n",
    "#    predictions = torch.argmax(logits, dim=-1)\n",
    "#    metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.argmax(outputs.logits, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relation_uri_to_id()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_relation_uri = {v:k for k,v in relation_uri_to_id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_relation_uri[42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "degree = {'a': 10, 'b': 5, 'c': 2}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "x = ['c', 'a', 'b']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "['a', 'b', 'c']"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(x, key=lambda e: - degree[e])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [],
   "source": [
    "import torch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "outputs": [],
   "source": [
    "e1_emb = torch.tensor([1.,2,3,4])\n",
    "rel_emb = torch.tensor([5.,6,7,8])\n",
    "e2_emb = torch.tensor([1.,2,3,4])\n",
    "\n",
    "# requirement: height * width = embedding dim\n",
    "height = 2\n",
    "width = 2\n",
    "e1_emb = e1_emb.view(-1, 1, height, width)\n",
    "\n",
    "rel_emb = rel_emb.view(-1, 1, height, width)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "outputs": [],
   "source": [
    "stacked_inputs = torch.cat([e1_emb, rel_emb], 2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[[1., 2.],\n          [3., 4.],\n          [5., 6.],\n          [7., 8.]]]])"
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_inputs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [],
   "source": [
    "conv1 = torch.nn.Conv2d(1, 32, (2, 2), 1, 0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [],
   "source": [
    "x_conv = conv1(stacked_inputs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 32, 3, 1])"
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_conv.size()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [],
   "source": [
    "x_conv = torch.relu(x_conv)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[[0.0000],\n          [0.0000],\n          [0.0000]],\n\n         [[1.3309],\n          [2.1268],\n          [2.9226]],\n\n         [[0.0000],\n          [0.0000],\n          [0.0000]],\n\n         [[1.0137],\n          [0.8094],\n          [0.6051]],\n\n         [[0.0000],\n          [0.0000],\n          [0.0000]],\n\n         [[0.0000],\n          [0.0000],\n          [0.0000]],\n\n         [[0.4274],\n          [0.6910],\n          [0.9546]],\n\n         [[2.7062],\n          [4.0017],\n          [5.2972]],\n\n         [[0.0000],\n          [0.0000],\n          [0.0000]],\n\n         [[0.0000],\n          [0.0000],\n          [0.0000]],\n\n         [[1.6623],\n          [2.5654],\n          [3.4685]],\n\n         [[1.7829],\n          [3.6603],\n          [5.5377]],\n\n         [[1.5170],\n          [2.8361],\n          [4.1551]],\n\n         [[1.6728],\n          [2.4682],\n          [3.2635]],\n\n         [[0.0000],\n          [0.0000],\n          [0.0000]],\n\n         [[0.1390],\n          [0.0000],\n          [0.0000]],\n\n         [[0.0000],\n          [0.0000],\n          [0.0000]],\n\n         [[0.5730],\n          [1.1076],\n          [1.6422]],\n\n         [[0.1083],\n          [0.0000],\n          [0.0000]],\n\n         [[2.3303],\n          [3.3004],\n          [4.2706]],\n\n         [[0.0000],\n          [0.0000],\n          [0.0000]],\n\n         [[2.9495],\n          [4.9435],\n          [6.9375]],\n\n         [[0.2255],\n          [0.3829],\n          [0.5404]],\n\n         [[2.6872],\n          [5.3898],\n          [8.0924]],\n\n         [[1.9762],\n          [3.3619],\n          [4.7476]],\n\n         [[0.0000],\n          [0.0000],\n          [0.0000]],\n\n         [[0.6932],\n          [0.4701],\n          [0.2470]],\n\n         [[0.0000],\n          [0.0000],\n          [0.0000]],\n\n         [[0.0000],\n          [0.3119],\n          [0.9274]],\n\n         [[0.0000],\n          [0.0000],\n          [0.0000]],\n\n         [[2.6432],\n          [4.3492],\n          [6.0552]],\n\n         [[1.5376],\n          [3.4815],\n          [5.4254]]]], grad_fn=<ReluBackward0>)"
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_conv"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [],
   "source": [
    "x_flatten = x_conv.flatten()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([96])"
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_flatten.size()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "outputs": [],
   "source": [
    "embedding_dim = 4\n",
    "# 96 = x.size(0)\n",
    "fc = torch.nn.Linear(96, embedding_dim)\n",
    "x_fc = fc(x_flatten)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([4])"
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_fc.size()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([4])"
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e2_emb.size()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(10.2821, grad_fn=<DotBackward0>)"
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.dot(x.flatten(), e2_emb.t())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Types page link graph to tensor of triples"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import torch\n",
    "triples = []\n",
    "with open('../data/wikidata5m_inductive/page_links_typed.txt') as triples_in:\n",
    "    for line in triples_in:\n",
    "        head, relation, tail = line[:-1].split('\\t')\n",
    "        triples.append([int(head), int(relation), int(tail)])\n",
    "triples = torch.tensor(triples)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([100109001, 3])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triples.size()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "torch.save(triples, '../data/wikidata5m_inductive/page_links_typed.pt')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
