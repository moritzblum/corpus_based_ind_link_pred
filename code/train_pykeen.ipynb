{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homes/mblum/miniconda3/envs/lp/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pykeen.triples import TriplesFactory\n",
    "from pykeen.pipeline import pipeline\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pykeen.pipeline.api:No random seed is specified. Setting to 1349941219.\n",
      "WARNING:pykeen.triples.triples_factory:You're trying to map triples with 743 entities and 0 relations that are not in the training set. These triples will be excluded from the mapping.\n",
      "WARNING:pykeen.triples.triples_factory:In total 703 from 2902 triples were filtered out\n",
      "INFO:pykeen.pipeline.api:Using device: gpu\n",
      "Training epochs on cuda:0:   0%|          | 0/50 [00:00<?, ?epoch/s]\n",
      "Training batches on cuda:0:   0%|          | 0/801 [00:00<?, ?batch/s]\u001B[A\n",
      "Training batches on cuda:0:   2%|▏         | 17/801 [00:00<00:04, 164.37batch/s]\u001B[A\n",
      "Training batches on cuda:0:   4%|▍         | 36/801 [00:00<00:04, 177.11batch/s]\u001B[A\n",
      "Training batches on cuda:0:   7%|▋         | 55/801 [00:00<00:04, 180.31batch/s]\u001B[A\n",
      "Training batches on cuda:0:   9%|▉         | 74/801 [00:00<00:03, 182.63batch/s]\u001B[A\n",
      "Training batches on cuda:0:  12%|█▏        | 93/801 [00:00<00:03, 183.23batch/s]\u001B[A\n",
      "Training batches on cuda:0:  14%|█▍        | 112/801 [00:00<00:03, 184.23batch/s]\u001B[A\n",
      "Training batches on cuda:0:  16%|█▋        | 131/801 [00:00<00:03, 184.82batch/s]\u001B[A\n",
      "Training batches on cuda:0:  19%|█▊        | 150/801 [00:00<00:03, 185.23batch/s]\u001B[A\n",
      "Training batches on cuda:0:  21%|██        | 169/801 [00:00<00:03, 185.49batch/s]\u001B[A\n",
      "Training batches on cuda:0:  24%|██▎       | 190/801 [00:01<00:03, 190.54batch/s]\u001B[A\n",
      "Training batches on cuda:0:  26%|██▋       | 211/801 [00:01<00:03, 194.96batch/s]\u001B[A\n",
      "Training batches on cuda:0:  29%|██▉       | 232/801 [00:01<00:02, 197.95batch/s]\u001B[A\n",
      "Training batches on cuda:0:  32%|███▏      | 253/801 [00:01<00:02, 199.92batch/s]\u001B[A\n",
      "Training batches on cuda:0:  34%|███▍      | 274/801 [00:01<00:02, 201.38batch/s]\u001B[A\n",
      "Training batches on cuda:0:  37%|███▋      | 295/801 [00:01<00:02, 202.38batch/s]\u001B[A\n",
      "Training batches on cuda:0:  39%|███▉      | 316/801 [00:01<00:02, 201.20batch/s]\u001B[A\n",
      "Training batches on cuda:0:  42%|████▏     | 337/801 [00:01<00:02, 202.17batch/s]\u001B[A\n",
      "Training batches on cuda:0:  45%|████▍     | 358/801 [00:01<00:02, 202.97batch/s]\u001B[A\n",
      "Training batches on cuda:0:  47%|████▋     | 379/801 [00:01<00:02, 203.45batch/s]\u001B[A\n",
      "Training batches on cuda:0:  50%|████▉     | 400/801 [00:02<00:01, 203.59batch/s]\u001B[A\n",
      "Training batches on cuda:0:  53%|█████▎    | 421/801 [00:02<00:01, 203.54batch/s]\u001B[A\n",
      "Training batches on cuda:0:  55%|█████▌    | 442/801 [00:02<00:01, 203.90batch/s]\u001B[A\n",
      "Training batches on cuda:0:  58%|█████▊    | 463/801 [00:02<00:01, 204.09batch/s]\u001B[A\n",
      "Training batches on cuda:0:  60%|██████    | 484/801 [00:02<00:01, 204.29batch/s]\u001B[A\n",
      "Training batches on cuda:0:  63%|██████▎   | 505/801 [00:02<00:01, 204.47batch/s]\u001B[A\n",
      "Training batches on cuda:0:  66%|██████▌   | 526/801 [00:02<00:01, 204.52batch/s]\u001B[A\n",
      "Training batches on cuda:0:  68%|██████▊   | 547/801 [00:02<00:01, 204.58batch/s]\u001B[A\n",
      "Training batches on cuda:0:  71%|███████   | 568/801 [00:02<00:01, 204.61batch/s]\u001B[A\n",
      "Training batches on cuda:0:  74%|███████▎  | 589/801 [00:02<00:01, 204.70batch/s]\u001B[A\n",
      "Training batches on cuda:0:  76%|███████▌  | 610/801 [00:03<00:00, 204.62batch/s]\u001B[A\n",
      "Training batches on cuda:0:  79%|███████▉  | 631/801 [00:03<00:00, 204.69batch/s]\u001B[A\n",
      "Training batches on cuda:0:  81%|████████▏ | 652/801 [00:03<00:00, 204.63batch/s]\u001B[A\n",
      "Training batches on cuda:0:  84%|████████▍ | 673/801 [00:03<00:00, 204.68batch/s]\u001B[A\n",
      "Training batches on cuda:0:  87%|████████▋ | 694/801 [00:03<00:00, 204.55batch/s]\u001B[A\n",
      "Training batches on cuda:0:  89%|████████▉ | 715/801 [00:03<00:00, 204.56batch/s]\u001B[A\n",
      "Training batches on cuda:0:  92%|█████████▏| 736/801 [00:03<00:00, 204.53batch/s]\u001B[A\n",
      "Training batches on cuda:0:  95%|█████████▍| 757/801 [00:03<00:00, 204.54batch/s]\u001B[A\n",
      "Training batches on cuda:0:  97%|█████████▋| 778/801 [00:03<00:00, 204.51batch/s]\u001B[A\n",
      "Training batches on cuda:0: 100%|█████████▉| 799/801 [00:04<00:00, 204.48batch/s]\u001B[A\n",
      "Training epochs on cuda:0:   2%|▏         | 1/50 [00:04<03:25,  4.20s/epoch, loss=1, prev_loss=nan]\n",
      "Training batches on cuda:0:   0%|          | 0/801 [00:00<?, ?batch/s]\u001B[A\n",
      "Training batches on cuda:0:   2%|▏         | 19/801 [00:00<00:04, 185.26batch/s]\u001B[A\n",
      "Training batches on cuda:0:   5%|▍         | 40/801 [00:00<00:03, 196.54batch/s]\u001B[A\n",
      "Training batches on cuda:0:   8%|▊         | 61/801 [00:00<00:03, 200.28batch/s]\u001B[A\n",
      "Training batches on cuda:0:  10%|█         | 82/801 [00:00<00:03, 201.26batch/s]\u001B[A\n",
      "Training batches on cuda:0:  13%|█▎        | 103/801 [00:00<00:03, 202.51batch/s]\u001B[A\n",
      "Training batches on cuda:0:  15%|█▌        | 124/801 [00:00<00:03, 203.23batch/s]\u001B[A\n",
      "Training batches on cuda:0:  18%|█▊        | 145/801 [00:00<00:03, 203.78batch/s]\u001B[A\n",
      "Training batches on cuda:0:  21%|██        | 166/801 [00:00<00:03, 204.10batch/s]\u001B[A\n",
      "Training batches on cuda:0:  23%|██▎       | 187/801 [00:00<00:03, 204.24batch/s]\u001B[A\n",
      "Training batches on cuda:0:  26%|██▌       | 208/801 [00:01<00:02, 202.76batch/s]\u001B[A\n",
      "Training batches on cuda:0:  29%|██▊       | 229/801 [00:01<00:02, 203.30batch/s]\u001B[A\n",
      "Training batches on cuda:0:  31%|███       | 250/801 [00:01<00:02, 203.83batch/s]\u001B[A\n",
      "Training batches on cuda:0:  34%|███▍      | 271/801 [00:01<00:02, 204.04batch/s]\u001B[A\n",
      "Training batches on cuda:0:  36%|███▋      | 292/801 [00:01<00:02, 204.30batch/s]\u001B[A\n",
      "Training batches on cuda:0:  39%|███▉      | 313/801 [00:01<00:02, 204.42batch/s]\u001B[A\n",
      "Training batches on cuda:0:  42%|████▏     | 334/801 [00:01<00:02, 204.43batch/s]\u001B[A\n",
      "Training batches on cuda:0:  44%|████▍     | 355/801 [00:01<00:02, 204.41batch/s]\u001B[A\n",
      "Training batches on cuda:0:  47%|████▋     | 376/801 [00:01<00:02, 204.41batch/s]\u001B[A\n",
      "Training batches on cuda:0:  50%|████▉     | 397/801 [00:01<00:01, 204.47batch/s]\u001B[A\n",
      "Training batches on cuda:0:  52%|█████▏    | 418/801 [00:02<00:01, 204.53batch/s]\u001B[A\n",
      "Training batches on cuda:0:  55%|█████▍    | 439/801 [00:02<00:01, 204.60batch/s]\u001B[A\n",
      "Training batches on cuda:0:  57%|█████▋    | 460/801 [00:02<00:01, 204.58batch/s]\u001B[A\n",
      "Training batches on cuda:0:  60%|██████    | 481/801 [00:02<00:01, 204.58batch/s]\u001B[A\n",
      "Training batches on cuda:0:  63%|██████▎   | 502/801 [00:02<00:01, 204.67batch/s]\u001B[A\n",
      "Training batches on cuda:0:  65%|██████▌   | 523/801 [00:02<00:01, 204.74batch/s]\u001B[A\n",
      "Training batches on cuda:0:  68%|██████▊   | 544/801 [00:02<00:01, 204.60batch/s]\u001B[A\n",
      "Training batches on cuda:0:  71%|███████   | 565/801 [00:02<00:01, 203.04batch/s]\u001B[A\n",
      "Training batches on cuda:0:  73%|███████▎  | 586/801 [00:02<00:01, 203.36batch/s]\u001B[A\n",
      "Training batches on cuda:0:  76%|███████▌  | 607/801 [00:02<00:00, 203.74batch/s]\u001B[A\n",
      "Training batches on cuda:0:  78%|███████▊  | 628/801 [00:03<00:00, 203.96batch/s]\u001B[A\n",
      "Training batches on cuda:0:  81%|████████  | 649/801 [00:03<00:00, 204.16batch/s]\u001B[A\n",
      "Training batches on cuda:0:  84%|████████▎ | 670/801 [00:03<00:00, 203.76batch/s]\u001B[A\n",
      "Training batches on cuda:0:  86%|████████▋ | 691/801 [00:03<00:00, 203.92batch/s]\u001B[A\n",
      "Training batches on cuda:0:  89%|████████▉ | 712/801 [00:03<00:00, 204.01batch/s]\u001B[A\n",
      "Training batches on cuda:0:  92%|█████████▏| 733/801 [00:03<00:00, 203.95batch/s]\u001B[A\n",
      "Training batches on cuda:0:  94%|█████████▍| 754/801 [00:03<00:00, 204.12batch/s]\u001B[A\n",
      "Training batches on cuda:0:  97%|█████████▋| 775/801 [00:03<00:00, 204.24batch/s]\u001B[A\n",
      "Training batches on cuda:0:  99%|█████████▉| 796/801 [00:03<00:00, 204.29batch/s]\u001B[A\n",
      "Training epochs on cuda:0:   4%|▍         | 2/50 [00:08<03:18,  4.14s/epoch, loss=1, prev_loss=1]  \n",
      "Training batches on cuda:0:   0%|          | 0/801 [00:00<?, ?batch/s]\u001B[A\n",
      "Training batches on cuda:0:   2%|▏         | 19/801 [00:00<00:04, 187.08batch/s]\u001B[A\n",
      "Training batches on cuda:0:   5%|▍         | 40/801 [00:00<00:03, 197.12batch/s]\u001B[A\n",
      "Training batches on cuda:0:   8%|▊         | 61/801 [00:00<00:03, 200.43batch/s]\u001B[A\n",
      "Training batches on cuda:0:  10%|█         | 82/801 [00:00<00:03, 200.86batch/s]\u001B[A\n",
      "Training batches on cuda:0:  13%|█▎        | 103/801 [00:00<00:03, 201.90batch/s]\u001B[A\n",
      "Training batches on cuda:0:  15%|█▌        | 124/801 [00:00<00:03, 202.27batch/s]\u001B[A\n",
      "Training batches on cuda:0:  18%|█▊        | 145/801 [00:00<00:03, 202.99batch/s]\u001B[A\n",
      "Training batches on cuda:0:  21%|██        | 166/801 [00:00<00:03, 203.30batch/s]\u001B[A\n",
      "Training batches on cuda:0:  23%|██▎       | 187/801 [00:00<00:03, 203.69batch/s]\u001B[A\n",
      "Training batches on cuda:0:  26%|██▌       | 208/801 [00:01<00:02, 203.94batch/s]\u001B[A\n",
      "Training batches on cuda:0:  29%|██▊       | 229/801 [00:01<00:02, 203.61batch/s]\u001B[A\n",
      "Training batches on cuda:0:  31%|███       | 250/801 [00:01<00:02, 203.41batch/s]\u001B[A\n",
      "Training batches on cuda:0:  34%|███▍      | 271/801 [00:01<00:02, 203.39batch/s]\u001B[A\n",
      "Training batches on cuda:0:  36%|███▋      | 292/801 [00:01<00:02, 203.68batch/s]\u001B[A\n",
      "Training batches on cuda:0:  39%|███▉      | 313/801 [00:01<00:02, 203.84batch/s]\u001B[A\n",
      "Training batches on cuda:0:  42%|████▏     | 334/801 [00:01<00:02, 203.62batch/s]\u001B[A\n",
      "Training batches on cuda:0:  44%|████▍     | 355/801 [00:01<00:02, 203.54batch/s]\u001B[A\n",
      "Training batches on cuda:0:  47%|████▋     | 376/801 [00:01<00:02, 203.26batch/s]\u001B[A\n",
      "Training batches on cuda:0:  50%|████▉     | 397/801 [00:01<00:01, 203.21batch/s]\u001B[A\n",
      "Training batches on cuda:0:  52%|█████▏    | 418/801 [00:02<00:01, 203.05batch/s]\u001B[A\n",
      "Training batches on cuda:0:  55%|█████▍    | 439/801 [00:02<00:01, 203.21batch/s]\u001B[A\n",
      "Training batches on cuda:0:  57%|█████▋    | 460/801 [00:02<00:01, 202.22batch/s]\u001B[A\n",
      "Training batches on cuda:0:  60%|██████    | 481/801 [00:02<00:01, 202.60batch/s]\u001B[A\n",
      "Training batches on cuda:0:  63%|██████▎   | 502/801 [00:02<00:01, 202.81batch/s]\u001B[A\n",
      "Training batches on cuda:0:  65%|██████▌   | 523/801 [00:02<00:01, 202.99batch/s]\u001B[A\n",
      "Training batches on cuda:0:  68%|██████▊   | 544/801 [00:02<00:01, 203.02batch/s]\u001B[A\n",
      "Training batches on cuda:0:  71%|███████   | 565/801 [00:02<00:01, 203.00batch/s]\u001B[A\n",
      "Training batches on cuda:0:  73%|███████▎  | 586/801 [00:02<00:01, 203.20batch/s]\u001B[A\n",
      "Training batches on cuda:0:  76%|███████▌  | 607/801 [00:02<00:00, 203.25batch/s]\u001B[A\n",
      "Training batches on cuda:0:  78%|███████▊  | 628/801 [00:03<00:00, 203.70batch/s]\u001B[A\n",
      "Training batches on cuda:0:  81%|████████  | 649/801 [00:03<00:00, 203.41batch/s]\u001B[A\n",
      "Training batches on cuda:0:  84%|████████▎ | 670/801 [00:03<00:00, 203.38batch/s]\u001B[A\n",
      "Training batches on cuda:0:  86%|████████▋ | 691/801 [00:03<00:00, 203.52batch/s]\u001B[A\n",
      "Training batches on cuda:0:  89%|████████▉ | 712/801 [00:03<00:00, 203.26batch/s]\u001B[A\n",
      "Training batches on cuda:0:  92%|█████████▏| 733/801 [00:03<00:00, 203.18batch/s]\u001B[A\n",
      "Training batches on cuda:0:  94%|█████████▍| 754/801 [00:03<00:00, 203.13batch/s]\u001B[A\n",
      "Training batches on cuda:0:  97%|█████████▋| 775/801 [00:03<00:00, 203.44batch/s]\u001B[A\n",
      "Training batches on cuda:0:  99%|█████████▉| 796/801 [00:03<00:00, 203.75batch/s]\u001B[A\n",
      "Training epochs on cuda:0:   6%|▌         | 3/50 [00:12<03:13,  4.12s/epoch, loss=0.998, prev_loss=1]\n",
      "Training batches on cuda:0:   0%|          | 0/801 [00:00<?, ?batch/s]\u001B[A\n",
      "Training batches on cuda:0:   2%|▏         | 19/801 [00:00<00:04, 186.84batch/s]\u001B[A\n",
      "Training batches on cuda:0:   5%|▍         | 39/801 [00:00<00:03, 193.47batch/s]\u001B[A\n",
      "Training batches on cuda:0:   7%|▋         | 60/801 [00:00<00:03, 198.10batch/s]\u001B[A\n",
      "Training batches on cuda:0:  10%|█         | 81/801 [00:00<00:03, 199.66batch/s]\u001B[A\n",
      "Training batches on cuda:0:  13%|█▎        | 102/801 [00:00<00:03, 200.67batch/s]\u001B[A\n",
      "Training batches on cuda:0:  15%|█▌        | 123/801 [00:00<00:03, 201.56batch/s]\u001B[A\n",
      "Training batches on cuda:0:  18%|█▊        | 144/801 [00:00<00:03, 202.15batch/s]\u001B[A\n",
      "Training batches on cuda:0:  21%|██        | 165/801 [00:00<00:03, 202.60batch/s]\u001B[A\n",
      "Training batches on cuda:0:  23%|██▎       | 186/801 [00:00<00:03, 203.30batch/s]\u001B[A\n",
      "Training batches on cuda:0:  26%|██▌       | 207/801 [00:01<00:02, 203.34batch/s]\u001B[A\n",
      "Training batches on cuda:0:  28%|██▊       | 228/801 [00:01<00:02, 203.22batch/s]\u001B[A\n",
      "Training batches on cuda:0:  31%|███       | 249/801 [00:01<00:02, 203.62batch/s]\u001B[A\n",
      "Training batches on cuda:0:  34%|███▎      | 270/801 [00:01<00:02, 203.69batch/s]\u001B[A\n",
      "Training batches on cuda:0:  36%|███▋      | 291/801 [00:01<00:02, 203.50batch/s]\u001B[A\n",
      "Training batches on cuda:0:  39%|███▉      | 312/801 [00:01<00:02, 203.32batch/s]\u001B[A\n",
      "Training batches on cuda:0:  42%|████▏     | 333/801 [00:01<00:02, 203.70batch/s]\u001B[A\n",
      "Training batches on cuda:0:  44%|████▍     | 354/801 [00:01<00:02, 204.03batch/s]\u001B[A\n",
      "Training batches on cuda:0:  47%|████▋     | 375/801 [00:01<00:02, 203.96batch/s]\u001B[A\n",
      "Training batches on cuda:0:  49%|████▉     | 396/801 [00:01<00:01, 203.73batch/s]\u001B[A\n",
      "Training batches on cuda:0:  52%|█████▏    | 417/801 [00:02<00:01, 203.60batch/s]\u001B[A\n",
      "Training batches on cuda:0:  55%|█████▍    | 438/801 [00:02<00:01, 203.55batch/s]\u001B[A\n",
      "Training batches on cuda:0:  57%|█████▋    | 459/801 [00:02<00:01, 203.46batch/s]\u001B[A\n",
      "Training batches on cuda:0:  60%|█████▉    | 480/801 [00:02<00:01, 203.56batch/s]\u001B[A\n",
      "Training batches on cuda:0:  63%|██████▎   | 501/801 [00:02<00:01, 203.31batch/s]\u001B[A\n",
      "Training batches on cuda:0:  65%|██████▌   | 522/801 [00:02<00:01, 203.37batch/s]\u001B[A\n",
      "Training batches on cuda:0:  68%|██████▊   | 543/801 [00:02<00:01, 203.19batch/s]\u001B[A\n",
      "Training batches on cuda:0:  70%|███████   | 564/801 [00:02<00:01, 203.36batch/s]\u001B[A\n",
      "Training batches on cuda:0:  73%|███████▎  | 585/801 [00:02<00:01, 203.65batch/s]\u001B[A\n",
      "Training batches on cuda:0:  76%|███████▌  | 606/801 [00:02<00:00, 204.00batch/s]\u001B[A\n",
      "Training batches on cuda:0:  78%|███████▊  | 627/801 [00:03<00:00, 203.81batch/s]\u001B[A\n",
      "Training batches on cuda:0:  81%|████████  | 648/801 [00:03<00:00, 203.55batch/s]\u001B[A\n",
      "Training batches on cuda:0:  84%|████████▎ | 669/801 [00:03<00:00, 203.94batch/s]\u001B[A\n",
      "Training batches on cuda:0:  86%|████████▌ | 690/801 [00:03<00:00, 204.19batch/s]\u001B[A\n",
      "Training batches on cuda:0:  89%|████████▉ | 711/801 [00:03<00:00, 203.89batch/s]\u001B[A\n",
      "Training batches on cuda:0:  91%|█████████▏| 732/801 [00:03<00:00, 203.82batch/s]\u001B[A\n",
      "Training batches on cuda:0:  94%|█████████▍| 753/801 [00:03<00:00, 203.89batch/s]\u001B[A\n",
      "Training batches on cuda:0:  97%|█████████▋| 774/801 [00:03<00:00, 202.22batch/s]\u001B[A\n",
      "Training batches on cuda:0:  99%|█████████▉| 795/801 [00:03<00:00, 202.99batch/s]\u001B[A\n",
      "Training epochs on cuda:0:   8%|▊         | 4/50 [00:16<03:09,  4.12s/epoch, loss=0.98, prev_loss=0.998]\n",
      "Training batches on cuda:0:   0%|          | 0/801 [00:00<?, ?batch/s]\u001B[A\n",
      "Training batches on cuda:0:   2%|▏         | 19/801 [00:00<00:04, 187.10batch/s]\u001B[A\n",
      "Training batches on cuda:0:   5%|▍         | 40/801 [00:00<00:03, 196.85batch/s]\u001B[A\n",
      "Training batches on cuda:0:   8%|▊         | 61/801 [00:00<00:03, 200.54batch/s]\u001B[A\n",
      "Training batches on cuda:0:  10%|█         | 82/801 [00:00<00:03, 201.15batch/s]\u001B[A\n",
      "Training batches on cuda:0:  13%|█▎        | 103/801 [00:00<00:03, 202.28batch/s]\u001B[A\n",
      "Training batches on cuda:0:  15%|█▌        | 124/801 [00:00<00:03, 203.16batch/s]\u001B[A\n",
      "Training batches on cuda:0:  18%|█▊        | 145/801 [00:00<00:03, 203.64batch/s]\u001B[A\n",
      "Training batches on cuda:0:  21%|██        | 166/801 [00:00<00:03, 203.58batch/s]\u001B[A\n",
      "Training batches on cuda:0:  23%|██▎       | 187/801 [00:00<00:03, 203.52batch/s]\u001B[A\n",
      "Training batches on cuda:0:  26%|██▌       | 208/801 [00:01<00:02, 203.77batch/s]\u001B[A\n",
      "Training batches on cuda:0:  29%|██▊       | 229/801 [00:01<00:02, 203.85batch/s]\u001B[A\n",
      "Training batches on cuda:0:  31%|███       | 250/801 [00:01<00:02, 204.13batch/s]\u001B[A\n",
      "Training batches on cuda:0:  34%|███▍      | 271/801 [00:01<00:02, 203.95batch/s]\u001B[A\n",
      "Training batches on cuda:0:  36%|███▋      | 292/801 [00:01<00:02, 203.93batch/s]\u001B[A\n",
      "Training batches on cuda:0:  39%|███▉      | 313/801 [00:01<00:02, 202.62batch/s]\u001B[A\n",
      "Training batches on cuda:0:  42%|████▏     | 334/801 [00:01<00:02, 202.65batch/s]\u001B[A\n",
      "Training batches on cuda:0:  44%|████▍     | 355/801 [00:01<00:02, 203.02batch/s]\u001B[A\n",
      "Training batches on cuda:0:  47%|████▋     | 376/801 [00:01<00:02, 203.35batch/s]\u001B[A\n",
      "Training batches on cuda:0:  50%|████▉     | 397/801 [00:01<00:01, 203.55batch/s]\u001B[A\n",
      "Training batches on cuda:0:  52%|█████▏    | 418/801 [00:02<00:01, 203.68batch/s]\u001B[A\n",
      "Training batches on cuda:0:  55%|█████▍    | 439/801 [00:02<00:01, 203.62batch/s]\u001B[A\n",
      "Training batches on cuda:0:  57%|█████▋    | 460/801 [00:02<00:01, 203.64batch/s]\u001B[A\n",
      "Training batches on cuda:0:  60%|██████    | 481/801 [00:02<00:01, 203.53batch/s]\u001B[A\n",
      "Training batches on cuda:0:  63%|██████▎   | 502/801 [00:02<00:01, 203.33batch/s]\u001B[A\n",
      "Training batches on cuda:0:  65%|██████▌   | 523/801 [00:02<00:01, 203.42batch/s]\u001B[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  68%|██████▊   | 544/801 [00:02<00:01, 203.16batch/s]\u001B[A\n",
      "Training batches on cuda:0:  71%|███████   | 565/801 [00:02<00:01, 202.93batch/s]\u001B[A\n",
      "Training batches on cuda:0:  73%|███████▎  | 586/801 [00:02<00:01, 202.72batch/s]\u001B[A\n",
      "Training batches on cuda:0:  76%|███████▌  | 607/801 [00:02<00:00, 203.04batch/s]\u001B[A\n",
      "Training batches on cuda:0:  78%|███████▊  | 628/801 [00:03<00:00, 202.88batch/s]\u001B[A\n",
      "Training batches on cuda:0:  81%|████████  | 649/801 [00:03<00:00, 202.68batch/s]\u001B[A\n",
      "Training batches on cuda:0:  84%|████████▎ | 670/801 [00:03<00:00, 202.56batch/s]\u001B[A\n",
      "Training batches on cuda:0:  86%|████████▋ | 691/801 [00:03<00:00, 202.27batch/s]\u001B[A\n",
      "Training batches on cuda:0:  89%|████████▉ | 712/801 [00:03<00:00, 202.53batch/s]\u001B[A\n",
      "Training batches on cuda:0:  92%|█████████▏| 733/801 [00:03<00:00, 202.47batch/s]\u001B[A\n",
      "Training batches on cuda:0:  94%|█████████▍| 754/801 [00:03<00:00, 202.39batch/s]\u001B[A\n",
      "Training batches on cuda:0:  97%|█████████▋| 775/801 [00:03<00:00, 202.44batch/s]\u001B[A\n",
      "Training batches on cuda:0:  99%|█████████▉| 796/801 [00:03<00:00, 202.44batch/s]\u001B[A\n",
      "Training epochs on cuda:0:  10%|█         | 5/50 [00:20<03:05,  4.11s/epoch, loss=0.959, prev_loss=0.98]\n",
      "Training batches on cuda:0:   0%|          | 0/801 [00:00<?, ?batch/s]\u001B[A\n",
      "Training batches on cuda:0:   2%|▏         | 19/801 [00:00<00:04, 189.76batch/s]\u001B[A\n",
      "Training batches on cuda:0:   5%|▍         | 40/801 [00:00<00:03, 197.48batch/s]\u001B[A\n",
      "Training batches on cuda:0:   8%|▊         | 61/801 [00:00<00:03, 200.46batch/s]\u001B[A\n",
      "Training batches on cuda:0:  10%|█         | 82/801 [00:00<00:03, 200.82batch/s]\u001B[A\n",
      "Training batches on cuda:0:  13%|█▎        | 103/801 [00:00<00:03, 202.18batch/s]\u001B[A\n",
      "Training batches on cuda:0:  15%|█▌        | 124/801 [00:00<00:03, 202.63batch/s]\u001B[A\n",
      "Training batches on cuda:0:  18%|█▊        | 145/801 [00:00<00:03, 203.12batch/s]\u001B[A\n",
      "Training batches on cuda:0:  21%|██        | 166/801 [00:00<00:03, 203.18batch/s]\u001B[A\n",
      "Training batches on cuda:0:  23%|██▎       | 187/801 [00:00<00:03, 203.42batch/s]\u001B[A\n",
      "Training batches on cuda:0:  26%|██▌       | 208/801 [00:01<00:02, 203.63batch/s]\u001B[A\n",
      "Training batches on cuda:0:  29%|██▊       | 229/801 [00:01<00:02, 203.40batch/s]\u001B[A\n",
      "Training batches on cuda:0:  31%|███       | 250/801 [00:01<00:02, 203.60batch/s]\u001B[A\n",
      "Training batches on cuda:0:  34%|███▍      | 271/801 [00:01<00:02, 203.75batch/s]\u001B[A\n",
      "Training batches on cuda:0:  36%|███▋      | 292/801 [00:01<00:02, 203.91batch/s]\u001B[A\n",
      "Training batches on cuda:0:  39%|███▉      | 313/801 [00:01<00:02, 203.98batch/s]\u001B[A\n",
      "Training batches on cuda:0:  42%|████▏     | 334/801 [00:01<00:02, 203.63batch/s]\u001B[A\n",
      "Training batches on cuda:0:  44%|████▍     | 355/801 [00:01<00:02, 203.60batch/s]\u001B[A\n",
      "Training batches on cuda:0:  47%|████▋     | 376/801 [00:01<00:02, 203.66batch/s]\u001B[A\n",
      "Training batches on cuda:0:  50%|████▉     | 397/801 [00:01<00:01, 203.74batch/s]\u001B[A\n",
      "Training batches on cuda:0:  52%|█████▏    | 418/801 [00:02<00:01, 203.74batch/s]\u001B[A\n",
      "Training batches on cuda:0:  55%|█████▍    | 439/801 [00:02<00:01, 203.79batch/s]\u001B[A\n",
      "Training batches on cuda:0:  57%|█████▋    | 460/801 [00:02<00:01, 203.72batch/s]\u001B[A\n",
      "Training batches on cuda:0:  60%|██████    | 481/801 [00:02<00:01, 203.67batch/s]\u001B[A\n",
      "Training batches on cuda:0:  63%|██████▎   | 502/801 [00:02<00:01, 203.50batch/s]\u001B[A\n",
      "Training batches on cuda:0:  65%|██████▌   | 523/801 [00:02<00:01, 203.59batch/s]\u001B[A\n",
      "Training batches on cuda:0:  68%|██████▊   | 544/801 [00:02<00:01, 203.60batch/s]\u001B[A\n",
      "Training batches on cuda:0:  71%|███████   | 565/801 [00:02<00:01, 203.31batch/s]\u001B[A\n",
      "Training batches on cuda:0:  73%|███████▎  | 586/801 [00:02<00:01, 203.38batch/s]\u001B[A\n",
      "Training batches on cuda:0:  76%|███████▌  | 607/801 [00:02<00:00, 203.29batch/s]\u001B[A\n",
      "Training batches on cuda:0:  78%|███████▊  | 628/801 [00:03<00:00, 203.32batch/s]\u001B[A\n",
      "Training batches on cuda:0:  81%|████████  | 649/801 [00:03<00:00, 203.35batch/s]\u001B[A\n",
      "Training batches on cuda:0:  84%|████████▎ | 670/801 [00:03<00:00, 203.11batch/s]\u001B[A\n",
      "Training batches on cuda:0:  86%|████████▋ | 691/801 [00:03<00:00, 203.45batch/s]\u001B[A\n",
      "Training batches on cuda:0:  89%|████████▉ | 712/801 [00:03<00:00, 203.59batch/s]\u001B[A\n",
      "Training batches on cuda:0:  92%|█████████▏| 733/801 [00:03<00:00, 203.66batch/s]\u001B[A\n",
      "Training batches on cuda:0:  94%|█████████▍| 754/801 [00:03<00:00, 203.47batch/s]\u001B[A\n",
      "Training batches on cuda:0:  97%|█████████▋| 775/801 [00:03<00:00, 203.29batch/s]\u001B[A\n",
      "Training batches on cuda:0:  99%|█████████▉| 796/801 [00:03<00:00, 203.39batch/s]\u001B[A\n",
      "Training epochs on cuda:0:  12%|█▏        | 6/50 [00:24<03:00,  4.11s/epoch, loss=0.94, prev_loss=0.959]\n",
      "Training batches on cuda:0:   0%|          | 0/801 [00:00<?, ?batch/s]\u001B[A\n",
      "Training batches on cuda:0:   2%|▏         | 19/801 [00:00<00:04, 185.80batch/s]\u001B[A\n",
      "Training batches on cuda:0:   5%|▍         | 40/801 [00:00<00:03, 196.65batch/s]\u001B[A\n",
      "Training batches on cuda:0:   8%|▊         | 61/801 [00:00<00:03, 200.17batch/s]\u001B[A\n",
      "Training batches on cuda:0:  10%|█         | 82/801 [00:00<00:03, 200.70batch/s]\u001B[A\n",
      "Training batches on cuda:0:  13%|█▎        | 103/801 [00:00<00:03, 202.01batch/s]\u001B[A\n",
      "Training batches on cuda:0:  15%|█▌        | 124/801 [00:00<00:03, 202.41batch/s]\u001B[A\n",
      "Training batches on cuda:0:  18%|█▊        | 145/801 [00:00<00:03, 203.11batch/s]\u001B[A\n",
      "Training batches on cuda:0:  21%|██        | 166/801 [00:00<00:03, 203.63batch/s]\u001B[A\n",
      "Training batches on cuda:0:  23%|██▎       | 187/801 [00:00<00:03, 203.90batch/s]\u001B[A\n",
      "Training batches on cuda:0:  26%|██▌       | 208/801 [00:01<00:02, 203.76batch/s]\u001B[A\n",
      "Training batches on cuda:0:  29%|██▊       | 229/801 [00:01<00:02, 203.57batch/s]\u001B[A\n",
      "Training batches on cuda:0:  31%|███       | 250/801 [00:01<00:02, 203.53batch/s]\u001B[A\n",
      "Training batches on cuda:0:  34%|███▍      | 271/801 [00:01<00:02, 203.05batch/s]\u001B[A\n",
      "Training batches on cuda:0:  36%|███▋      | 292/801 [00:01<00:02, 202.96batch/s]\u001B[A\n",
      "Training batches on cuda:0:  39%|███▉      | 313/801 [00:01<00:02, 203.18batch/s]\u001B[A\n",
      "Training batches on cuda:0:  42%|████▏     | 334/801 [00:01<00:02, 203.25batch/s]\u001B[A\n",
      "Training batches on cuda:0:  44%|████▍     | 355/801 [00:01<00:02, 203.29batch/s]\u001B[A\n",
      "Training batches on cuda:0:  47%|████▋     | 376/801 [00:01<00:02, 203.40batch/s]\u001B[A\n",
      "Training batches on cuda:0:  50%|████▉     | 397/801 [00:01<00:01, 203.53batch/s]\u001B[A\n",
      "Training batches on cuda:0:  52%|█████▏    | 418/801 [00:02<00:01, 202.81batch/s]\u001B[A\n",
      "Training batches on cuda:0:  55%|█████▍    | 439/801 [00:02<00:01, 203.17batch/s]\u001B[A\n",
      "Training batches on cuda:0:  57%|█████▋    | 460/801 [00:02<00:01, 203.03batch/s]\u001B[A\n",
      "Training batches on cuda:0:  60%|██████    | 481/801 [00:02<00:01, 203.24batch/s]\u001B[A\n",
      "Training batches on cuda:0:  63%|██████▎   | 502/801 [00:02<00:01, 202.04batch/s]\u001B[A\n",
      "Training batches on cuda:0:  65%|██████▌   | 523/801 [00:02<00:01, 202.45batch/s]\u001B[A\n",
      "Training batches on cuda:0:  68%|██████▊   | 544/801 [00:02<00:01, 202.82batch/s]\u001B[A\n",
      "Training batches on cuda:0:  71%|███████   | 565/801 [00:02<00:01, 203.14batch/s]\u001B[A\n",
      "Training batches on cuda:0:  73%|███████▎  | 586/801 [00:02<00:01, 203.53batch/s]\u001B[A\n",
      "Training batches on cuda:0:  76%|███████▌  | 607/801 [00:02<00:00, 203.85batch/s]\u001B[A\n",
      "Training batches on cuda:0:  78%|███████▊  | 628/801 [00:03<00:00, 203.59batch/s]\u001B[A\n",
      "Training batches on cuda:0:  81%|████████  | 649/801 [00:03<00:00, 203.95batch/s]\u001B[A\n",
      "Training batches on cuda:0:  84%|████████▎ | 670/801 [00:03<00:00, 204.20batch/s]\u001B[A\n",
      "Training batches on cuda:0:  86%|████████▋ | 691/801 [00:03<00:00, 204.08batch/s]\u001B[A\n",
      "Training batches on cuda:0:  89%|████████▉ | 712/801 [00:03<00:00, 203.90batch/s]\u001B[A\n",
      "Training batches on cuda:0:  92%|█████████▏| 733/801 [00:03<00:00, 204.25batch/s]\u001B[A\n",
      "Training batches on cuda:0:  94%|█████████▍| 754/801 [00:03<00:00, 204.34batch/s]\u001B[A\n",
      "Training batches on cuda:0:  97%|█████████▋| 775/801 [00:03<00:00, 204.42batch/s]\u001B[A\n",
      "Training batches on cuda:0:  99%|█████████▉| 796/801 [00:03<00:00, 204.27batch/s]\u001B[A\n",
      "Training epochs on cuda:0:  14%|█▍        | 7/50 [00:28<02:56,  4.11s/epoch, loss=0.921, prev_loss=0.94]\n",
      "Training batches on cuda:0:   0%|          | 0/801 [00:00<?, ?batch/s]\u001B[A\n",
      "Training batches on cuda:0:   1%|▏         | 12/801 [00:00<00:06, 114.92batch/s]\u001B[A\n",
      "Training batches on cuda:0:   4%|▍         | 33/801 [00:00<00:04, 166.44batch/s]\u001B[A\n",
      "Training batches on cuda:0:   7%|▋         | 54/801 [00:00<00:04, 183.36batch/s]\u001B[A\n",
      "Training batches on cuda:0:   9%|▉         | 74/801 [00:00<00:03, 189.54batch/s]\u001B[A\n",
      "Training batches on cuda:0:  12%|█▏        | 95/801 [00:00<00:03, 194.90batch/s]\u001B[A\n",
      "Training batches on cuda:0:  14%|█▍        | 116/801 [00:00<00:03, 197.67batch/s]\u001B[A\n",
      "Training batches on cuda:0:  17%|█▋        | 137/801 [00:00<00:03, 199.68batch/s]\u001B[A\n",
      "Training batches on cuda:0:  20%|█▉        | 158/801 [00:00<00:03, 201.09batch/s]\u001B[A\n",
      "Training batches on cuda:0:  22%|██▏       | 179/801 [00:00<00:03, 201.85batch/s]\u001B[A\n",
      "Training batches on cuda:0:  25%|██▍       | 200/801 [00:01<00:02, 202.19batch/s]\u001B[A\n",
      "Training batches on cuda:0:  28%|██▊       | 221/801 [00:01<00:02, 202.39batch/s]\u001B[A\n",
      "Training batches on cuda:0:  30%|███       | 242/801 [00:01<00:02, 202.52batch/s]\u001B[A\n",
      "Training batches on cuda:0:  33%|███▎      | 263/801 [00:01<00:02, 203.05batch/s]\u001B[A\n",
      "Training batches on cuda:0:  35%|███▌      | 284/801 [00:01<00:02, 202.90batch/s]\u001B[A\n",
      "Training batches on cuda:0:  38%|███▊      | 305/801 [00:01<00:02, 203.12batch/s]\u001B[A\n",
      "Training batches on cuda:0:  41%|████      | 326/801 [00:01<00:02, 203.49batch/s]\u001B[A\n",
      "Training batches on cuda:0:  43%|████▎     | 347/801 [00:01<00:02, 203.45batch/s]\u001B[A\n",
      "Training batches on cuda:0:  46%|████▌     | 368/801 [00:01<00:02, 199.17batch/s]\u001B[A\n",
      "Training batches on cuda:0:  49%|████▊     | 389/801 [00:01<00:02, 200.45batch/s]\u001B[A\n",
      "Training batches on cuda:0:  51%|█████     | 410/801 [00:02<00:01, 201.48batch/s]\u001B[A\n",
      "Training batches on cuda:0:  54%|█████▍    | 431/801 [00:02<00:01, 201.78batch/s]\u001B[A\n",
      "Training batches on cuda:0:  56%|█████▋    | 452/801 [00:02<00:01, 202.50batch/s]\u001B[A\n",
      "Training batches on cuda:0:  59%|█████▉    | 473/801 [00:02<00:01, 202.61batch/s]\u001B[A\n",
      "Training batches on cuda:0:  62%|██████▏   | 494/801 [00:02<00:01, 202.62batch/s]\u001B[A\n",
      "Training batches on cuda:0:  64%|██████▍   | 515/801 [00:02<00:01, 202.59batch/s]\u001B[A\n",
      "Training batches on cuda:0:  67%|██████▋   | 536/801 [00:02<00:01, 202.80batch/s]\u001B[A\n",
      "Training batches on cuda:0:  70%|██████▉   | 557/801 [00:02<00:01, 203.16batch/s]\u001B[A\n",
      "Training batches on cuda:0:  72%|███████▏  | 578/801 [00:02<00:01, 202.89batch/s]\u001B[A\n",
      "Training batches on cuda:0:  75%|███████▍  | 599/801 [00:03<00:00, 203.20batch/s]\u001B[A\n",
      "Training batches on cuda:0:  77%|███████▋  | 620/801 [00:03<00:00, 202.87batch/s]\u001B[A\n",
      "Training batches on cuda:0:  80%|████████  | 641/801 [00:03<00:00, 202.76batch/s]\u001B[A\n",
      "Training batches on cuda:0:  83%|████████▎ | 662/801 [00:03<00:00, 203.00batch/s]\u001B[A\n",
      "Training batches on cuda:0:  85%|████████▌ | 683/801 [00:03<00:00, 202.97batch/s]\u001B[A\n",
      "Training batches on cuda:0:  88%|████████▊ | 704/801 [00:03<00:00, 202.99batch/s]\u001B[A\n",
      "Training batches on cuda:0:  91%|█████████ | 725/801 [00:03<00:00, 202.86batch/s]\u001B[A\n",
      "Training batches on cuda:0:  93%|█████████▎| 746/801 [00:03<00:00, 202.67batch/s]\u001B[A\n",
      "Training batches on cuda:0:  96%|█████████▌| 767/801 [00:03<00:00, 202.74batch/s]\u001B[A\n",
      "Training batches on cuda:0:  98%|█████████▊| 788/801 [00:03<00:00, 203.00batch/s]\u001B[A\n",
      "Training epochs on cuda:0:  16%|█▌        | 8/50 [00:32<02:53,  4.13s/epoch, loss=0.899, prev_loss=0.921]\n",
      "Training batches on cuda:0:   0%|          | 0/801 [00:00<?, ?batch/s]\u001B[A\n",
      "Training batches on cuda:0:   2%|▏         | 19/801 [00:00<00:04, 187.97batch/s]\u001B[A\n",
      "Training batches on cuda:0:   5%|▍         | 38/801 [00:00<00:10, 70.67batch/s] \u001B[A\n",
      "Training batches on cuda:0:   7%|▋         | 58/801 [00:00<00:07, 100.87batch/s]\u001B[A\n",
      "Training batches on cuda:0:  10%|▉         | 78/801 [00:00<00:05, 125.12batch/s]\u001B[A\n",
      "Training batches on cuda:0:  12%|█▏        | 98/801 [00:00<00:04, 144.28batch/s]\u001B[A\n",
      "Training batches on cuda:0:  15%|█▍        | 118/801 [00:00<00:04, 159.06batch/s]\u001B[A\n",
      "Training batches on cuda:0:  17%|█▋        | 138/801 [00:00<00:03, 169.28batch/s]\u001B[A\n",
      "Training batches on cuda:0:  20%|█▉        | 158/801 [00:01<00:03, 177.37batch/s]\u001B[A\n",
      "Training batches on cuda:0:  22%|██▏       | 178/801 [00:01<00:03, 183.24batch/s]\u001B[A\n",
      "Training batches on cuda:0:  25%|██▍       | 198/801 [00:01<00:03, 187.45batch/s]\u001B[A\n",
      "Training batches on cuda:0:  27%|██▋       | 218/801 [00:01<00:03, 190.32batch/s]\u001B[A\n",
      "Training batches on cuda:0:  30%|██▉       | 238/801 [00:01<00:02, 192.39batch/s]\u001B[A\n",
      "Training batches on cuda:0:  32%|███▏      | 259/801 [00:01<00:02, 194.88batch/s]\u001B[A\n",
      "Training batches on cuda:0:  35%|███▍      | 280/801 [00:01<00:02, 196.59batch/s]\u001B[A\n",
      "Training batches on cuda:0:  38%|███▊      | 301/801 [00:01<00:02, 197.84batch/s]\u001B[A\n",
      "Training batches on cuda:0:  40%|████      | 322/801 [00:01<00:02, 198.65batch/s]\u001B[A\n",
      "Training batches on cuda:0:  43%|████▎     | 343/801 [00:02<00:02, 199.21batch/s]\u001B[A\n",
      "Training batches on cuda:0:  45%|████▌     | 364/801 [00:02<00:02, 199.62batch/s]\u001B[A\n",
      "Training batches on cuda:0:  48%|████▊     | 385/801 [00:02<00:02, 199.91batch/s]\u001B[A\n",
      "Training batches on cuda:0:  51%|█████     | 406/801 [00:02<00:01, 200.05batch/s]\u001B[A\n",
      "Training batches on cuda:0:  53%|█████▎    | 427/801 [00:02<00:01, 200.20batch/s]\u001B[A\n",
      "Training batches on cuda:0:  56%|█████▌    | 448/801 [00:02<00:01, 200.32batch/s]\u001B[A\n",
      "Training batches on cuda:0:  59%|█████▊    | 469/801 [00:02<00:01, 200.37batch/s]\u001B[A\n",
      "Training batches on cuda:0:  61%|██████    | 490/801 [00:02<00:01, 200.40batch/s]\u001B[A\n",
      "Training batches on cuda:0:  64%|██████▍   | 511/801 [00:02<00:01, 200.53batch/s]\u001B[A\n",
      "Training batches on cuda:0:  66%|██████▋   | 532/801 [00:02<00:01, 200.51batch/s]\u001B[A\n",
      "Training batches on cuda:0:  69%|██████▉   | 553/801 [00:03<00:01, 200.41batch/s]\u001B[A\n",
      "Training batches on cuda:0:  72%|███████▏  | 574/801 [00:03<00:01, 200.48batch/s]\u001B[A\n",
      "Training batches on cuda:0:  74%|███████▍  | 595/801 [00:03<00:01, 200.47batch/s]\u001B[A\n",
      "Training batches on cuda:0:  77%|███████▋  | 616/801 [00:03<00:00, 200.54batch/s]\u001B[A\n",
      "Training batches on cuda:0:  80%|███████▉  | 637/801 [00:03<00:00, 200.53batch/s]\u001B[A\n",
      "Training batches on cuda:0:  82%|████████▏ | 658/801 [00:03<00:00, 200.60batch/s]\u001B[A\n",
      "Training batches on cuda:0:  85%|████████▍ | 679/801 [00:03<00:00, 200.54batch/s]\u001B[A\n",
      "Training batches on cuda:0:  87%|████████▋ | 700/801 [00:03<00:00, 200.61batch/s]\u001B[A\n",
      "Training batches on cuda:0:  90%|█████████ | 721/801 [00:03<00:00, 200.49batch/s]\u001B[A\n",
      "Training batches on cuda:0:  93%|█████████▎| 742/801 [00:04<00:00, 200.61batch/s]\u001B[A\n",
      "Training batches on cuda:0:  95%|█████████▌| 763/801 [00:04<00:00, 200.55batch/s]\u001B[A\n",
      "Training batches on cuda:0:  98%|█████████▊| 784/801 [00:04<00:00, 200.60batch/s]\u001B[A\n",
      "Training epochs on cuda:0:  18%|█▊        | 9/50 [00:37<02:53,  4.24s/epoch, loss=0.877, prev_loss=0.899]\n",
      "Training batches on cuda:0:   0%|          | 0/801 [00:00<?, ?batch/s]\u001B[A\n",
      "Training batches on cuda:0:   2%|▏         | 20/801 [00:00<00:04, 191.33batch/s]\u001B[A\n",
      "Training batches on cuda:0:   5%|▍         | 40/801 [00:00<00:03, 196.14batch/s]\u001B[A\n",
      "Training batches on cuda:0:   8%|▊         | 61/801 [00:00<00:03, 198.31batch/s]\u001B[A\n",
      "Training batches on cuda:0:  10%|█         | 81/801 [00:00<00:03, 198.23batch/s]\u001B[A\n",
      "Training batches on cuda:0:  13%|█▎        | 102/801 [00:00<00:03, 198.92batch/s]\u001B[A\n",
      "Training batches on cuda:0:  15%|█▌        | 123/801 [00:00<00:03, 199.51batch/s]\u001B[A\n",
      "Training batches on cuda:0:  18%|█▊        | 144/801 [00:00<00:03, 199.90batch/s]\u001B[A\n",
      "Training batches on cuda:0:  21%|██        | 165/801 [00:00<00:03, 200.19batch/s]\u001B[A\n",
      "Training batches on cuda:0:  23%|██▎       | 186/801 [00:00<00:03, 200.24batch/s]\u001B[A\n",
      "Training batches on cuda:0:  26%|██▌       | 207/801 [00:01<00:02, 200.35batch/s]\u001B[A\n",
      "Training batches on cuda:0:  28%|██▊       | 228/801 [00:01<00:02, 200.45batch/s]\u001B[A\n",
      "Training batches on cuda:0:  31%|███       | 249/801 [00:01<00:02, 200.49batch/s]\u001B[A\n",
      "Training batches on cuda:0:  34%|███▎      | 270/801 [00:01<00:02, 200.58batch/s]\u001B[A\n",
      "Training batches on cuda:0:  36%|███▋      | 291/801 [00:01<00:02, 200.66batch/s]\u001B[A\n",
      "Training batches on cuda:0:  39%|███▉      | 312/801 [00:01<00:02, 200.67batch/s]\u001B[A\n",
      "Training batches on cuda:0:  42%|████▏     | 333/801 [00:01<00:02, 200.65batch/s]\u001B[A\n",
      "Training batches on cuda:0:  44%|████▍     | 354/801 [00:01<00:02, 200.58batch/s]\u001B[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  47%|████▋     | 375/801 [00:01<00:02, 200.41batch/s]\u001B[A\n",
      "Training batches on cuda:0:  49%|████▉     | 396/801 [00:01<00:02, 200.50batch/s]\u001B[A\n",
      "Training batches on cuda:0:  52%|█████▏    | 417/801 [00:02<00:01, 200.51batch/s]\u001B[A\n",
      "Training batches on cuda:0:  55%|█████▍    | 438/801 [00:02<00:01, 200.45batch/s]\u001B[A\n",
      "Training batches on cuda:0:  57%|█████▋    | 459/801 [00:02<00:01, 200.48batch/s]\u001B[A\n",
      "Training batches on cuda:0:  60%|█████▉    | 480/801 [00:02<00:01, 200.41batch/s]\u001B[A\n",
      "Training batches on cuda:0:  63%|██████▎   | 501/801 [00:02<00:01, 200.47batch/s]\u001B[A\n",
      "Training batches on cuda:0:  65%|██████▌   | 522/801 [00:02<00:01, 200.54batch/s]\u001B[A\n",
      "Training batches on cuda:0:  68%|██████▊   | 543/801 [00:02<00:01, 200.55batch/s]\u001B[A\n",
      "Training batches on cuda:0:  70%|███████   | 564/801 [00:02<00:01, 200.50batch/s]\u001B[A\n",
      "Training batches on cuda:0:  73%|███████▎  | 585/801 [00:02<00:01, 200.54batch/s]\u001B[A\n",
      "Training batches on cuda:0:  76%|███████▌  | 606/801 [00:03<00:00, 200.55batch/s]\u001B[A\n",
      "Training batches on cuda:0:  78%|███████▊  | 627/801 [00:03<00:00, 200.54batch/s]\u001B[A\n",
      "Training batches on cuda:0:  81%|████████  | 648/801 [00:03<00:00, 200.57batch/s]\u001B[A\n",
      "Training batches on cuda:0:  84%|████████▎ | 669/801 [00:03<00:00, 200.48batch/s]\u001B[A\n",
      "Training batches on cuda:0:  86%|████████▌ | 690/801 [00:03<00:00, 200.51batch/s]\u001B[A\n",
      "Training batches on cuda:0:  89%|████████▉ | 711/801 [00:03<00:00, 200.49batch/s]\u001B[A\n",
      "Training batches on cuda:0:  91%|█████████▏| 732/801 [00:03<00:00, 200.40batch/s]\u001B[A\n",
      "Training batches on cuda:0:  94%|█████████▍| 753/801 [00:03<00:00, 200.18batch/s]\u001B[A\n",
      "Training batches on cuda:0:  97%|█████████▋| 774/801 [00:03<00:00, 200.04batch/s]\u001B[A\n",
      "Training batches on cuda:0:  99%|█████████▉| 795/801 [00:03<00:00, 199.84batch/s]\u001B[A\n",
      "Training epochs on cuda:0:  20%|██        | 10/50 [00:41<02:48,  4.22s/epoch, loss=0.858, prev_loss=0.877]\n",
      "Training batches on cuda:0:   0%|          | 0/801 [00:00<?, ?batch/s]\u001B[A\n",
      "Training batches on cuda:0:   2%|▏         | 19/801 [00:00<00:04, 189.08batch/s]\u001B[A\n",
      "Training batches on cuda:0:   5%|▍         | 39/801 [00:00<00:03, 195.22batch/s]\u001B[A\n",
      "Training batches on cuda:0:   7%|▋         | 60/801 [00:00<00:03, 197.70batch/s]\u001B[A\n",
      "Training batches on cuda:0:  10%|▉         | 80/801 [00:00<00:03, 197.77batch/s]\u001B[A\n",
      "Training batches on cuda:0:  13%|█▎        | 101/801 [00:00<00:03, 198.65batch/s]\u001B[A\n",
      "Training batches on cuda:0:  15%|█▌        | 122/801 [00:00<00:03, 199.33batch/s]\u001B[A\n",
      "Training batches on cuda:0:  18%|█▊        | 142/801 [00:00<00:03, 199.52batch/s]\u001B[A\n",
      "Training batches on cuda:0:  20%|██        | 163/801 [00:00<00:03, 199.82batch/s]\u001B[A\n",
      "Training batches on cuda:0:  23%|██▎       | 183/801 [00:00<00:03, 199.87batch/s]\u001B[A\n",
      "Training batches on cuda:0:  25%|██▌       | 204/801 [00:01<00:02, 200.22batch/s]\u001B[A\n",
      "Training batches on cuda:0:  28%|██▊       | 225/801 [00:01<00:02, 200.23batch/s]\u001B[A\n",
      "Training batches on cuda:0:  31%|███       | 246/801 [00:01<00:02, 200.27batch/s]\u001B[A\n",
      "Training batches on cuda:0:  33%|███▎      | 267/801 [00:01<00:02, 200.36batch/s]\u001B[A\n",
      "Training batches on cuda:0:  36%|███▌      | 288/801 [00:01<00:02, 200.28batch/s]\u001B[A\n",
      "Training batches on cuda:0:  39%|███▊      | 309/801 [00:01<00:02, 200.39batch/s]\u001B[A\n",
      "Training batches on cuda:0:  41%|████      | 330/801 [00:01<00:02, 200.36batch/s]\u001B[A\n",
      "Training batches on cuda:0:  44%|████▍     | 351/801 [00:01<00:02, 200.27batch/s]\u001B[A\n",
      "Training batches on cuda:0:  46%|████▋     | 372/801 [00:01<00:02, 199.96batch/s]\u001B[A\n",
      "Training batches on cuda:0:  49%|████▉     | 392/801 [00:01<00:02, 199.60batch/s]\u001B[A\n",
      "Training batches on cuda:0:  51%|█████▏    | 412/801 [00:02<00:01, 199.48batch/s]\u001B[A\n",
      "Training batches on cuda:0:  54%|█████▍    | 432/801 [00:02<00:01, 199.36batch/s]\u001B[A\n",
      "Training batches on cuda:0:  56%|█████▋    | 452/801 [00:02<00:01, 199.24batch/s]\u001B[A\n",
      "Training batches on cuda:0:  59%|█████▉    | 472/801 [00:02<00:01, 199.18batch/s]\u001B[A\n",
      "Training batches on cuda:0:  61%|██████▏   | 492/801 [00:02<00:01, 199.11batch/s]\u001B[A\n",
      "Training batches on cuda:0:  64%|██████▍   | 512/801 [00:02<00:01, 199.07batch/s]\u001B[A\n",
      "Training batches on cuda:0:  66%|██████▋   | 532/801 [00:02<00:01, 199.08batch/s]\u001B[A\n",
      "Training batches on cuda:0:  69%|██████▉   | 552/801 [00:02<00:01, 198.87batch/s]\u001B[A\n",
      "Training batches on cuda:0:  71%|███████▏  | 572/801 [00:02<00:01, 198.88batch/s]\u001B[A\n",
      "Training batches on cuda:0:  74%|███████▍  | 592/801 [00:02<00:01, 199.11batch/s]\u001B[A\n",
      "Training batches on cuda:0:  76%|███████▋  | 612/801 [00:03<00:00, 199.01batch/s]\u001B[A\n",
      "Training batches on cuda:0:  79%|███████▉  | 632/801 [00:03<00:00, 199.28batch/s]\u001B[A\n",
      "Training batches on cuda:0:  82%|████████▏ | 653/801 [00:03<00:00, 199.55batch/s]\u001B[A\n",
      "Training batches on cuda:0:  84%|████████▍ | 674/801 [00:03<00:00, 199.81batch/s]\u001B[A\n",
      "Training batches on cuda:0:  87%|████████▋ | 694/801 [00:03<00:00, 199.85batch/s]\u001B[A\n",
      "Training batches on cuda:0:  89%|████████▉ | 715/801 [00:03<00:00, 199.98batch/s]\u001B[A\n",
      "Training batches on cuda:0:  92%|█████████▏| 735/801 [00:03<00:00, 199.98batch/s]\u001B[A\n",
      "Training batches on cuda:0:  94%|█████████▍| 755/801 [00:03<00:00, 199.93batch/s]\u001B[A\n",
      "Training batches on cuda:0:  97%|█████████▋| 775/801 [00:03<00:00, 199.93batch/s]\u001B[A\n",
      "Training batches on cuda:0:  99%|█████████▉| 795/801 [00:03<00:00, 199.86batch/s]\u001B[A\n",
      "Training epochs on cuda:0:  22%|██▏       | 11/50 [00:45<02:44,  4.21s/epoch, loss=0.842, prev_loss=0.858]\n",
      "Training batches on cuda:0:   0%|          | 0/801 [00:00<?, ?batch/s]\u001B[A\n",
      "Training batches on cuda:0:   2%|▏         | 19/801 [00:00<00:04, 189.58batch/s]\u001B[A\n",
      "Training batches on cuda:0:   5%|▍         | 39/801 [00:00<00:03, 195.33batch/s]\u001B[A\n",
      "Training batches on cuda:0:   7%|▋         | 60/801 [00:00<00:03, 197.65batch/s]\u001B[A\n",
      "Training batches on cuda:0:  10%|▉         | 80/801 [00:00<00:03, 197.64batch/s]\u001B[A\n",
      "Training batches on cuda:0:  12%|█▏        | 100/801 [00:00<00:03, 198.44batch/s]\u001B[A\n",
      "Training batches on cuda:0:  15%|█▌        | 121/801 [00:00<00:03, 199.03batch/s]\u001B[A\n",
      "Training batches on cuda:0:  18%|█▊        | 142/801 [00:00<00:03, 199.50batch/s]\u001B[A\n",
      "Training batches on cuda:0:  20%|██        | 163/801 [00:00<00:03, 199.79batch/s]\u001B[A\n",
      "Training batches on cuda:0:  23%|██▎       | 183/801 [00:00<00:03, 199.82batch/s]\u001B[A\n",
      "Training batches on cuda:0:  25%|██▌       | 204/801 [00:01<00:02, 200.04batch/s]\u001B[A\n",
      "Training batches on cuda:0:  28%|██▊       | 225/801 [00:01<00:02, 200.12batch/s]\u001B[A\n",
      "Training batches on cuda:0:  31%|███       | 246/801 [00:01<00:02, 200.17batch/s]\u001B[A\n",
      "Training batches on cuda:0:  33%|███▎      | 267/801 [00:01<00:02, 200.20batch/s]\u001B[A\n",
      "Training batches on cuda:0:  36%|███▌      | 288/801 [00:01<00:02, 200.26batch/s]\u001B[A\n",
      "Training batches on cuda:0:  39%|███▊      | 309/801 [00:01<00:02, 200.20batch/s]\u001B[A\n",
      "Training batches on cuda:0:  41%|████      | 330/801 [00:01<00:02, 200.44batch/s]\u001B[A\n",
      "Training batches on cuda:0:  44%|████▍     | 351/801 [00:01<00:02, 200.49batch/s]\u001B[A\n",
      "Training batches on cuda:0:  46%|████▋     | 372/801 [00:01<00:02, 200.63batch/s]\u001B[A\n",
      "Training batches on cuda:0:  49%|████▉     | 393/801 [00:01<00:02, 200.68batch/s]\u001B[A\n",
      "Training batches on cuda:0:  52%|█████▏    | 414/801 [00:02<00:01, 200.69batch/s]\u001B[A\n",
      "Training batches on cuda:0:  54%|█████▍    | 435/801 [00:02<00:01, 200.69batch/s]\u001B[A\n",
      "Training batches on cuda:0:  57%|█████▋    | 456/801 [00:02<00:01, 200.75batch/s]\u001B[A\n",
      "Training batches on cuda:0:  60%|█████▉    | 477/801 [00:02<00:01, 200.73batch/s]\u001B[A\n",
      "Training batches on cuda:0:  62%|██████▏   | 498/801 [00:02<00:01, 200.70batch/s]\u001B[A\n",
      "Training batches on cuda:0:  65%|██████▍   | 519/801 [00:02<00:01, 200.65batch/s]\u001B[A\n",
      "Training batches on cuda:0:  67%|██████▋   | 540/801 [00:02<00:01, 200.58batch/s]\u001B[A\n",
      "Training batches on cuda:0:  70%|███████   | 561/801 [00:02<00:01, 200.46batch/s]\u001B[A\n",
      "Training batches on cuda:0:  73%|███████▎  | 582/801 [00:02<00:01, 200.38batch/s]\u001B[A\n",
      "Training batches on cuda:0:  75%|███████▌  | 603/801 [00:03<00:00, 200.38batch/s]\u001B[A\n",
      "Training batches on cuda:0:  78%|███████▊  | 624/801 [00:03<00:00, 200.41batch/s]\u001B[A\n",
      "Training batches on cuda:0:  81%|████████  | 645/801 [00:03<00:00, 200.31batch/s]\u001B[A\n",
      "Training batches on cuda:0:  83%|████████▎ | 666/801 [00:03<00:00, 200.21batch/s]\u001B[A\n",
      "Training batches on cuda:0:  86%|████████▌ | 687/801 [00:03<00:00, 200.32batch/s]\u001B[A\n",
      "Training batches on cuda:0:  88%|████████▊ | 708/801 [00:03<00:00, 200.31batch/s]\u001B[A\n",
      "Training batches on cuda:0:  91%|█████████ | 729/801 [00:03<00:00, 200.35batch/s]\u001B[A\n",
      "Training batches on cuda:0:  94%|█████████▎| 750/801 [00:03<00:00, 200.27batch/s]\u001B[A\n",
      "Training batches on cuda:0:  96%|█████████▋| 771/801 [00:03<00:00, 200.25batch/s]\u001B[A\n",
      "Training batches on cuda:0:  99%|█████████▉| 792/801 [00:03<00:00, 200.13batch/s]\u001B[A\n",
      "Training epochs on cuda:0:  24%|██▍       | 12/50 [00:50<02:39,  4.20s/epoch, loss=0.831, prev_loss=0.842]\n",
      "Training batches on cuda:0:   0%|          | 0/801 [00:00<?, ?batch/s]\u001B[A\n",
      "Training batches on cuda:0:   2%|▏         | 20/801 [00:00<00:04, 191.68batch/s]\u001B[A\n",
      "Training batches on cuda:0:   5%|▍         | 40/801 [00:00<00:03, 196.45batch/s]\u001B[A\n",
      "Training batches on cuda:0:   8%|▊         | 61/801 [00:00<00:03, 198.32batch/s]\u001B[A\n",
      "Training batches on cuda:0:  10%|█         | 81/801 [00:00<00:03, 197.92batch/s]\u001B[A\n",
      "Training batches on cuda:0:  13%|█▎        | 102/801 [00:00<00:03, 198.83batch/s]\u001B[A\n",
      "Training batches on cuda:0:  15%|█▌        | 123/801 [00:00<00:03, 199.44batch/s]\u001B[A\n",
      "Training batches on cuda:0:  18%|█▊        | 143/801 [00:00<00:03, 199.55batch/s]\u001B[A\n",
      "Training batches on cuda:0:  20%|██        | 164/801 [00:00<00:03, 199.85batch/s]\u001B[A\n",
      "Training batches on cuda:0:  23%|██▎       | 185/801 [00:00<00:03, 200.08batch/s]\u001B[A\n",
      "Training batches on cuda:0:  26%|██▌       | 206/801 [00:01<00:02, 200.15batch/s]\u001B[A\n",
      "Training batches on cuda:0:  28%|██▊       | 227/801 [00:01<00:02, 200.26batch/s]\u001B[A\n",
      "Training batches on cuda:0:  31%|███       | 248/801 [00:01<00:02, 200.16batch/s]\u001B[A\n",
      "Training batches on cuda:0:  34%|███▎      | 269/801 [00:01<00:02, 199.66batch/s]\u001B[A\n",
      "Training batches on cuda:0:  36%|███▌      | 289/801 [00:01<00:02, 198.50batch/s]\u001B[A\n",
      "Training batches on cuda:0:  39%|███▊      | 309/801 [00:01<00:02, 198.67batch/s]\u001B[A\n",
      "Training batches on cuda:0:  41%|████      | 330/801 [00:01<00:02, 199.18batch/s]\u001B[A\n",
      "Training batches on cuda:0:  44%|████▍     | 351/801 [00:01<00:02, 199.55batch/s]\u001B[A\n",
      "Training batches on cuda:0:  46%|████▋     | 371/801 [00:01<00:02, 199.53batch/s]\u001B[A\n",
      "Training batches on cuda:0:  49%|████▉     | 392/801 [00:01<00:02, 199.78batch/s]\u001B[A\n",
      "Training batches on cuda:0:  51%|█████▏    | 412/801 [00:02<00:01, 199.84batch/s]\u001B[A\n",
      "Training batches on cuda:0:  54%|█████▍    | 433/801 [00:02<00:01, 200.19batch/s]\u001B[A\n",
      "Training batches on cuda:0:  57%|█████▋    | 454/801 [00:02<00:01, 200.19batch/s]\u001B[A\n",
      "Training batches on cuda:0:  59%|█████▉    | 475/801 [00:02<00:01, 200.26batch/s]\u001B[A\n",
      "Training batches on cuda:0:  62%|██████▏   | 496/801 [00:02<00:01, 200.30batch/s]\u001B[A\n",
      "Training batches on cuda:0:  65%|██████▍   | 517/801 [00:02<00:01, 200.42batch/s]\u001B[A\n",
      "Training batches on cuda:0:  67%|██████▋   | 538/801 [00:02<00:01, 200.46batch/s]\u001B[A\n",
      "Training batches on cuda:0:  70%|██████▉   | 559/801 [00:02<00:01, 200.56batch/s]\u001B[A\n",
      "Training batches on cuda:0:  72%|███████▏  | 580/801 [00:02<00:01, 200.28batch/s]\u001B[A\n",
      "Training batches on cuda:0:  75%|███████▌  | 601/801 [00:03<00:00, 200.40batch/s]\u001B[A\n",
      "Training batches on cuda:0:  78%|███████▊  | 622/801 [00:03<00:00, 200.50batch/s]\u001B[A\n",
      "Training batches on cuda:0:  80%|████████  | 643/801 [00:03<00:00, 200.58batch/s]\u001B[A\n",
      "Training batches on cuda:0:  83%|████████▎ | 664/801 [00:03<00:00, 200.50batch/s]\u001B[A\n",
      "Training batches on cuda:0:  86%|████████▌ | 685/801 [00:03<00:00, 200.29batch/s]\u001B[A\n",
      "Training batches on cuda:0:  88%|████████▊ | 706/801 [00:03<00:00, 200.08batch/s]\u001B[A\n",
      "Training batches on cuda:0:  91%|█████████ | 727/801 [00:03<00:00, 200.10batch/s]\u001B[A\n",
      "Training batches on cuda:0:  93%|█████████▎| 748/801 [00:03<00:00, 199.96batch/s]\u001B[A\n",
      "Training batches on cuda:0:  96%|█████████▌| 768/801 [00:03<00:00, 199.89batch/s]\u001B[A\n",
      "Training batches on cuda:0:  99%|█████████▊| 789/801 [00:03<00:00, 200.07batch/s]\u001B[A\n",
      "Training epochs on cuda:0:  26%|██▌       | 13/50 [00:54<02:35,  4.19s/epoch, loss=0.823, prev_loss=0.831]\n",
      "Training batches on cuda:0:   0%|          | 0/801 [00:00<?, ?batch/s]\u001B[A\n",
      "Training batches on cuda:0:   2%|▏         | 20/801 [00:00<00:04, 191.41batch/s]\u001B[A\n",
      "Training batches on cuda:0:   5%|▍         | 40/801 [00:00<00:03, 196.12batch/s]\u001B[A\n",
      "Training batches on cuda:0:   8%|▊         | 61/801 [00:00<00:03, 198.09batch/s]\u001B[A\n",
      "Training batches on cuda:0:  10%|█         | 81/801 [00:00<00:03, 198.27batch/s]\u001B[A\n",
      "Training batches on cuda:0:  13%|█▎        | 102/801 [00:00<00:03, 199.22batch/s]\u001B[A\n",
      "Training batches on cuda:0:  15%|█▌        | 122/801 [00:00<00:03, 198.19batch/s]\u001B[A\n",
      "Training batches on cuda:0:  18%|█▊        | 143/801 [00:00<00:03, 199.02batch/s]\u001B[A\n",
      "Training batches on cuda:0:  20%|██        | 164/801 [00:00<00:03, 199.53batch/s]\u001B[A\n",
      "Training batches on cuda:0:  23%|██▎       | 184/801 [00:00<00:03, 196.02batch/s]\u001B[A\n",
      "Training batches on cuda:0:  26%|██▌       | 205/801 [00:01<00:03, 197.48batch/s]\u001B[A\n",
      "Training batches on cuda:0:  28%|██▊       | 226/801 [00:01<00:02, 198.40batch/s]\u001B[A\n",
      "Training batches on cuda:0:  31%|███       | 247/801 [00:01<00:02, 199.10batch/s]\u001B[A\n",
      "Training batches on cuda:0:  33%|███▎      | 268/801 [00:01<00:02, 199.50batch/s]\u001B[A\n",
      "Training batches on cuda:0:  36%|███▌      | 289/801 [00:01<00:02, 199.89batch/s]\u001B[A\n",
      "Training batches on cuda:0:  39%|███▊      | 310/801 [00:01<00:02, 200.05batch/s]\u001B[A\n",
      "Training batches on cuda:0:  41%|████▏     | 331/801 [00:01<00:02, 200.26batch/s]\u001B[A\n",
      "Training batches on cuda:0:  44%|████▍     | 352/801 [00:01<00:02, 200.38batch/s]\u001B[A\n",
      "Training batches on cuda:0:  47%|████▋     | 373/801 [00:01<00:02, 200.39batch/s]\u001B[A\n",
      "Training batches on cuda:0:  49%|████▉     | 394/801 [00:01<00:02, 200.48batch/s]\u001B[A\n",
      "Training batches on cuda:0:  52%|█████▏    | 415/801 [00:02<00:01, 200.54batch/s]\u001B[A\n",
      "Training batches on cuda:0:  54%|█████▍    | 436/801 [00:02<00:01, 200.50batch/s]\u001B[A\n",
      "Training batches on cuda:0:  57%|█████▋    | 457/801 [00:02<00:01, 200.50batch/s]\u001B[A\n",
      "Training batches on cuda:0:  60%|█████▉    | 478/801 [00:02<00:01, 200.48batch/s]\u001B[A\n",
      "Training batches on cuda:0:  62%|██████▏   | 499/801 [00:02<00:01, 200.47batch/s]\u001B[A\n",
      "Training batches on cuda:0:  65%|██████▍   | 520/801 [00:02<00:01, 200.42batch/s]\u001B[A\n",
      "Training batches on cuda:0:  68%|██████▊   | 541/801 [00:02<00:01, 200.47batch/s]\u001B[A\n",
      "Training batches on cuda:0:  70%|███████   | 562/801 [00:02<00:01, 200.54batch/s]\u001B[A\n",
      "Training batches on cuda:0:  73%|███████▎  | 583/801 [00:02<00:01, 200.57batch/s]\u001B[A\n",
      "Training batches on cuda:0:  75%|███████▌  | 604/801 [00:03<00:00, 200.59batch/s]\u001B[A\n",
      "Training batches on cuda:0:  78%|███████▊  | 625/801 [00:03<00:00, 200.59batch/s]\u001B[A\n",
      "Training batches on cuda:0:  81%|████████  | 646/801 [00:03<00:00, 200.62batch/s]\u001B[A\n",
      "Training batches on cuda:0:  83%|████████▎ | 667/801 [00:03<00:00, 200.65batch/s]\u001B[A\n",
      "Training batches on cuda:0:  86%|████████▌ | 688/801 [00:03<00:00, 198.58batch/s]\u001B[A\n",
      "Training batches on cuda:0:  89%|████████▊ | 709/801 [00:03<00:00, 199.11batch/s]\u001B[A\n",
      "Training batches on cuda:0:  91%|█████████ | 730/801 [00:03<00:00, 199.57batch/s]\u001B[A\n",
      "Training batches on cuda:0:  94%|█████████▎| 750/801 [00:03<00:00, 199.67batch/s]\u001B[A\n",
      "Training batches on cuda:0:  96%|█████████▋| 771/801 [00:03<00:00, 199.93batch/s]\u001B[A\n",
      "Training batches on cuda:0:  99%|█████████▉| 792/801 [00:03<00:00, 200.19batch/s]\u001B[A\n",
      "Training epochs on cuda:0:  28%|██▊       | 14/50 [00:58<02:30,  4.19s/epoch, loss=0.815, prev_loss=0.823]\n",
      "Training batches on cuda:0:   0%|          | 0/801 [00:00<?, ?batch/s]\u001B[A\n",
      "Training batches on cuda:0:   2%|▏         | 19/801 [00:00<00:04, 189.57batch/s]\u001B[A\n",
      "Training batches on cuda:0:   5%|▍         | 40/801 [00:00<00:03, 196.16batch/s]\u001B[A\n",
      "Training batches on cuda:0:   8%|▊         | 61/801 [00:00<00:03, 198.13batch/s]\u001B[A\n",
      "Training batches on cuda:0:  10%|█         | 81/801 [00:00<00:03, 198.09batch/s]\u001B[A\n",
      "Training batches on cuda:0:  13%|█▎        | 102/801 [00:00<00:03, 198.98batch/s]\u001B[A\n",
      "Training batches on cuda:0:  15%|█▌        | 122/801 [00:00<00:03, 198.44batch/s]\u001B[A\n",
      "Training batches on cuda:0:  18%|█▊        | 142/801 [00:00<00:03, 195.80batch/s]\u001B[A\n",
      "Training batches on cuda:0:  20%|██        | 163/801 [00:00<00:03, 197.41batch/s]\u001B[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  23%|██▎       | 184/801 [00:00<00:03, 198.51batch/s]\u001B[A\n",
      "Training batches on cuda:0:  26%|██▌       | 205/801 [00:01<00:02, 199.28batch/s]\u001B[A\n",
      "Training batches on cuda:0:  28%|██▊       | 226/801 [00:01<00:02, 199.65batch/s]\u001B[A\n",
      "Training batches on cuda:0:  31%|███       | 247/801 [00:01<00:02, 200.07batch/s]\u001B[A\n",
      "Training batches on cuda:0:  33%|███▎      | 268/801 [00:01<00:02, 200.16batch/s]\u001B[A\n",
      "Training batches on cuda:0:  36%|███▌      | 289/801 [00:01<00:02, 200.29batch/s]\u001B[A\n",
      "Training batches on cuda:0:  39%|███▊      | 310/801 [00:01<00:02, 200.51batch/s]\u001B[A\n",
      "Training batches on cuda:0:  41%|████▏     | 331/801 [00:01<00:02, 200.73batch/s]\u001B[A\n",
      "Training batches on cuda:0:  44%|████▍     | 352/801 [00:01<00:02, 200.86batch/s]\u001B[A\n",
      "Training batches on cuda:0:  47%|████▋     | 373/801 [00:01<00:02, 200.91batch/s]\u001B[A\n",
      "Training batches on cuda:0:  49%|████▉     | 394/801 [00:01<00:02, 200.73batch/s]\u001B[A\n",
      "Training batches on cuda:0:  52%|█████▏    | 415/801 [00:02<00:01, 200.74batch/s]\u001B[A\n",
      "Training batches on cuda:0:  54%|█████▍    | 436/801 [00:02<00:01, 200.63batch/s]\u001B[A\n",
      "Training batches on cuda:0:  57%|█████▋    | 457/801 [00:02<00:01, 200.58batch/s]\u001B[A\n",
      "Training batches on cuda:0:  60%|█████▉    | 478/801 [00:02<00:01, 200.37batch/s]\u001B[A\n",
      "Training batches on cuda:0:  62%|██████▏   | 499/801 [00:02<00:01, 200.45batch/s]\u001B[A\n",
      "Training batches on cuda:0:  65%|██████▍   | 520/801 [00:02<00:01, 200.59batch/s]\u001B[A\n",
      "Training batches on cuda:0:  68%|██████▊   | 541/801 [00:02<00:01, 200.59batch/s]\u001B[A\n",
      "Training batches on cuda:0:  70%|███████   | 562/801 [00:02<00:01, 200.75batch/s]\u001B[A\n",
      "Training batches on cuda:0:  73%|███████▎  | 583/801 [00:02<00:01, 200.79batch/s]\u001B[A\n",
      "Training batches on cuda:0:  75%|███████▌  | 604/801 [00:03<00:00, 200.75batch/s]\u001B[A\n",
      "Training batches on cuda:0:  78%|███████▊  | 625/801 [00:03<00:00, 200.77batch/s]\u001B[A\n",
      "Training batches on cuda:0:  81%|████████  | 646/801 [00:03<00:00, 200.78batch/s]\u001B[A\n",
      "Training batches on cuda:0:  83%|████████▎ | 667/801 [00:03<00:00, 200.80batch/s]\u001B[A\n",
      "Training batches on cuda:0:  86%|████████▌ | 688/801 [00:03<00:00, 200.76batch/s]\u001B[A\n",
      "Training batches on cuda:0:  89%|████████▊ | 709/801 [00:03<00:00, 200.85batch/s]\u001B[A\n",
      "Training batches on cuda:0:  91%|█████████ | 730/801 [00:03<00:00, 200.80batch/s]\u001B[A\n",
      "Training batches on cuda:0:  94%|█████████▍| 751/801 [00:03<00:00, 200.85batch/s]\u001B[A\n",
      "Training batches on cuda:0:  96%|█████████▋| 772/801 [00:03<00:00, 200.81batch/s]\u001B[A\n",
      "Training batches on cuda:0:  99%|█████████▉| 793/801 [00:03<00:00, 200.82batch/s]\u001B[A\n",
      "Training epochs on cuda:0:  30%|███       | 15/50 [01:02<02:26,  4.18s/epoch, loss=0.78, prev_loss=0.815] \n",
      "Training batches on cuda:0:   0%|          | 0/801 [00:00<?, ?batch/s]\u001B[A\n",
      "Training batches on cuda:0:   2%|▏         | 20/801 [00:00<00:04, 191.40batch/s]\u001B[A\n",
      "Training batches on cuda:0:   5%|▍         | 40/801 [00:00<00:03, 196.26batch/s]\u001B[A\n",
      "Training batches on cuda:0:   8%|▊         | 61/801 [00:00<00:03, 198.32batch/s]\u001B[A\n",
      "Training batches on cuda:0:  10%|█         | 81/801 [00:00<00:03, 198.38batch/s]\u001B[A\n",
      "Training batches on cuda:0:  13%|█▎        | 102/801 [00:00<00:03, 199.08batch/s]\u001B[A\n",
      "Training batches on cuda:0:  15%|█▌        | 123/801 [00:00<00:03, 199.74batch/s]\u001B[A\n",
      "Training batches on cuda:0:  18%|█▊        | 144/801 [00:00<00:03, 200.16batch/s]\u001B[A\n",
      "Training batches on cuda:0:  21%|██        | 165/801 [00:00<00:03, 200.32batch/s]\u001B[A\n",
      "Training batches on cuda:0:  23%|██▎       | 186/801 [00:00<00:03, 200.51batch/s]\u001B[A\n",
      "Training batches on cuda:0:  26%|██▌       | 207/801 [00:01<00:02, 200.54batch/s]\u001B[A\n",
      "Training batches on cuda:0:  28%|██▊       | 228/801 [00:01<00:02, 200.68batch/s]\u001B[A\n",
      "Training batches on cuda:0:  31%|███       | 249/801 [00:01<00:02, 200.75batch/s]\u001B[A\n",
      "Training batches on cuda:0:  34%|███▎      | 270/801 [00:01<00:02, 200.75batch/s]\u001B[A\n",
      "Training batches on cuda:0:  36%|███▋      | 291/801 [00:01<00:02, 200.81batch/s]\u001B[A\n",
      "Training batches on cuda:0:  39%|███▉      | 312/801 [00:01<00:02, 200.86batch/s]\u001B[A\n",
      "Training batches on cuda:0:  42%|████▏     | 333/801 [00:01<00:02, 200.85batch/s]\u001B[A\n",
      "Training batches on cuda:0:  44%|████▍     | 354/801 [00:01<00:02, 200.83batch/s]\u001B[A\n",
      "Training batches on cuda:0:  47%|████▋     | 375/801 [00:01<00:02, 199.65batch/s]\u001B[A\n",
      "Training batches on cuda:0:  49%|████▉     | 396/801 [00:01<00:02, 200.98batch/s]\u001B[A\n",
      "Training batches on cuda:0:  52%|█████▏    | 417/801 [00:02<00:01, 197.82batch/s]\u001B[A\n",
      "Training batches on cuda:0:  55%|█████▍    | 438/801 [00:02<00:01, 198.67batch/s]\u001B[A\n",
      "Training batches on cuda:0:  57%|█████▋    | 459/801 [00:02<00:01, 199.29batch/s]\u001B[A\n",
      "Training batches on cuda:0:  60%|█████▉    | 479/801 [00:02<00:01, 197.48batch/s]\u001B[A\n",
      "Training batches on cuda:0:  62%|██████▏   | 499/801 [00:02<00:01, 187.37batch/s]\u001B[A\n",
      "Training batches on cuda:0:  65%|██████▍   | 518/801 [00:02<00:01, 162.79batch/s]\u001B[A\n",
      "Training batches on cuda:0:  67%|██████▋   | 535/801 [00:02<00:01, 148.47batch/s]\u001B[A\n",
      "Training batches on cuda:0:  69%|██████▉   | 551/801 [00:02<00:01, 141.76batch/s]\u001B[A\n",
      "Training batches on cuda:0:  71%|███████   | 566/801 [00:03<00:01, 137.05batch/s]\u001B[A\n",
      "Training batches on cuda:0:  72%|███████▏  | 580/801 [00:03<00:01, 132.76batch/s]\u001B[A\n",
      "Training batches on cuda:0:  74%|███████▍  | 594/801 [00:03<00:01, 131.95batch/s]\u001B[A\n",
      "Training batches on cuda:0:  76%|███████▌  | 608/801 [00:03<00:01, 129.46batch/s]\u001B[A\n",
      "Training batches on cuda:0:  78%|███████▊  | 621/801 [00:03<00:01, 128.81batch/s]\u001B[A\n",
      "Training batches on cuda:0:  79%|███████▉  | 634/801 [00:03<00:01, 128.87batch/s]\u001B[A\n",
      "Training batches on cuda:0:  81%|████████  | 648/801 [00:03<00:01, 131.01batch/s]\u001B[A\n",
      "Training batches on cuda:0:  84%|████████▎ | 669/801 [00:03<00:00, 151.75batch/s]\u001B[A\n",
      "Training batches on cuda:0:  86%|████████▌ | 690/801 [00:03<00:00, 166.50batch/s]\u001B[A\n",
      "Training batches on cuda:0:  89%|████████▉ | 711/801 [00:04<00:00, 176.98batch/s]\u001B[A\n",
      "Training batches on cuda:0:  91%|█████████▏| 732/801 [00:04<00:00, 184.40batch/s]\u001B[A\n",
      "Training batches on cuda:0:  94%|█████████▍| 753/801 [00:04<00:00, 189.57batch/s]\u001B[A\n",
      "Training batches on cuda:0:  97%|█████████▋| 773/801 [00:04<00:00, 191.87batch/s]\u001B[A\n",
      "Training batches on cuda:0:  99%|█████████▉| 794/801 [00:04<00:00, 194.90batch/s]\u001B[A\n",
      "Training epochs on cuda:0:  32%|███▏      | 16/50 [01:07<02:26,  4.32s/epoch, loss=0.664, prev_loss=0.78]\n",
      "Training batches on cuda:0:   0%|          | 0/801 [00:00<?, ?batch/s]\u001B[A\n",
      "Training batches on cuda:0:   2%|▏         | 19/801 [00:00<00:04, 186.15batch/s]\u001B[A\n",
      "Training batches on cuda:0:   5%|▍         | 40/801 [00:00<00:03, 195.75batch/s]\u001B[A\n",
      "Training batches on cuda:0:   8%|▊         | 61/801 [00:00<00:03, 199.63batch/s]\u001B[A\n",
      "Training batches on cuda:0:  10%|█         | 82/801 [00:00<00:03, 200.12batch/s]\u001B[A\n",
      "Training batches on cuda:0:  13%|█▎        | 103/801 [00:00<00:03, 200.67batch/s]\u001B[A\n",
      "Training batches on cuda:0:  15%|█▌        | 124/801 [00:00<00:03, 200.90batch/s]\u001B[A\n",
      "Training batches on cuda:0:  18%|█▊        | 145/801 [00:00<00:03, 201.56batch/s]\u001B[A\n",
      "Training batches on cuda:0:  21%|██        | 166/801 [00:00<00:03, 201.45batch/s]\u001B[A\n",
      "Training batches on cuda:0:  23%|██▎       | 187/801 [00:00<00:03, 202.79batch/s]\u001B[A\n",
      "Training batches on cuda:0:  26%|██▌       | 208/801 [00:01<00:02, 203.14batch/s]\u001B[A\n",
      "Training batches on cuda:0:  29%|██▊       | 229/801 [00:01<00:02, 203.02batch/s]\u001B[A\n",
      "Training batches on cuda:0:  31%|███       | 250/801 [00:01<00:02, 202.03batch/s]\u001B[A\n",
      "Training batches on cuda:0:  34%|███▍      | 271/801 [00:01<00:02, 201.74batch/s]\u001B[A\n",
      "Training batches on cuda:0:  36%|███▋      | 292/801 [00:01<00:02, 199.18batch/s]\u001B[A\n",
      "Training batches on cuda:0:  39%|███▉      | 313/801 [00:01<00:02, 199.53batch/s]\u001B[A\n",
      "Training batches on cuda:0:  42%|████▏     | 333/801 [00:01<00:02, 199.13batch/s]\u001B[A\n",
      "Training batches on cuda:0:  44%|████▍     | 353/801 [00:01<00:02, 199.14batch/s]\u001B[A\n",
      "Training batches on cuda:0:  47%|████▋     | 373/801 [00:01<00:02, 197.75batch/s]\u001B[A\n",
      "Training batches on cuda:0:  49%|████▉     | 393/801 [00:01<00:02, 197.50batch/s]\u001B[A\n",
      "Training batches on cuda:0:  52%|█████▏    | 413/801 [00:02<00:01, 198.09batch/s]\u001B[A\n",
      "Training batches on cuda:0:  54%|█████▍    | 433/801 [00:02<00:02, 155.21batch/s]\u001B[A\n",
      "Training batches on cuda:0:  57%|█████▋    | 453/801 [00:02<00:02, 166.08batch/s]\u001B[A\n",
      "Training batches on cuda:0:  59%|█████▉    | 473/801 [00:02<00:01, 173.99batch/s]\u001B[A\n",
      "Training batches on cuda:0:  61%|██████▏   | 492/801 [00:02<00:01, 175.33batch/s]\u001B[A\n",
      "Training batches on cuda:0:  64%|██████▍   | 511/801 [00:02<00:01, 172.71batch/s]\u001B[A\n",
      "Training batches on cuda:0:  66%|██████▋   | 531/801 [00:02<00:01, 180.02batch/s]\u001B[A\n",
      "Training batches on cuda:0:  69%|██████▉   | 551/801 [00:02<00:01, 185.55batch/s]\u001B[A\n",
      "Training batches on cuda:0:  71%|███████▏  | 571/801 [00:02<00:01, 188.25batch/s]\u001B[A\n",
      "Training batches on cuda:0:  74%|███████▍  | 592/801 [00:03<00:01, 192.06batch/s]\u001B[A\n",
      "Training batches on cuda:0:  76%|███████▋  | 612/801 [00:03<00:00, 192.80batch/s]\u001B[A\n",
      "Training batches on cuda:0:  79%|███████▉  | 633/801 [00:03<00:00, 195.63batch/s]\u001B[A\n",
      "Training batches on cuda:0:  82%|████████▏ | 654/801 [00:03<00:00, 197.94batch/s]\u001B[A\n",
      "Training batches on cuda:0:  84%|████████▍ | 675/801 [00:03<00:00, 199.28batch/s]\u001B[A\n",
      "Training batches on cuda:0:  87%|████████▋ | 696/801 [00:03<00:00, 200.24batch/s]\u001B[A\n",
      "Training batches on cuda:0:  90%|████████▉ | 717/801 [00:03<00:00, 201.26batch/s]\u001B[A\n",
      "Training batches on cuda:0:  92%|█████████▏| 738/801 [00:03<00:00, 201.72batch/s]\u001B[A\n",
      "Training batches on cuda:0:  95%|█████████▍| 759/801 [00:03<00:00, 202.05batch/s]\u001B[A\n",
      "Training batches on cuda:0:  97%|█████████▋| 780/801 [00:04<00:00, 202.16batch/s]\u001B[A\n",
      "Training batches on cuda:0: 100%|██████████| 801/801 [00:04<00:00, 187.43batch/s]\u001B[A\n",
      "Training epochs on cuda:0:  34%|███▍      | 17/50 [01:11<02:22,  4.32s/epoch, loss=0.58, prev_loss=0.664]\n",
      "Training batches on cuda:0:   0%|          | 0/801 [00:00<?, ?batch/s]\u001B[A\n",
      "Training batches on cuda:0:   2%|▏         | 19/801 [00:00<00:04, 187.46batch/s]\u001B[A\n",
      "Training batches on cuda:0:   5%|▍         | 40/801 [00:00<00:03, 196.30batch/s]\u001B[A\n",
      "Training batches on cuda:0:   8%|▊         | 61/801 [00:00<00:03, 198.98batch/s]\u001B[A\n",
      "Training batches on cuda:0:  10%|█         | 82/801 [00:00<00:03, 199.54batch/s]\u001B[A\n",
      "Training batches on cuda:0:  13%|█▎        | 102/801 [00:00<00:04, 171.55batch/s]\u001B[A\n",
      "Training batches on cuda:0:  15%|█▌        | 122/801 [00:00<00:03, 180.03batch/s]\u001B[A\n",
      "Training batches on cuda:0:  18%|█▊        | 142/801 [00:00<00:03, 186.02batch/s]\u001B[A\n",
      "Training batches on cuda:0:  20%|██        | 163/801 [00:00<00:03, 190.48batch/s]\u001B[A\n",
      "Training batches on cuda:0:  23%|██▎       | 183/801 [00:00<00:03, 193.29batch/s]\u001B[A\n",
      "Training batches on cuda:0:  25%|██▌       | 204/801 [00:01<00:03, 195.43batch/s]\u001B[A\n",
      "Training batches on cuda:0:  28%|██▊       | 224/801 [00:01<00:02, 196.71batch/s]\u001B[A\n",
      "Training batches on cuda:0:  31%|███       | 245/801 [00:01<00:02, 197.78batch/s]\u001B[A\n",
      "Training batches on cuda:0:  33%|███▎      | 265/801 [00:01<00:02, 197.41batch/s]\u001B[A\n",
      "Training batches on cuda:0:  36%|███▌      | 285/801 [00:01<00:02, 197.08batch/s]\u001B[A\n",
      "Training batches on cuda:0:  38%|███▊      | 305/801 [00:01<00:02, 197.88batch/s]\u001B[A\n",
      "Training batches on cuda:0:  41%|████      | 325/801 [00:01<00:02, 198.38batch/s]\u001B[A\n",
      "Training batches on cuda:0:  43%|████▎     | 345/801 [00:01<00:02, 198.75batch/s]\u001B[A\n",
      "Training batches on cuda:0:  46%|████▌     | 365/801 [00:01<00:02, 198.82batch/s]\u001B[A\n",
      "Training batches on cuda:0:  48%|████▊     | 385/801 [00:01<00:02, 198.98batch/s]\u001B[A\n",
      "Training batches on cuda:0:  51%|█████     | 405/801 [00:02<00:01, 199.09batch/s]\u001B[A\n",
      "Training batches on cuda:0:  53%|█████▎    | 425/801 [00:02<00:01, 199.12batch/s]\u001B[A\n",
      "Training batches on cuda:0:  56%|█████▌    | 445/801 [00:02<00:01, 198.33batch/s]\u001B[A\n",
      "Training batches on cuda:0:  58%|█████▊    | 465/801 [00:02<00:01, 197.20batch/s]\u001B[A\n",
      "Training batches on cuda:0:  61%|██████    | 485/801 [00:02<00:01, 196.52batch/s]\u001B[A\n",
      "Training batches on cuda:0:  63%|██████▎   | 506/801 [00:02<00:01, 197.66batch/s]\u001B[A\n",
      "Training batches on cuda:0:  66%|██████▌   | 526/801 [00:02<00:01, 198.06batch/s]\u001B[A\n",
      "Training batches on cuda:0:  68%|██████▊   | 547/801 [00:02<00:01, 198.82batch/s]\u001B[A\n",
      "Training batches on cuda:0:  71%|███████   | 567/801 [00:02<00:01, 198.88batch/s]\u001B[A\n",
      "Training batches on cuda:0:  73%|███████▎  | 588/801 [00:03<00:01, 199.24batch/s]\u001B[A\n",
      "Training batches on cuda:0:  76%|███████▌  | 608/801 [00:03<00:00, 199.38batch/s]\u001B[A\n",
      "Training batches on cuda:0:  79%|███████▊  | 629/801 [00:03<00:00, 199.65batch/s]\u001B[A\n",
      "Training batches on cuda:0:  81%|████████  | 649/801 [00:03<00:00, 198.22batch/s]\u001B[A\n",
      "Training batches on cuda:0:  84%|████████▎ | 669/801 [00:03<00:00, 197.49batch/s]\u001B[A\n",
      "Training batches on cuda:0:  86%|████████▌ | 689/801 [00:03<00:00, 197.43batch/s]\u001B[A\n",
      "Training batches on cuda:0:  89%|████████▊ | 710/801 [00:03<00:00, 198.35batch/s]\u001B[A\n",
      "Training batches on cuda:0:  91%|█████████ | 730/801 [00:03<00:00, 198.81batch/s]\u001B[A\n",
      "Training batches on cuda:0:  94%|█████████▎| 750/801 [00:03<00:00, 198.80batch/s]\u001B[A\n",
      "Training batches on cuda:0:  96%|█████████▌| 770/801 [00:03<00:00, 199.09batch/s]\u001B[A\n",
      "Training batches on cuda:0:  99%|█████████▉| 791/801 [00:04<00:00, 199.44batch/s]\u001B[A\n",
      "Training epochs on cuda:0:  36%|███▌      | 18/50 [01:15<02:17,  4.30s/epoch, loss=0.525, prev_loss=0.58]\n",
      "Training batches on cuda:0:   0%|          | 0/801 [00:00<?, ?batch/s]\u001B[A\n",
      "Training batches on cuda:0:   2%|▏         | 15/801 [00:00<00:05, 148.02batch/s]\u001B[A\n",
      "Training batches on cuda:0:   4%|▍         | 35/801 [00:00<00:04, 175.50batch/s]\u001B[A\n",
      "Training batches on cuda:0:   7%|▋         | 55/801 [00:00<00:04, 185.70batch/s]\u001B[A\n",
      "Training batches on cuda:0:   9%|▉         | 75/801 [00:00<00:03, 190.53batch/s]\u001B[A\n",
      "Training batches on cuda:0:  12%|█▏        | 95/801 [00:00<00:03, 193.85batch/s]\u001B[A\n",
      "Training batches on cuda:0:  14%|█▍        | 115/801 [00:00<00:03, 195.67batch/s]\u001B[A\n",
      "Training batches on cuda:0:  17%|█▋        | 135/801 [00:00<00:03, 196.85batch/s]\u001B[A\n",
      "Training batches on cuda:0:  19%|█▉        | 155/801 [00:00<00:03, 197.58batch/s]\u001B[A\n",
      "Training batches on cuda:0:  22%|██▏       | 175/801 [00:00<00:03, 198.30batch/s]\u001B[A\n",
      "Training batches on cuda:0:  24%|██▍       | 195/801 [00:01<00:03, 198.09batch/s]\u001B[A\n",
      "Training batches on cuda:0:  27%|██▋       | 215/801 [00:01<00:02, 196.94batch/s]\u001B[A\n",
      "Training batches on cuda:0:  29%|██▉       | 235/801 [00:01<00:02, 196.41batch/s]\u001B[A\n",
      "Training batches on cuda:0:  32%|███▏      | 255/801 [00:01<00:02, 197.13batch/s]\u001B[A\n",
      "Training batches on cuda:0:  34%|███▍      | 275/801 [00:01<00:02, 197.91batch/s]\u001B[A\n",
      "Training batches on cuda:0:  37%|███▋      | 296/801 [00:01<00:02, 198.73batch/s]\u001B[A\n",
      "Training batches on cuda:0:  39%|███▉      | 316/801 [00:01<00:02, 198.65batch/s]\u001B[A\n",
      "Training batches on cuda:0:  42%|████▏     | 336/801 [00:01<00:02, 198.90batch/s]\u001B[A\n",
      "Training batches on cuda:0:  45%|████▍     | 357/801 [00:01<00:02, 199.46batch/s]\u001B[A\n",
      "Training batches on cuda:0:  47%|████▋     | 377/801 [00:01<00:02, 199.39batch/s]\u001B[A\n",
      "Training batches on cuda:0:  50%|████▉     | 397/801 [00:02<00:02, 198.51batch/s]\u001B[A\n",
      "Training batches on cuda:0:  52%|█████▏    | 417/801 [00:02<00:01, 197.72batch/s]\u001B[A\n",
      "Training batches on cuda:0:  55%|█████▍    | 437/801 [00:02<00:01, 196.85batch/s]\u001B[A\n",
      "Training batches on cuda:0:  57%|█████▋    | 457/801 [00:02<00:01, 197.71batch/s]\u001B[A\n",
      "Training batches on cuda:0:  60%|█████▉    | 478/801 [00:02<00:01, 198.55batch/s]\u001B[A\n",
      "Training batches on cuda:0:  62%|██████▏   | 499/801 [00:02<00:01, 199.02batch/s]\u001B[A\n",
      "Training batches on cuda:0:  65%|██████▍   | 519/801 [00:02<00:01, 199.12batch/s]\u001B[A\n",
      "Training batches on cuda:0:  67%|██████▋   | 540/801 [00:02<00:01, 199.53batch/s]\u001B[A\n",
      "Training batches on cuda:0:  70%|██████▉   | 560/801 [00:02<00:01, 199.30batch/s]\u001B[A\n",
      "Training batches on cuda:0:  72%|███████▏  | 580/801 [00:02<00:01, 199.30batch/s]\u001B[A\n",
      "Training batches on cuda:0:  75%|███████▍  | 600/801 [00:03<00:01, 198.00batch/s]\u001B[A\n",
      "Training batches on cuda:0:  77%|███████▋  | 620/801 [00:03<00:00, 197.96batch/s]\u001B[A\n",
      "Training batches on cuda:0:  80%|███████▉  | 640/801 [00:03<00:00, 197.49batch/s]\u001B[A\n",
      "Training batches on cuda:0:  82%|████████▏ | 660/801 [00:03<00:00, 198.15batch/s]\u001B[A\n",
      "Training batches on cuda:0:  85%|████████▍ | 680/801 [00:03<00:00, 198.35batch/s]\u001B[A\n",
      "Training batches on cuda:0:  87%|████████▋ | 700/801 [00:03<00:00, 198.71batch/s]\u001B[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  90%|████████▉ | 720/801 [00:03<00:00, 198.67batch/s]\u001B[A\n",
      "Training batches on cuda:0:  92%|█████████▏| 740/801 [00:03<00:00, 198.81batch/s]\u001B[A\n",
      "Training batches on cuda:0:  95%|█████████▍| 760/801 [00:03<00:00, 167.20batch/s]\u001B[A\n",
      "Training batches on cuda:0:  97%|█████████▋| 780/801 [00:04<00:00, 175.15batch/s]\u001B[A\n",
      "Training batches on cuda:0: 100%|█████████▉| 800/801 [00:04<00:00, 181.55batch/s]\u001B[A\n",
      "Training epochs on cuda:0:  38%|███▊      | 19/50 [01:20<02:13,  4.30s/epoch, loss=0.471, prev_loss=0.525]\n",
      "Training batches on cuda:0:   0%|          | 0/801 [00:00<?, ?batch/s]\u001B[A\n",
      "Training batches on cuda:0:   2%|▏         | 19/801 [00:00<00:04, 183.46batch/s]\u001B[A\n",
      "Training batches on cuda:0:   5%|▍         | 40/801 [00:00<00:03, 193.60batch/s]\u001B[A\n",
      "Training batches on cuda:0:   8%|▊         | 61/801 [00:00<00:03, 196.74batch/s]\u001B[A\n",
      "Training batches on cuda:0:  10%|█         | 81/801 [00:00<00:03, 197.32batch/s]\u001B[A\n",
      "Training batches on cuda:0:  13%|█▎        | 102/801 [00:00<00:03, 198.84batch/s]\u001B[A\n",
      "Training batches on cuda:0:  15%|█▌        | 123/801 [00:00<00:03, 199.63batch/s]\u001B[A\n",
      "Training batches on cuda:0:  18%|█▊        | 144/801 [00:00<00:03, 199.91batch/s]\u001B[A\n",
      "Training batches on cuda:0:  20%|██        | 164/801 [00:00<00:03, 199.73batch/s]\u001B[A\n",
      "Training batches on cuda:0:  23%|██▎       | 184/801 [00:00<00:03, 199.53batch/s]\u001B[A\n",
      "Training batches on cuda:0:  26%|██▌       | 205/801 [00:01<00:02, 199.71batch/s]\u001B[A\n",
      "Training batches on cuda:0:  28%|██▊       | 225/801 [00:01<00:02, 199.77batch/s]\u001B[A\n",
      "Training batches on cuda:0:  31%|███       | 246/801 [00:01<00:02, 199.88batch/s]\u001B[A\n",
      "Training batches on cuda:0:  33%|███▎      | 266/801 [00:01<00:02, 199.91batch/s]\u001B[A\n",
      "Training batches on cuda:0:  36%|███▌      | 287/801 [00:01<00:02, 200.01batch/s]\u001B[A\n",
      "Training batches on cuda:0:  38%|███▊      | 308/801 [00:01<00:02, 200.08batch/s]\u001B[A\n",
      "Training batches on cuda:0:  41%|████      | 329/801 [00:01<00:02, 199.90batch/s]\u001B[A\n",
      "Training batches on cuda:0:  44%|████▎     | 349/801 [00:01<00:02, 199.67batch/s]\u001B[A\n",
      "Training batches on cuda:0:  46%|████▌     | 369/801 [00:01<00:02, 199.72batch/s]\u001B[A\n",
      "Training batches on cuda:0:  49%|████▊     | 390/801 [00:01<00:02, 199.90batch/s]\u001B[A\n",
      "Training batches on cuda:0:  51%|█████     | 410/801 [00:02<00:01, 199.69batch/s]\u001B[A\n",
      "Training batches on cuda:0:  54%|█████▍    | 431/801 [00:02<00:01, 200.00batch/s]\u001B[A\n",
      "Training batches on cuda:0:  56%|█████▋    | 451/801 [00:02<00:01, 199.80batch/s]\u001B[A\n",
      "Training batches on cuda:0:  59%|█████▉    | 471/801 [00:02<00:01, 199.84batch/s]\u001B[A\n",
      "Training batches on cuda:0:  61%|██████▏   | 491/801 [00:02<00:01, 199.88batch/s]\u001B[A\n",
      "Training batches on cuda:0:  64%|██████▍   | 512/801 [00:02<00:01, 199.98batch/s]\u001B[A\n",
      "Training batches on cuda:0:  67%|██████▋   | 533/801 [00:02<00:01, 200.54batch/s]\u001B[A\n",
      "Training batches on cuda:0:  69%|██████▉   | 554/801 [00:02<00:01, 200.14batch/s]\u001B[A\n",
      "Training batches on cuda:0:  72%|███████▏  | 575/801 [00:02<00:01, 199.93batch/s]\u001B[A\n",
      "Training batches on cuda:0:  74%|███████▍  | 595/801 [00:02<00:01, 199.95batch/s]\u001B[A\n",
      "Training batches on cuda:0:  77%|███████▋  | 615/801 [00:03<00:00, 199.95batch/s]\u001B[A\n",
      "Training batches on cuda:0:  79%|███████▉  | 636/801 [00:03<00:00, 200.30batch/s]\u001B[A\n",
      "Training batches on cuda:0:  82%|████████▏ | 657/801 [00:03<00:00, 200.99batch/s]\u001B[A\n",
      "Training batches on cuda:0:  85%|████████▍ | 678/801 [00:03<00:00, 201.98batch/s]\u001B[A\n",
      "Training batches on cuda:0:  87%|████████▋ | 699/801 [00:03<00:00, 202.82batch/s]\u001B[A\n",
      "Training batches on cuda:0:  90%|████████▉ | 720/801 [00:03<00:00, 203.30batch/s]\u001B[A\n",
      "Training batches on cuda:0:  93%|█████████▎| 741/801 [00:03<00:00, 203.60batch/s]\u001B[A\n",
      "Training batches on cuda:0:  95%|█████████▌| 762/801 [00:03<00:00, 203.83batch/s]\u001B[A\n",
      "Training batches on cuda:0:  98%|█████████▊| 783/801 [00:03<00:00, 203.98batch/s]\u001B[A\n",
      "Training epochs on cuda:0:  40%|████      | 20/50 [01:24<02:07,  4.26s/epoch, loss=0.444, prev_loss=0.471]\n",
      "Training batches on cuda:0:   0%|          | 0/801 [00:00<?, ?batch/s]\u001B[A\n",
      "Training batches on cuda:0:   2%|▏         | 19/801 [00:00<00:04, 187.33batch/s]\u001B[A\n",
      "Training batches on cuda:0:   5%|▍         | 40/801 [00:00<00:03, 197.50batch/s]\u001B[A\n",
      "Training batches on cuda:0:   8%|▊         | 61/801 [00:00<00:03, 200.70batch/s]\u001B[A\n",
      "Training batches on cuda:0:  10%|█         | 82/801 [00:00<00:03, 201.15batch/s]\u001B[A\n",
      "Training batches on cuda:0:  13%|█▎        | 103/801 [00:00<00:03, 202.06batch/s]\u001B[A\n",
      "Training batches on cuda:0:  15%|█▌        | 124/801 [00:00<00:03, 202.40batch/s]\u001B[A\n",
      "Training batches on cuda:0:  18%|█▊        | 145/801 [00:00<00:03, 203.02batch/s]\u001B[A\n",
      "Training batches on cuda:0:  21%|██        | 166/801 [00:00<00:03, 203.09batch/s]\u001B[A\n",
      "Training batches on cuda:0:  23%|██▎       | 187/801 [00:00<00:03, 203.16batch/s]\u001B[A\n",
      "Training batches on cuda:0:  26%|██▌       | 208/801 [00:01<00:02, 203.43batch/s]\u001B[A\n",
      "Training batches on cuda:0:  29%|██▊       | 229/801 [00:01<00:02, 203.39batch/s]\u001B[A\n",
      "Training batches on cuda:0:  31%|███       | 250/801 [00:01<00:02, 203.40batch/s]\u001B[A\n",
      "Training batches on cuda:0:  34%|███▍      | 271/801 [00:01<00:02, 203.31batch/s]\u001B[A\n",
      "Training batches on cuda:0:  36%|███▋      | 292/801 [00:01<00:02, 203.41batch/s]\u001B[A\n",
      "Training batches on cuda:0:  39%|███▉      | 313/801 [00:01<00:02, 203.48batch/s]\u001B[A\n",
      "Training batches on cuda:0:  42%|████▏     | 334/801 [00:01<00:02, 203.30batch/s]\u001B[A\n",
      "Training batches on cuda:0:  44%|████▍     | 355/801 [00:01<00:02, 203.53batch/s]\u001B[A\n",
      "Training batches on cuda:0:  47%|████▋     | 376/801 [00:01<00:02, 203.35batch/s]\u001B[A\n",
      "Training batches on cuda:0:  50%|████▉     | 397/801 [00:01<00:01, 203.42batch/s]\u001B[A\n",
      "Training batches on cuda:0:  52%|█████▏    | 418/801 [00:02<00:01, 203.40batch/s]\u001B[A\n",
      "Training batches on cuda:0:  55%|█████▍    | 439/801 [00:02<00:01, 203.45batch/s]\u001B[A\n",
      "Training batches on cuda:0:  57%|█████▋    | 460/801 [00:02<00:01, 203.39batch/s]\u001B[A\n",
      "Training batches on cuda:0:  60%|██████    | 481/801 [00:02<00:01, 203.82batch/s]\u001B[A\n",
      "Training batches on cuda:0:  63%|██████▎   | 502/801 [00:02<00:01, 203.57batch/s]\u001B[A\n",
      "Training batches on cuda:0:  65%|██████▌   | 523/801 [00:02<00:01, 203.52batch/s]\u001B[A\n",
      "Training batches on cuda:0:  68%|██████▊   | 544/801 [00:02<00:01, 203.24batch/s]\u001B[A\n",
      "Training batches on cuda:0:  71%|███████   | 565/801 [00:02<00:01, 203.18batch/s]\u001B[A\n",
      "Training batches on cuda:0:  73%|███████▎  | 586/801 [00:02<00:01, 203.29batch/s]\u001B[A\n",
      "Training batches on cuda:0:  76%|███████▌  | 607/801 [00:02<00:00, 203.28batch/s]\u001B[A\n",
      "Training batches on cuda:0:  78%|███████▊  | 628/801 [00:03<00:00, 203.40batch/s]\u001B[A\n",
      "Training batches on cuda:0:  81%|████████  | 649/801 [00:03<00:00, 203.29batch/s]\u001B[A\n",
      "Training batches on cuda:0:  84%|████████▎ | 670/801 [00:03<00:00, 203.30batch/s]\u001B[A\n",
      "Training batches on cuda:0:  86%|████████▋ | 691/801 [00:03<00:00, 203.31batch/s]\u001B[A\n",
      "Training batches on cuda:0:  89%|████████▉ | 712/801 [00:03<00:00, 203.25batch/s]\u001B[A\n",
      "Training batches on cuda:0:  92%|█████████▏| 733/801 [00:03<00:00, 203.42batch/s]\u001B[A\n",
      "Training batches on cuda:0:  94%|█████████▍| 754/801 [00:03<00:00, 203.17batch/s]\u001B[A\n",
      "Training batches on cuda:0:  97%|█████████▋| 775/801 [00:03<00:00, 203.24batch/s]\u001B[A\n",
      "Training batches on cuda:0:  99%|█████████▉| 796/801 [00:03<00:00, 203.27batch/s]\u001B[A\n",
      "Training epochs on cuda:0:  42%|████▏     | 21/50 [01:28<02:02,  4.21s/epoch, loss=0.426, prev_loss=0.444]\n",
      "Training batches on cuda:0:   0%|          | 0/801 [00:00<?, ?batch/s]\u001B[A\n",
      "Training batches on cuda:0:   2%|▏         | 19/801 [00:00<00:04, 188.44batch/s]\u001B[A\n",
      "Training batches on cuda:0:   5%|▍         | 40/801 [00:00<00:03, 197.03batch/s]\u001B[A\n",
      "Training batches on cuda:0:   8%|▊         | 61/801 [00:00<00:03, 199.87batch/s]\u001B[A\n",
      "Training batches on cuda:0:  10%|█         | 82/801 [00:00<00:03, 200.38batch/s]\u001B[A\n",
      "Training batches on cuda:0:  13%|█▎        | 103/801 [00:00<00:03, 201.52batch/s]\u001B[A\n",
      "Training batches on cuda:0:  15%|█▌        | 124/801 [00:00<00:03, 202.02batch/s]\u001B[A\n",
      "Training batches on cuda:0:  18%|█▊        | 145/801 [00:00<00:03, 202.66batch/s]\u001B[A\n",
      "Training batches on cuda:0:  21%|██        | 166/801 [00:00<00:03, 202.98batch/s]\u001B[A\n",
      "Training batches on cuda:0:  23%|██▎       | 187/801 [00:00<00:03, 202.96batch/s]\u001B[A\n",
      "Training batches on cuda:0:  26%|██▌       | 208/801 [00:01<00:02, 202.75batch/s]\u001B[A\n",
      "Training batches on cuda:0:  29%|██▊       | 229/801 [00:01<00:02, 202.81batch/s]\u001B[A\n",
      "Training batches on cuda:0:  31%|███       | 250/801 [00:01<00:02, 203.06batch/s]\u001B[A\n",
      "Training batches on cuda:0:  34%|███▍      | 271/801 [00:01<00:02, 203.13batch/s]\u001B[A\n",
      "Training batches on cuda:0:  36%|███▋      | 292/801 [00:01<00:02, 202.85batch/s]\u001B[A\n",
      "Training batches on cuda:0:  39%|███▉      | 313/801 [00:01<00:02, 203.18batch/s]\u001B[A\n",
      "Training batches on cuda:0:  42%|████▏     | 334/801 [00:01<00:02, 203.20batch/s]\u001B[A\n",
      "Training batches on cuda:0:  44%|████▍     | 355/801 [00:01<00:02, 202.17batch/s]\u001B[A\n",
      "Training batches on cuda:0:  47%|████▋     | 376/801 [00:01<00:02, 202.61batch/s]\u001B[A\n",
      "Training batches on cuda:0:  50%|████▉     | 397/801 [00:02<00:02, 151.03batch/s]\u001B[A\n",
      "Training batches on cuda:0:  52%|█████▏    | 417/801 [00:02<00:02, 162.52batch/s]\u001B[A\n",
      "Training batches on cuda:0:  55%|█████▍    | 438/801 [00:02<00:02, 172.58batch/s]\u001B[A\n",
      "Training batches on cuda:0:  57%|█████▋    | 459/801 [00:02<00:01, 180.30batch/s]\u001B[A\n",
      "Training batches on cuda:0:  60%|█████▉    | 479/801 [00:02<00:01, 185.47batch/s]\u001B[A\n",
      "Training batches on cuda:0:  62%|██████▏   | 499/801 [00:02<00:01, 189.44batch/s]\u001B[A\n",
      "Training batches on cuda:0:  65%|██████▍   | 520/801 [00:02<00:01, 192.72batch/s]\u001B[A\n",
      "Training batches on cuda:0:  68%|██████▊   | 541/801 [00:02<00:01, 195.27batch/s]\u001B[A\n",
      "Training batches on cuda:0:  70%|███████   | 561/801 [00:02<00:01, 196.29batch/s]\u001B[A\n",
      "Training batches on cuda:0:  73%|███████▎  | 581/801 [00:03<00:01, 197.34batch/s]\u001B[A\n",
      "Training batches on cuda:0:  75%|███████▌  | 602/801 [00:03<00:01, 198.38batch/s]\u001B[A\n",
      "Training batches on cuda:0:  78%|███████▊  | 623/801 [00:03<00:00, 199.27batch/s]\u001B[A\n",
      "Training batches on cuda:0:  80%|████████  | 644/801 [00:03<00:00, 199.75batch/s]\u001B[A\n",
      "Training batches on cuda:0:  83%|████████▎ | 665/801 [00:03<00:00, 199.77batch/s]\u001B[A\n",
      "Training batches on cuda:0:  86%|████████▌ | 686/801 [00:03<00:00, 200.04batch/s]\u001B[A\n",
      "Training batches on cuda:0:  88%|████████▊ | 707/801 [00:03<00:00, 200.13batch/s]\u001B[A\n",
      "Training batches on cuda:0:  91%|█████████ | 728/801 [00:03<00:00, 199.87batch/s]\u001B[A\n",
      "Training batches on cuda:0:  93%|█████████▎| 748/801 [00:03<00:00, 199.25batch/s]\u001B[A\n",
      "Training batches on cuda:0:  96%|█████████▌| 768/801 [00:03<00:00, 199.29batch/s]\u001B[A\n",
      "Training batches on cuda:0:  98%|█████████▊| 788/801 [00:04<00:00, 199.41batch/s]\u001B[A\n",
      "Training epochs on cuda:0:  44%|████▍     | 22/50 [01:32<01:58,  4.23s/epoch, loss=0.407, prev_loss=0.426]\n",
      "Training batches on cuda:0:   0%|          | 0/801 [00:00<?, ?batch/s]\u001B[A\n",
      "Training batches on cuda:0:   2%|▏         | 19/801 [00:00<00:04, 186.17batch/s]\u001B[A\n",
      "Training batches on cuda:0:   5%|▍         | 39/801 [00:00<00:03, 193.98batch/s]\u001B[A\n",
      "Training batches on cuda:0:   7%|▋         | 60/801 [00:00<00:03, 197.89batch/s]\u001B[A\n",
      "Training batches on cuda:0:  10%|▉         | 80/801 [00:00<00:03, 198.06batch/s]\u001B[A\n",
      "Training batches on cuda:0:  12%|█▏        | 100/801 [00:00<00:03, 198.72batch/s]\u001B[A\n",
      "Training batches on cuda:0:  15%|█▌        | 121/801 [00:00<00:03, 199.38batch/s]\u001B[A\n",
      "Training batches on cuda:0:  18%|█▊        | 142/801 [00:00<00:03, 199.79batch/s]\u001B[A\n",
      "Training batches on cuda:0:  20%|██        | 163/801 [00:00<00:03, 200.37batch/s]\u001B[A\n",
      "Training batches on cuda:0:  23%|██▎       | 184/801 [00:00<00:03, 200.24batch/s]\u001B[A\n",
      "Training batches on cuda:0:  26%|██▌       | 205/801 [00:01<00:02, 200.69batch/s]\u001B[A\n",
      "Training batches on cuda:0:  28%|██▊       | 226/801 [00:01<00:02, 201.87batch/s]\u001B[A\n",
      "Training batches on cuda:0:  31%|███       | 247/801 [00:01<00:02, 203.16batch/s]\u001B[A\n",
      "Training batches on cuda:0:  33%|███▎      | 268/801 [00:01<00:02, 203.71batch/s]\u001B[A\n",
      "Training batches on cuda:0:  36%|███▌      | 289/801 [00:01<00:02, 204.06batch/s]\u001B[A\n",
      "Training batches on cuda:0:  39%|███▊      | 310/801 [00:01<00:02, 204.33batch/s]\u001B[A\n",
      "Training batches on cuda:0:  41%|████▏     | 331/801 [00:01<00:02, 203.35batch/s]\u001B[A\n",
      "Training batches on cuda:0:  44%|████▍     | 352/801 [00:01<00:02, 202.35batch/s]\u001B[A\n",
      "Training batches on cuda:0:  47%|████▋     | 373/801 [00:01<00:02, 201.73batch/s]\u001B[A\n",
      "Training batches on cuda:0:  49%|████▉     | 394/801 [00:01<00:02, 201.28batch/s]\u001B[A\n",
      "Training batches on cuda:0:  52%|█████▏    | 415/801 [00:02<00:01, 201.61batch/s]\u001B[A\n",
      "Training batches on cuda:0:  54%|█████▍    | 436/801 [00:02<00:01, 201.48batch/s]\u001B[A\n",
      "Training batches on cuda:0:  57%|█████▋    | 457/801 [00:02<00:01, 201.31batch/s]\u001B[A\n",
      "Training batches on cuda:0:  60%|█████▉    | 478/801 [00:02<00:01, 201.13batch/s]\u001B[A\n",
      "Training batches on cuda:0:  62%|██████▏   | 499/801 [00:02<00:01, 201.30batch/s]\u001B[A\n",
      "Training batches on cuda:0:  65%|██████▍   | 520/801 [00:02<00:01, 201.03batch/s]\u001B[A\n",
      "Training batches on cuda:0:  68%|██████▊   | 541/801 [00:02<00:01, 200.82batch/s]\u001B[A\n",
      "Training batches on cuda:0:  70%|███████   | 562/801 [00:02<00:01, 200.67batch/s]\u001B[A\n",
      "Training batches on cuda:0:  73%|███████▎  | 583/801 [00:02<00:01, 201.15batch/s]\u001B[A\n",
      "Training batches on cuda:0:  75%|███████▌  | 604/801 [00:03<00:00, 201.23batch/s]\u001B[A\n",
      "Training batches on cuda:0:  78%|███████▊  | 625/801 [00:03<00:00, 201.36batch/s]\u001B[A\n",
      "Training batches on cuda:0:  81%|████████  | 646/801 [00:03<00:00, 201.12batch/s]\u001B[A\n",
      "Training batches on cuda:0:  83%|████████▎ | 667/801 [00:03<00:00, 200.76batch/s]\u001B[A\n",
      "Training batches on cuda:0:  86%|████████▌ | 688/801 [00:03<00:00, 200.60batch/s]\u001B[A\n",
      "Training batches on cuda:0:  89%|████████▊ | 709/801 [00:03<00:00, 181.86batch/s]\u001B[A\n",
      "Training batches on cuda:0:  91%|█████████ | 728/801 [00:03<00:00, 176.47batch/s]\u001B[A\n",
      "Training batches on cuda:0:  94%|█████████▎| 749/801 [00:03<00:00, 183.15batch/s]\u001B[A\n",
      "Training batches on cuda:0:  96%|█████████▌| 768/801 [00:03<00:00, 170.21batch/s]\u001B[A\n",
      "Training batches on cuda:0:  99%|█████████▊| 789/801 [00:04<00:00, 178.65batch/s]\u001B[A\n",
      "Training epochs on cuda:0:  46%|████▌     | 23/50 [01:36<01:54,  4.23s/epoch, loss=0.387, prev_loss=0.407]\n",
      "Training batches on cuda:0:   0%|          | 0/801 [00:00<?, ?batch/s]\u001B[A\n",
      "Training batches on cuda:0:   2%|▏         | 19/801 [00:00<00:04, 185.64batch/s]\u001B[A\n",
      "Training batches on cuda:0:   5%|▍         | 39/801 [00:00<00:03, 193.97batch/s]\u001B[A\n",
      "Training batches on cuda:0:   7%|▋         | 60/801 [00:00<00:03, 197.18batch/s]\u001B[A\n",
      "Training batches on cuda:0:  10%|▉         | 80/801 [00:00<00:03, 197.66batch/s]\u001B[A\n",
      "Training batches on cuda:0:  12%|█▏        | 100/801 [00:00<00:03, 198.47batch/s]\u001B[A\n",
      "Training batches on cuda:0:  15%|█▌        | 121/801 [00:00<00:03, 199.43batch/s]\u001B[A\n",
      "Training batches on cuda:0:  18%|█▊        | 142/801 [00:00<00:03, 200.10batch/s]\u001B[A\n",
      "Training batches on cuda:0:  20%|██        | 163/801 [00:00<00:03, 200.06batch/s]\u001B[A\n",
      "Training batches on cuda:0:  23%|██▎       | 184/801 [00:00<00:03, 199.36batch/s]\u001B[A\n",
      "Training batches on cuda:0:  25%|██▌       | 204/801 [00:01<00:03, 196.43batch/s]\u001B[A\n",
      "Training batches on cuda:0:  28%|██▊       | 224/801 [00:01<00:02, 196.03batch/s]\u001B[A\n",
      "Training batches on cuda:0:  30%|███       | 244/801 [00:01<00:02, 196.18batch/s]\u001B[A\n",
      "Training batches on cuda:0:  33%|███▎      | 264/801 [00:01<00:02, 195.36batch/s]\u001B[A\n",
      "Training batches on cuda:0:  35%|███▌      | 284/801 [00:01<00:02, 194.35batch/s]\u001B[A\n",
      "Training batches on cuda:0:  38%|███▊      | 304/801 [00:01<00:02, 193.42batch/s]\u001B[A\n",
      "Training batches on cuda:0:  40%|████      | 324/801 [00:01<00:02, 193.83batch/s]\u001B[A\n",
      "Training batches on cuda:0:  43%|████▎     | 344/801 [00:01<00:02, 193.86batch/s]\u001B[A\n",
      "Training batches on cuda:0:  45%|████▌     | 364/801 [00:01<00:02, 194.49batch/s]\u001B[A\n",
      "Training batches on cuda:0:  48%|████▊     | 384/801 [00:01<00:02, 194.40batch/s]\u001B[A\n",
      "Training batches on cuda:0:  50%|█████     | 404/801 [00:02<00:02, 194.67batch/s]\u001B[A\n",
      "Training batches on cuda:0:  53%|█████▎    | 424/801 [00:02<00:01, 195.23batch/s]\u001B[A\n",
      "Training batches on cuda:0:  55%|█████▌    | 444/801 [00:02<00:01, 195.26batch/s]\u001B[A\n",
      "Training batches on cuda:0:  58%|█████▊    | 464/801 [00:02<00:01, 195.59batch/s]\u001B[A\n",
      "Training batches on cuda:0:  60%|██████    | 484/801 [00:02<00:01, 195.29batch/s]\u001B[A\n",
      "Training batches on cuda:0:  63%|██████▎   | 504/801 [00:02<00:01, 194.94batch/s]\u001B[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  65%|██████▌   | 524/801 [00:02<00:01, 194.94batch/s]\u001B[A\n",
      "Training batches on cuda:0:  68%|██████▊   | 544/801 [00:02<00:01, 194.55batch/s]\u001B[A\n",
      "Training batches on cuda:0:  70%|███████   | 564/801 [00:02<00:01, 194.78batch/s]\u001B[A\n",
      "Training batches on cuda:0:  73%|███████▎  | 584/801 [00:02<00:01, 195.17batch/s]\u001B[A\n",
      "Training batches on cuda:0:  75%|███████▌  | 604/801 [00:03<00:01, 195.17batch/s]\u001B[A\n",
      "Training batches on cuda:0:  78%|███████▊  | 624/801 [00:03<00:01, 176.02batch/s]\u001B[A\n",
      "Training batches on cuda:0:  80%|████████  | 644/801 [00:03<00:00, 180.99batch/s]\u001B[A\n",
      "Training batches on cuda:0:  83%|████████▎ | 664/801 [00:03<00:00, 184.60batch/s]\u001B[A\n",
      "Training batches on cuda:0:  85%|████████▌ | 684/801 [00:03<00:00, 187.13batch/s]\u001B[A\n",
      "Training batches on cuda:0:  88%|████████▊ | 704/801 [00:03<00:00, 189.25batch/s]\u001B[A\n",
      "Training batches on cuda:0:  90%|█████████ | 724/801 [00:03<00:00, 191.05batch/s]\u001B[A\n",
      "Training batches on cuda:0:  93%|█████████▎| 744/801 [00:03<00:00, 192.43batch/s]\u001B[A\n",
      "Training batches on cuda:0:  95%|█████████▌| 764/801 [00:03<00:00, 191.74batch/s]\u001B[A\n",
      "Training batches on cuda:0:  98%|█████████▊| 785/801 [00:04<00:00, 195.07batch/s]\u001B[A\n",
      "Training epochs on cuda:0:  48%|████▊     | 24/50 [01:41<01:50,  4.25s/epoch, loss=0.374, prev_loss=0.387]\n",
      "Training batches on cuda:0:   0%|          | 0/801 [00:00<?, ?batch/s]\u001B[A\n",
      "Training batches on cuda:0:   2%|▏         | 19/801 [00:00<00:04, 187.56batch/s]\u001B[A\n",
      "Training batches on cuda:0:   5%|▍         | 40/801 [00:00<00:03, 196.96batch/s]\u001B[A\n",
      "Training batches on cuda:0:   8%|▊         | 61/801 [00:00<00:03, 201.57batch/s]\u001B[A\n",
      "Training batches on cuda:0:  10%|█         | 82/801 [00:00<00:03, 197.37batch/s]\u001B[A\n",
      "Training batches on cuda:0:  13%|█▎        | 103/801 [00:00<00:03, 199.76batch/s]\u001B[A\n",
      "Training batches on cuda:0:  15%|█▌        | 124/801 [00:00<00:03, 201.06batch/s]\u001B[A\n",
      "Training batches on cuda:0:  18%|█▊        | 145/801 [00:00<00:03, 202.14batch/s]\u001B[A\n",
      "Training batches on cuda:0:  21%|██        | 166/801 [00:00<00:03, 202.18batch/s]\u001B[A\n",
      "Training batches on cuda:0:  23%|██▎       | 187/801 [00:00<00:03, 202.16batch/s]\u001B[A\n",
      "Training batches on cuda:0:  26%|██▌       | 208/801 [00:01<00:02, 201.88batch/s]\u001B[A\n",
      "Training batches on cuda:0:  29%|██▊       | 229/801 [00:01<00:02, 202.32batch/s]\u001B[A\n",
      "Training batches on cuda:0:  31%|███       | 250/801 [00:01<00:02, 202.79batch/s]\u001B[A\n",
      "Training batches on cuda:0:  34%|███▍      | 271/801 [00:01<00:02, 202.64batch/s]\u001B[A\n",
      "Training batches on cuda:0:  36%|███▋      | 292/801 [00:01<00:02, 200.45batch/s]\u001B[A\n",
      "Training batches on cuda:0:  39%|███▉      | 313/801 [00:01<00:02, 198.34batch/s]\u001B[A\n",
      "Training batches on cuda:0:  42%|████▏     | 334/801 [00:01<00:02, 199.39batch/s]\u001B[A\n",
      "Training batches on cuda:0:  44%|████▍     | 355/801 [00:01<00:02, 200.01batch/s]\u001B[A\n",
      "Training batches on cuda:0:  47%|████▋     | 376/801 [00:01<00:02, 200.41batch/s]\u001B[A\n",
      "Training batches on cuda:0:  50%|████▉     | 397/801 [00:01<00:02, 200.56batch/s]\u001B[A\n",
      "Training batches on cuda:0:  52%|█████▏    | 418/801 [00:02<00:01, 200.80batch/s]\u001B[A\n",
      "Training batches on cuda:0:  55%|█████▍    | 439/801 [00:02<00:01, 200.93batch/s]\u001B[A\n",
      "Training batches on cuda:0:  57%|█████▋    | 460/801 [00:02<00:01, 200.62batch/s]\u001B[A\n",
      "Training batches on cuda:0:  60%|██████    | 481/801 [00:02<00:01, 201.15batch/s]\u001B[A\n",
      "Training batches on cuda:0:  63%|██████▎   | 502/801 [00:02<00:01, 201.28batch/s]\u001B[A\n",
      "Training batches on cuda:0:  65%|██████▌   | 523/801 [00:02<00:01, 200.51batch/s]\u001B[A\n",
      "Training batches on cuda:0:  68%|██████▊   | 544/801 [00:02<00:01, 201.05batch/s]\u001B[A\n",
      "Training batches on cuda:0:  71%|███████   | 565/801 [00:02<00:01, 201.11batch/s]\u001B[A\n",
      "Training batches on cuda:0:  73%|███████▎  | 586/801 [00:02<00:01, 201.03batch/s]\u001B[A\n",
      "Training batches on cuda:0:  76%|███████▌  | 607/801 [00:03<00:00, 200.82batch/s]\u001B[A\n",
      "Training batches on cuda:0:  78%|███████▊  | 628/801 [00:03<00:00, 201.14batch/s]\u001B[A\n",
      "Training batches on cuda:0:  81%|████████  | 649/801 [00:03<00:00, 201.38batch/s]\u001B[A\n",
      "Training batches on cuda:0:  84%|████████▎ | 670/801 [00:03<00:00, 201.59batch/s]\u001B[A\n",
      "Training batches on cuda:0:  86%|████████▋ | 691/801 [00:03<00:00, 201.49batch/s]\u001B[A\n",
      "Training batches on cuda:0:  89%|████████▉ | 712/801 [00:03<00:00, 201.36batch/s]\u001B[A\n",
      "Training batches on cuda:0:  92%|█████████▏| 733/801 [00:03<00:00, 200.09batch/s]\u001B[A\n",
      "Training batches on cuda:0:  94%|█████████▍| 754/801 [00:03<00:00, 199.48batch/s]\u001B[A\n",
      "Training batches on cuda:0:  97%|█████████▋| 774/801 [00:03<00:00, 198.57batch/s]\u001B[A\n",
      "Training batches on cuda:0:  99%|█████████▉| 794/801 [00:04<00:00, 173.44batch/s]\u001B[A\n",
      "Training epochs on cuda:0:  50%|█████     | 25/50 [01:45<01:45,  4.24s/epoch, loss=0.366, prev_loss=0.374]\n",
      "Training batches on cuda:0:   0%|          | 0/801 [00:00<?, ?batch/s]\u001B[A\n",
      "Training batches on cuda:0:   2%|▏         | 19/801 [00:00<00:04, 183.57batch/s]\u001B[A\n",
      "Training batches on cuda:0:   5%|▍         | 39/801 [00:00<00:03, 190.73batch/s]\u001B[A\n",
      "Training batches on cuda:0:   7%|▋         | 59/801 [00:00<00:03, 193.20batch/s]\u001B[A\n",
      "Training batches on cuda:0:  10%|▉         | 79/801 [00:00<00:05, 137.28batch/s]\u001B[A\n",
      "Training batches on cuda:0:  12%|█▏        | 95/801 [00:00<00:08, 79.94batch/s] \u001B[A\n",
      "Training batches on cuda:0:  13%|█▎        | 107/801 [00:01<00:09, 70.83batch/s]\u001B[A\n",
      "Training batches on cuda:0:  16%|█▌        | 127/801 [00:01<00:07, 92.61batch/s]\u001B[A\n",
      "Training batches on cuda:0:  18%|█▊        | 148/801 [00:01<00:05, 114.81batch/s]\u001B[A\n",
      "Training batches on cuda:0:  21%|██        | 169/801 [00:01<00:04, 134.32batch/s]\u001B[A\n",
      "Training batches on cuda:0:  24%|██▎       | 190/801 [00:01<00:04, 150.51batch/s]\u001B[A\n",
      "Training batches on cuda:0:  26%|██▌       | 210/801 [00:01<00:03, 162.80batch/s]\u001B[A\n",
      "Training batches on cuda:0:  29%|██▊       | 230/801 [00:01<00:03, 172.56batch/s]\u001B[A\n",
      "Training batches on cuda:0:  31%|███       | 250/801 [00:01<00:03, 179.07batch/s]\u001B[A\n",
      "Training batches on cuda:0:  34%|███▎      | 270/801 [00:01<00:03, 176.76batch/s]\u001B[A\n",
      "Training batches on cuda:0:  36%|███▌      | 289/801 [00:02<00:04, 118.27batch/s]\u001B[A\n",
      "Training batches on cuda:0:  38%|███▊      | 304/801 [00:02<00:04, 111.13batch/s]\u001B[A\n",
      "Training batches on cuda:0:  40%|████      | 324/801 [00:02<00:03, 129.09batch/s]\u001B[A\n",
      "Training batches on cuda:0:  43%|████▎     | 345/801 [00:02<00:03, 146.16batch/s]\u001B[A\n",
      "Training batches on cuda:0:  46%|████▌     | 365/801 [00:02<00:02, 158.46batch/s]\u001B[A\n",
      "Training batches on cuda:0:  48%|████▊     | 383/801 [00:02<00:02, 150.87batch/s]\u001B[A\n",
      "Training batches on cuda:0:  50%|████▉     | 400/801 [00:02<00:02, 145.45batch/s]\u001B[A\n",
      "Training batches on cuda:0:  52%|█████▏    | 416/801 [00:03<00:02, 141.14batch/s]\u001B[A\n",
      "Training batches on cuda:0:  54%|█████▍    | 431/801 [00:03<00:02, 143.15batch/s]\u001B[A\n",
      "Training batches on cuda:0:  56%|█████▋    | 452/801 [00:03<00:02, 159.32batch/s]\u001B[A\n",
      "Training batches on cuda:0:  59%|█████▉    | 473/801 [00:03<00:01, 171.70batch/s]\u001B[A\n",
      "Training batches on cuda:0:  61%|██████▏   | 492/801 [00:03<00:01, 175.88batch/s]\u001B[A\n",
      "Training batches on cuda:0:  64%|██████▍   | 512/801 [00:03<00:01, 181.81batch/s]\u001B[A\n",
      "Training batches on cuda:0:  66%|██████▋   | 531/801 [00:03<00:01, 183.69batch/s]\u001B[A\n",
      "Training batches on cuda:0:  69%|██████▊   | 550/801 [00:03<00:01, 165.08batch/s]\u001B[A\n",
      "Training batches on cuda:0:  71%|███████   | 567/801 [00:04<00:01, 136.93batch/s]\u001B[A\n",
      "Training batches on cuda:0:  73%|███████▎  | 587/801 [00:04<00:01, 151.40batch/s]\u001B[A\n",
      "Training batches on cuda:0:  75%|███████▌  | 604/801 [00:04<00:01, 145.42batch/s]\u001B[A\n",
      "Training batches on cuda:0:  78%|███████▊  | 622/801 [00:04<00:01, 154.11batch/s]\u001B[A\n",
      "Training batches on cuda:0:  80%|████████  | 641/801 [00:04<00:00, 163.45batch/s]\u001B[A\n",
      "Training batches on cuda:0:  83%|████████▎ | 661/801 [00:04<00:00, 171.71batch/s]\u001B[A\n",
      "Training batches on cuda:0:  85%|████████▌ | 681/801 [00:04<00:00, 179.34batch/s]\u001B[A\n",
      "Training batches on cuda:0:  88%|████████▊ | 701/801 [00:04<00:00, 183.57batch/s]\u001B[A\n",
      "Training batches on cuda:0:  90%|████████▉ | 720/801 [00:04<00:00, 185.07batch/s]\u001B[A\n",
      "Training batches on cuda:0:  92%|█████████▏| 740/801 [00:04<00:00, 187.20batch/s]\u001B[A\n",
      "Training batches on cuda:0:  95%|█████████▍| 760/801 [00:05<00:00, 190.58batch/s]\u001B[A\n",
      "Training batches on cuda:0:  97%|█████████▋| 780/801 [00:05<00:00, 191.41batch/s]\u001B[A\n",
      "Training batches on cuda:0: 100%|█████████▉| 800/801 [00:05<00:00, 147.88batch/s]\u001B[A\n",
      "Training epochs on cuda:0:  52%|█████▏    | 26/50 [01:50<01:51,  4.64s/epoch, loss=0.363, prev_loss=0.366]\n",
      "Training batches on cuda:0:   0%|          | 0/801 [00:00<?, ?batch/s]\u001B[A\n",
      "Training batches on cuda:0:   1%|          | 5/801 [00:00<00:16, 49.01batch/s]\u001B[A\n",
      "Training batches on cuda:0:   1%|▏         | 12/801 [00:00<00:14, 56.14batch/s]\u001B[A\n",
      "Training batches on cuda:0:   4%|▎         | 30/801 [00:00<00:07, 109.35batch/s]\u001B[A\n",
      "Training batches on cuda:0:   6%|▌         | 50/801 [00:00<00:05, 143.34batch/s]\u001B[A\n",
      "Training batches on cuda:0:   9%|▊         | 70/801 [00:00<00:04, 161.93batch/s]\u001B[A\n",
      "Training batches on cuda:0:  11%|█         | 87/801 [00:00<00:04, 151.39batch/s]\u001B[A\n",
      "Training batches on cuda:0:  13%|█▎        | 103/801 [00:00<00:05, 138.82batch/s]\u001B[A\n",
      "Training batches on cuda:0:  15%|█▍        | 118/801 [00:00<00:05, 135.52batch/s]\u001B[A\n",
      "Training batches on cuda:0:  16%|█▋        | 132/801 [00:01<00:05, 125.91batch/s]\u001B[A\n",
      "Training batches on cuda:0:  18%|█▊        | 145/801 [00:01<00:05, 125.07batch/s]\u001B[A\n",
      "Training batches on cuda:0:  20%|█▉        | 158/801 [00:01<00:05, 121.69batch/s]\u001B[A\n",
      "Training batches on cuda:0:  21%|██▏       | 171/801 [00:01<00:05, 123.63batch/s]\u001B[A\n",
      "Training batches on cuda:0:  23%|██▎       | 184/801 [00:01<00:04, 125.17batch/s]\u001B[A\n",
      "Training batches on cuda:0:  25%|██▍       | 197/801 [00:01<00:04, 126.14batch/s]\u001B[A\n",
      "Training batches on cuda:0:  26%|██▌       | 210/801 [00:01<00:04, 125.36batch/s]\u001B[A\n",
      "Training batches on cuda:0:  28%|██▊       | 223/801 [00:01<00:04, 126.40batch/s]\u001B[A\n",
      "Training batches on cuda:0:  29%|██▉       | 236/801 [00:01<00:04, 127.08batch/s]\u001B[A\n",
      "Training batches on cuda:0:  31%|███       | 249/801 [00:01<00:04, 127.68batch/s]\u001B[A\n",
      "Training batches on cuda:0:  33%|███▎      | 262/801 [00:02<00:04, 123.45batch/s]\u001B[A\n",
      "Training batches on cuda:0:  34%|███▍      | 275/801 [00:02<00:04, 125.03batch/s]\u001B[A\n",
      "Training batches on cuda:0:  36%|███▌      | 288/801 [00:02<00:04, 126.19batch/s]\u001B[A\n",
      "Training batches on cuda:0:  38%|███▊      | 301/801 [00:02<00:03, 126.91batch/s]\u001B[A\n",
      "Training batches on cuda:0:  39%|███▉      | 314/801 [00:02<00:03, 123.01batch/s]\u001B[A\n",
      "Training batches on cuda:0:  41%|████      | 327/801 [00:02<00:03, 122.20batch/s]\u001B[A\n",
      "Training batches on cuda:0:  43%|████▎     | 341/801 [00:02<00:03, 125.85batch/s]\u001B[A\n",
      "Training batches on cuda:0:  44%|████▍     | 354/801 [00:02<00:03, 126.65batch/s]\u001B[A\n",
      "Training batches on cuda:0:  46%|████▌     | 367/801 [00:02<00:03, 122.23batch/s]\u001B[A\n",
      "Training batches on cuda:0:  48%|████▊     | 382/801 [00:03<00:03, 129.15batch/s]\u001B[A\n",
      "Training batches on cuda:0:  49%|████▉     | 395/801 [00:03<00:03, 127.41batch/s]\u001B[A\n",
      "Training batches on cuda:0:  51%|█████     | 408/801 [00:03<00:03, 125.32batch/s]\u001B[A\n",
      "Training batches on cuda:0:  53%|█████▎    | 422/801 [00:03<00:02, 128.17batch/s]\u001B[A\n",
      "Training batches on cuda:0:  54%|█████▍    | 435/801 [00:03<00:02, 128.38batch/s]\u001B[A\n",
      "Training batches on cuda:0:  56%|█████▌    | 448/801 [00:03<00:02, 128.63batch/s]\u001B[A\n",
      "Training batches on cuda:0:  58%|█████▊    | 461/801 [00:03<00:02, 128.73batch/s]\u001B[A\n",
      "Training batches on cuda:0:  59%|█████▉    | 474/801 [00:03<00:02, 124.07batch/s]\u001B[A\n",
      "Training batches on cuda:0:  61%|██████    | 487/801 [00:03<00:02, 125.50batch/s]\u001B[A\n",
      "Training batches on cuda:0:  62%|██████▏   | 500/801 [00:03<00:02, 126.52batch/s]\u001B[A\n",
      "Training batches on cuda:0:  64%|██████▍   | 513/801 [00:04<00:02, 127.10batch/s]\u001B[A\n",
      "Training batches on cuda:0:  66%|██████▌   | 526/801 [00:04<00:02, 123.13batch/s]\u001B[A\n",
      "Training batches on cuda:0:  67%|██████▋   | 539/801 [00:04<00:02, 124.85batch/s]\u001B[A\n",
      "Training batches on cuda:0:  69%|██████▉   | 552/801 [00:04<00:01, 126.04batch/s]\u001B[A\n",
      "Training batches on cuda:0:  71%|███████   | 565/801 [00:04<00:01, 126.88batch/s]\u001B[A\n",
      "Training batches on cuda:0:  72%|███████▏  | 578/801 [00:04<00:01, 122.90batch/s]\u001B[A\n",
      "Training batches on cuda:0:  74%|███████▍  | 591/801 [00:04<00:01, 124.67batch/s]\u001B[A\n",
      "Training batches on cuda:0:  75%|███████▌  | 604/801 [00:04<00:01, 125.94batch/s]\u001B[A\n",
      "Training batches on cuda:0:  77%|███████▋  | 617/801 [00:04<00:01, 126.78batch/s]\u001B[A\n",
      "Training batches on cuda:0:  79%|███████▊  | 630/801 [00:05<00:01, 122.49batch/s]\u001B[A\n",
      "Training batches on cuda:0:  80%|████████  | 643/801 [00:05<00:01, 124.37batch/s]\u001B[A\n",
      "Training batches on cuda:0:  82%|████████▏ | 657/801 [00:05<00:01, 123.80batch/s]\u001B[A\n",
      "Training batches on cuda:0:  84%|████████▎ | 670/801 [00:05<00:01, 125.29batch/s]\u001B[A\n",
      "Training batches on cuda:0:  85%|████████▌ | 683/801 [00:05<00:00, 126.41batch/s]\u001B[A\n",
      "Training batches on cuda:0:  87%|████████▋ | 696/801 [00:05<00:00, 127.14batch/s]\u001B[A\n",
      "Training batches on cuda:0:  89%|████████▊ | 709/801 [00:05<00:00, 127.41batch/s]\u001B[A\n",
      "Training batches on cuda:0:  90%|█████████ | 722/801 [00:05<00:00, 121.02batch/s]\u001B[A\n",
      "Training batches on cuda:0:  92%|█████████▏| 735/801 [00:05<00:00, 123.02batch/s]\u001B[A\n",
      "Training batches on cuda:0:  93%|█████████▎| 748/801 [00:05<00:00, 124.72batch/s]\u001B[A\n",
      "Training batches on cuda:0:  95%|█████████▌| 761/801 [00:06<00:00, 107.59batch/s]\u001B[A\n",
      "Training batches on cuda:0:  97%|█████████▋| 773/801 [00:06<00:00, 83.91batch/s] \u001B[A\n",
      "Training batches on cuda:0:  98%|█████████▊| 783/801 [00:06<00:00, 78.86batch/s]\u001B[A\n",
      "Training batches on cuda:0:  99%|█████████▉| 792/801 [00:06<00:00, 79.31batch/s]\u001B[A\n",
      "Training batches on cuda:0: 100%|██████████| 801/801 [00:06<00:00, 70.61batch/s]\u001B[A\n",
      "Training epochs on cuda:0:  54%|█████▍    | 27/50 [01:57<02:03,  5.37s/epoch, loss=0.358, prev_loss=0.363]\n",
      "Training batches on cuda:0:   0%|          | 0/801 [00:00<?, ?batch/s]\u001B[A\n",
      "Training batches on cuda:0:   1%|          | 7/801 [00:00<00:13, 59.12batch/s]\u001B[A\n",
      "Training batches on cuda:0:   2%|▏         | 13/801 [00:00<00:14, 55.90batch/s]\u001B[A\n",
      "Training batches on cuda:0:   2%|▏         | 19/801 [00:00<00:18, 42.79batch/s]\u001B[A\n",
      "Training batches on cuda:0:   3%|▎         | 24/801 [00:00<00:20, 38.19batch/s]\u001B[A\n",
      "Training batches on cuda:0:   3%|▎         | 28/801 [00:00<00:20, 38.01batch/s]\u001B[A\n",
      "Training batches on cuda:0:   4%|▍         | 32/801 [00:00<00:21, 35.30batch/s]\u001B[A\n",
      "Training batches on cuda:0:   4%|▍         | 36/801 [00:00<00:21, 34.91batch/s]\u001B[A\n",
      "Training batches on cuda:0:   5%|▍         | 40/801 [00:01<00:23, 32.81batch/s]\u001B[A\n",
      "Training batches on cuda:0:   5%|▌         | 44/801 [00:01<00:23, 32.85batch/s]\u001B[A\n",
      "Training batches on cuda:0:   6%|▌         | 48/801 [00:01<00:22, 34.03batch/s]\u001B[A\n",
      "Training batches on cuda:0:   6%|▋         | 52/801 [00:01<00:23, 32.28batch/s]\u001B[A\n",
      "Training batches on cuda:0:   7%|▋         | 59/801 [00:01<00:17, 41.46batch/s]\u001B[A\n",
      "Training batches on cuda:0:   9%|▉         | 72/801 [00:01<00:11, 64.72batch/s]\u001B[A\n",
      "Training batches on cuda:0:  11%|█         | 90/801 [00:01<00:07, 94.53batch/s]\u001B[A\n",
      "Training batches on cuda:0:  13%|█▎        | 102/801 [00:01<00:06, 101.16batch/s]\u001B[A\n",
      "Training batches on cuda:0:  15%|█▍        | 120/801 [00:01<00:05, 122.63batch/s]\u001B[A\n",
      "Training batches on cuda:0:  17%|█▋        | 139/801 [00:02<00:04, 141.67batch/s]\u001B[A\n",
      "Training batches on cuda:0:  20%|█▉        | 160/801 [00:02<00:04, 159.47batch/s]\u001B[A\n",
      "Training batches on cuda:0:  22%|██▏       | 180/801 [00:02<00:03, 170.17batch/s]\u001B[A\n",
      "Training batches on cuda:0:  25%|██▍       | 200/801 [00:02<00:03, 177.81batch/s]\u001B[A\n",
      "Training batches on cuda:0:  28%|██▊       | 221/801 [00:02<00:03, 184.93batch/s]\u001B[A\n",
      "Training batches on cuda:0:  30%|███       | 242/801 [00:02<00:02, 189.87batch/s]\u001B[A\n",
      "Training batches on cuda:0:  33%|███▎      | 263/801 [00:02<00:02, 193.26batch/s]\u001B[A\n",
      "Training batches on cuda:0:  35%|███▌      | 284/801 [00:02<00:02, 195.65batch/s]\u001B[A\n",
      "Training batches on cuda:0:  38%|███▊      | 305/801 [00:02<00:02, 197.17batch/s]\u001B[A\n",
      "Training batches on cuda:0:  41%|████      | 326/801 [00:02<00:02, 198.41batch/s]\u001B[A\n",
      "Training batches on cuda:0:  43%|████▎     | 347/801 [00:03<00:02, 199.27batch/s]\u001B[A\n",
      "Training batches on cuda:0:  46%|████▌     | 368/801 [00:03<00:02, 199.81batch/s]\u001B[A\n",
      "Training batches on cuda:0:  49%|████▊     | 389/801 [00:03<00:02, 200.24batch/s]\u001B[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  51%|█████     | 410/801 [00:03<00:01, 200.49batch/s]\u001B[A\n",
      "Training batches on cuda:0:  54%|█████▍    | 431/801 [00:03<00:01, 200.77batch/s]\u001B[A\n",
      "Training batches on cuda:0:  56%|█████▋    | 452/801 [00:03<00:01, 201.00batch/s]\u001B[A\n",
      "Training batches on cuda:0:  59%|█████▉    | 473/801 [00:03<00:01, 201.12batch/s]\u001B[A\n",
      "Training batches on cuda:0:  62%|██████▏   | 494/801 [00:03<00:01, 201.03batch/s]\u001B[A\n",
      "Training batches on cuda:0:  64%|██████▍   | 515/801 [00:03<00:01, 201.10batch/s]\u001B[A\n",
      "Training batches on cuda:0:  67%|██████▋   | 536/801 [00:04<00:01, 201.06batch/s]\u001B[A\n",
      "Training batches on cuda:0:  70%|██████▉   | 557/801 [00:04<00:01, 201.12batch/s]\u001B[A\n",
      "Training batches on cuda:0:  72%|███████▏  | 578/801 [00:04<00:01, 201.13batch/s]\u001B[A\n",
      "Training batches on cuda:0:  75%|███████▍  | 599/801 [00:04<00:01, 201.14batch/s]\u001B[A\n",
      "Training batches on cuda:0:  77%|███████▋  | 620/801 [00:04<00:00, 201.02batch/s]\u001B[A\n",
      "Training batches on cuda:0:  80%|████████  | 641/801 [00:04<00:00, 201.03batch/s]\u001B[A\n",
      "Training batches on cuda:0:  83%|████████▎ | 662/801 [00:04<00:00, 201.01batch/s]\u001B[A\n",
      "Training batches on cuda:0:  85%|████████▌ | 683/801 [00:04<00:00, 200.93batch/s]\u001B[A\n",
      "Training batches on cuda:0:  88%|████████▊ | 704/801 [00:04<00:00, 200.89batch/s]\u001B[A\n",
      "Training batches on cuda:0:  91%|█████████ | 725/801 [00:04<00:00, 200.95batch/s]\u001B[A\n",
      "Training batches on cuda:0:  93%|█████████▎| 746/801 [00:05<00:00, 201.00batch/s]\u001B[A\n",
      "Training batches on cuda:0:  96%|█████████▌| 767/801 [00:05<00:00, 201.08batch/s]\u001B[A\n",
      "Training batches on cuda:0:  98%|█████████▊| 788/801 [00:05<00:00, 201.04batch/s]\u001B[A\n",
      "Training epochs on cuda:0:  56%|█████▌    | 28/50 [02:03<01:59,  5.41s/epoch, loss=0.356, prev_loss=0.358]\n",
      "Training batches on cuda:0:   0%|          | 0/801 [00:00<?, ?batch/s]\u001B[A\n",
      "Training batches on cuda:0:   2%|▏         | 15/801 [00:00<00:05, 143.64batch/s]\u001B[A\n",
      "Training batches on cuda:0:   4%|▍         | 36/801 [00:00<00:04, 178.76batch/s]\u001B[A\n",
      "Training batches on cuda:0:   7%|▋         | 57/801 [00:00<00:03, 190.07batch/s]\u001B[A\n",
      "Training batches on cuda:0:  10%|▉         | 78/801 [00:00<00:03, 194.36batch/s]\u001B[A\n",
      "Training batches on cuda:0:  12%|█▏        | 99/801 [00:00<00:03, 197.78batch/s]\u001B[A\n",
      "Training batches on cuda:0:  15%|█▍        | 120/801 [00:00<00:03, 200.11batch/s]\u001B[A\n",
      "Training batches on cuda:0:  18%|█▊        | 141/801 [00:00<00:03, 201.58batch/s]\u001B[A\n",
      "Training batches on cuda:0:  20%|██        | 162/801 [00:00<00:03, 202.54batch/s]\u001B[A\n",
      "Training batches on cuda:0:  23%|██▎       | 183/801 [00:00<00:03, 203.12batch/s]\u001B[A\n",
      "Training batches on cuda:0:  25%|██▌       | 204/801 [00:01<00:02, 203.55batch/s]\u001B[A\n",
      "Training batches on cuda:0:  28%|██▊       | 225/801 [00:01<00:02, 203.92batch/s]\u001B[A\n",
      "Training batches on cuda:0:  31%|███       | 246/801 [00:01<00:02, 203.98batch/s]\u001B[A\n",
      "Training batches on cuda:0:  33%|███▎      | 267/801 [00:01<00:02, 203.98batch/s]\u001B[A\n",
      "Training batches on cuda:0:  36%|███▌      | 288/801 [00:01<00:02, 204.14batch/s]\u001B[A\n",
      "Training batches on cuda:0:  39%|███▊      | 309/801 [00:01<00:02, 204.23batch/s]\u001B[A\n",
      "Training batches on cuda:0:  41%|████      | 330/801 [00:01<00:02, 204.32batch/s]\u001B[A\n",
      "Training batches on cuda:0:  44%|████▍     | 351/801 [00:01<00:02, 204.42batch/s]\u001B[A\n",
      "Training batches on cuda:0:  46%|████▋     | 372/801 [00:01<00:02, 204.41batch/s]\u001B[A\n",
      "Training batches on cuda:0:  49%|████▉     | 393/801 [00:01<00:01, 204.38batch/s]\u001B[A\n",
      "Training batches on cuda:0:  52%|█████▏    | 414/801 [00:02<00:01, 204.41batch/s]\u001B[A\n",
      "Training batches on cuda:0:  54%|█████▍    | 435/801 [00:02<00:01, 204.32batch/s]\u001B[A\n",
      "Training batches on cuda:0:  57%|█████▋    | 456/801 [00:02<00:01, 202.88batch/s]\u001B[A\n",
      "Training batches on cuda:0:  60%|█████▉    | 477/801 [00:02<00:01, 202.30batch/s]\u001B[A\n",
      "Training batches on cuda:0:  62%|██████▏   | 498/801 [00:02<00:01, 201.91batch/s]\u001B[A\n",
      "Training batches on cuda:0:  65%|██████▍   | 519/801 [00:02<00:01, 201.63batch/s]\u001B[A\n",
      "Training batches on cuda:0:  67%|██████▋   | 540/801 [00:02<00:01, 201.49batch/s]\u001B[A\n",
      "Training batches on cuda:0:  70%|███████   | 561/801 [00:02<00:01, 201.33batch/s]\u001B[A\n",
      "Training batches on cuda:0:  73%|███████▎  | 582/801 [00:02<00:01, 201.10batch/s]\u001B[A\n",
      "Training batches on cuda:0:  75%|███████▌  | 603/801 [00:02<00:00, 201.09batch/s]\u001B[A\n",
      "Training batches on cuda:0:  78%|███████▊  | 624/801 [00:03<00:00, 200.67batch/s]\u001B[A\n",
      "Training batches on cuda:0:  81%|████████  | 645/801 [00:03<00:00, 200.73batch/s]\u001B[A\n",
      "Training batches on cuda:0:  83%|████████▎ | 666/801 [00:03<00:00, 200.81batch/s]\u001B[A\n",
      "Training batches on cuda:0:  86%|████████▌ | 687/801 [00:03<00:00, 200.72batch/s]\u001B[A\n",
      "Training batches on cuda:0:  88%|████████▊ | 708/801 [00:03<00:00, 200.74batch/s]\u001B[A\n",
      "Training batches on cuda:0:  91%|█████████ | 729/801 [00:03<00:00, 200.82batch/s]\u001B[A\n",
      "Training batches on cuda:0:  94%|█████████▎| 750/801 [00:03<00:00, 200.84batch/s]\u001B[A\n",
      "Training batches on cuda:0:  96%|█████████▋| 771/801 [00:03<00:00, 200.88batch/s]\u001B[A\n",
      "Training batches on cuda:0:  99%|█████████▉| 792/801 [00:03<00:00, 200.85batch/s]\u001B[A\n",
      "Training epochs on cuda:0:  58%|█████▊    | 29/50 [02:07<01:45,  5.03s/epoch, loss=0.352, prev_loss=0.356]\n",
      "Training batches on cuda:0:   0%|          | 0/801 [00:00<?, ?batch/s]\u001B[A\n",
      "Training batches on cuda:0:   2%|▏         | 19/801 [00:00<00:04, 188.58batch/s]\u001B[A\n",
      "Training batches on cuda:0:   5%|▍         | 40/801 [00:00<00:03, 196.57batch/s]\u001B[A\n",
      "Training batches on cuda:0:   8%|▊         | 61/801 [00:00<00:03, 199.00batch/s]\u001B[A\n",
      "Training batches on cuda:0:  10%|█         | 81/801 [00:00<00:03, 199.12batch/s]\u001B[A\n",
      "Training batches on cuda:0:  13%|█▎        | 102/801 [00:00<00:03, 200.12batch/s]\u001B[A\n",
      "Training batches on cuda:0:  15%|█▌        | 123/801 [00:00<00:03, 200.72batch/s]\u001B[A\n",
      "Training batches on cuda:0:  18%|█▊        | 144/801 [00:00<00:03, 201.03batch/s]\u001B[A\n",
      "Training batches on cuda:0:  21%|██        | 165/801 [00:00<00:03, 201.23batch/s]\u001B[A\n",
      "Training batches on cuda:0:  23%|██▎       | 186/801 [00:00<00:03, 201.35batch/s]\u001B[A\n",
      "Training batches on cuda:0:  26%|██▌       | 207/801 [00:01<00:02, 201.52batch/s]\u001B[A\n",
      "Training batches on cuda:0:  28%|██▊       | 228/801 [00:01<00:02, 201.47batch/s]\u001B[A\n",
      "Training batches on cuda:0:  31%|███       | 249/801 [00:01<00:02, 201.35batch/s]\u001B[A\n",
      "Training batches on cuda:0:  34%|███▎      | 270/801 [00:01<00:02, 201.33batch/s]\u001B[A\n",
      "Training batches on cuda:0:  36%|███▋      | 291/801 [00:01<00:02, 201.48batch/s]\u001B[A\n",
      "Training batches on cuda:0:  39%|███▉      | 312/801 [00:01<00:02, 201.51batch/s]\u001B[A\n",
      "Training batches on cuda:0:  42%|████▏     | 333/801 [00:01<00:02, 201.49batch/s]\u001B[A\n",
      "Training batches on cuda:0:  44%|████▍     | 354/801 [00:01<00:02, 201.58batch/s]\u001B[A\n",
      "Training batches on cuda:0:  47%|████▋     | 375/801 [00:01<00:02, 201.61batch/s]\u001B[A\n",
      "Training batches on cuda:0:  49%|████▉     | 396/801 [00:01<00:02, 201.75batch/s]\u001B[A\n",
      "Training batches on cuda:0:  52%|█████▏    | 417/801 [00:02<00:01, 201.78batch/s]\u001B[A\n",
      "Training batches on cuda:0:  55%|█████▍    | 438/801 [00:02<00:01, 201.62batch/s]\u001B[A\n",
      "Training batches on cuda:0:  57%|█████▋    | 459/801 [00:02<00:01, 201.44batch/s]\u001B[A\n",
      "Training batches on cuda:0:  60%|█████▉    | 480/801 [00:02<00:01, 201.58batch/s]\u001B[A\n",
      "Training batches on cuda:0:  63%|██████▎   | 501/801 [00:02<00:01, 202.26batch/s]\u001B[A\n",
      "Training batches on cuda:0:  65%|██████▌   | 522/801 [00:02<00:01, 202.82batch/s]\u001B[A\n",
      "Training batches on cuda:0:  68%|██████▊   | 543/801 [00:02<00:01, 203.19batch/s]\u001B[A\n",
      "Training batches on cuda:0:  70%|███████   | 564/801 [00:02<00:01, 203.58batch/s]\u001B[A\n",
      "Training batches on cuda:0:  73%|███████▎  | 585/801 [00:02<00:01, 203.78batch/s]\u001B[A\n",
      "Training batches on cuda:0:  76%|███████▌  | 606/801 [00:03<00:00, 203.90batch/s]\u001B[A\n",
      "Training batches on cuda:0:  78%|███████▊  | 627/801 [00:03<00:00, 203.81batch/s]\u001B[A\n",
      "Training batches on cuda:0:  81%|████████  | 648/801 [00:03<00:00, 203.78batch/s]\u001B[A\n",
      "Training batches on cuda:0:  84%|████████▎ | 669/801 [00:03<00:00, 203.93batch/s]\u001B[A\n",
      "Training batches on cuda:0:  86%|████████▌ | 690/801 [00:03<00:00, 204.01batch/s]\u001B[A\n",
      "Training batches on cuda:0:  89%|████████▉ | 711/801 [00:03<00:00, 204.02batch/s]\u001B[A\n",
      "Training batches on cuda:0:  91%|█████████▏| 732/801 [00:03<00:00, 204.10batch/s]\u001B[A\n",
      "Training batches on cuda:0:  94%|█████████▍| 753/801 [00:03<00:00, 204.15batch/s]\u001B[A\n",
      "Training batches on cuda:0:  97%|█████████▋| 774/801 [00:03<00:00, 204.19batch/s]\u001B[A\n",
      "Training batches on cuda:0:  99%|█████████▉| 795/801 [00:03<00:00, 204.16batch/s]\u001B[A\n",
      "Training epochs on cuda:0:  60%|██████    | 30/50 [02:11<01:35,  4.76s/epoch, loss=0.35, prev_loss=0.352] \n",
      "Training batches on cuda:0:   0%|          | 0/801 [00:00<?, ?batch/s]\u001B[A\n",
      "Training batches on cuda:0:   2%|▏         | 19/801 [00:00<00:04, 187.28batch/s]\u001B[A\n",
      "Training batches on cuda:0:   5%|▍         | 40/801 [00:00<00:03, 197.05batch/s]\u001B[A\n",
      "Training batches on cuda:0:   8%|▊         | 61/801 [00:00<00:03, 200.29batch/s]\u001B[A\n",
      "Training batches on cuda:0:  10%|█         | 82/801 [00:00<00:03, 201.06batch/s]\u001B[A\n",
      "Training batches on cuda:0:  13%|█▎        | 103/801 [00:00<00:03, 202.30batch/s]\u001B[A\n",
      "Training batches on cuda:0:  15%|█▌        | 124/801 [00:00<00:03, 203.04batch/s]\u001B[A\n",
      "Training batches on cuda:0:  18%|█▊        | 145/801 [00:00<00:03, 203.43batch/s]\u001B[A\n",
      "Training batches on cuda:0:  21%|██        | 166/801 [00:00<00:03, 203.71batch/s]\u001B[A\n",
      "Training batches on cuda:0:  23%|██▎       | 187/801 [00:00<00:03, 203.80batch/s]\u001B[A\n",
      "Training batches on cuda:0:  26%|██▌       | 208/801 [00:01<00:02, 203.72batch/s]\u001B[A\n",
      "Training batches on cuda:0:  29%|██▊       | 229/801 [00:01<00:02, 204.00batch/s]\u001B[A\n",
      "Training batches on cuda:0:  31%|███       | 250/801 [00:01<00:02, 204.12batch/s]\u001B[A\n",
      "Training batches on cuda:0:  34%|███▍      | 271/801 [00:01<00:02, 204.27batch/s]\u001B[A\n",
      "Training batches on cuda:0:  36%|███▋      | 292/801 [00:01<00:02, 204.37batch/s]\u001B[A\n",
      "Training batches on cuda:0:  39%|███▉      | 313/801 [00:01<00:02, 204.24batch/s]\u001B[A\n",
      "Training batches on cuda:0:  42%|████▏     | 334/801 [00:01<00:02, 204.31batch/s]\u001B[A\n",
      "Training batches on cuda:0:  44%|████▍     | 355/801 [00:01<00:02, 204.32batch/s]\u001B[A\n",
      "Training batches on cuda:0:  47%|████▋     | 376/801 [00:01<00:02, 204.16batch/s]\u001B[A\n",
      "Training batches on cuda:0:  50%|████▉     | 397/801 [00:01<00:01, 204.07batch/s]\u001B[A\n",
      "Training batches on cuda:0:  52%|█████▏    | 418/801 [00:02<00:01, 204.10batch/s]\u001B[A\n",
      "Training batches on cuda:0:  55%|█████▍    | 439/801 [00:02<00:01, 204.17batch/s]\u001B[A\n",
      "Training batches on cuda:0:  57%|█████▋    | 460/801 [00:02<00:01, 204.11batch/s]\u001B[A\n",
      "Training batches on cuda:0:  60%|██████    | 481/801 [00:02<00:01, 204.15batch/s]\u001B[A\n",
      "Training batches on cuda:0:  63%|██████▎   | 502/801 [00:02<00:01, 203.80batch/s]\u001B[A\n",
      "Training batches on cuda:0:  65%|██████▌   | 523/801 [00:02<00:01, 204.07batch/s]\u001B[A\n",
      "Training batches on cuda:0:  68%|██████▊   | 544/801 [00:02<00:01, 204.16batch/s]\u001B[A\n",
      "Training batches on cuda:0:  71%|███████   | 565/801 [00:02<00:01, 204.23batch/s]\u001B[A\n",
      "Training batches on cuda:0:  73%|███████▎  | 586/801 [00:02<00:01, 204.10batch/s]\u001B[A\n",
      "Training batches on cuda:0:  76%|███████▌  | 607/801 [00:02<00:00, 203.98batch/s]\u001B[A\n",
      "Training batches on cuda:0:  78%|███████▊  | 628/801 [00:03<00:00, 204.06batch/s]\u001B[A\n",
      "Training batches on cuda:0:  81%|████████  | 649/801 [00:03<00:00, 204.02batch/s]\u001B[A\n",
      "Training batches on cuda:0:  84%|████████▎ | 670/801 [00:03<00:00, 204.14batch/s]\u001B[A\n",
      "Training batches on cuda:0:  86%|████████▋ | 691/801 [00:03<00:00, 204.16batch/s]\u001B[A\n",
      "Training batches on cuda:0:  89%|████████▉ | 712/801 [00:03<00:00, 204.19batch/s]\u001B[A\n",
      "Training batches on cuda:0:  92%|█████████▏| 733/801 [00:03<00:00, 204.23batch/s]\u001B[A\n",
      "Training batches on cuda:0:  94%|█████████▍| 754/801 [00:03<00:00, 204.26batch/s]\u001B[A\n",
      "Training batches on cuda:0:  97%|█████████▋| 775/801 [00:03<00:00, 204.28batch/s]\u001B[A\n",
      "Training batches on cuda:0:  99%|█████████▉| 796/801 [00:03<00:00, 204.33batch/s]\u001B[A\n",
      "Training epochs on cuda:0:  62%|██████▏   | 31/50 [02:15<01:26,  4.56s/epoch, loss=0.348, prev_loss=0.35]\n",
      "Training batches on cuda:0:   0%|          | 0/801 [00:00<?, ?batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 4/801 [00:00<00:20, 38.99batch/s]\u001B[A\n",
      "Training batches on cuda:0:   3%|▎         | 24/801 [00:00<00:05, 132.12batch/s]\u001B[A\n",
      "Training batches on cuda:0:   5%|▌         | 44/801 [00:00<00:04, 161.99batch/s]\u001B[A\n",
      "Training batches on cuda:0:   8%|▊         | 64/801 [00:00<00:04, 176.67batch/s]\u001B[A\n",
      "Training batches on cuda:0:  10%|█         | 84/801 [00:00<00:03, 184.46batch/s]\u001B[A\n",
      "Training batches on cuda:0:  13%|█▎        | 104/801 [00:00<00:03, 189.71batch/s]\u001B[A\n",
      "Training batches on cuda:0:  15%|█▌        | 124/801 [00:00<00:03, 193.02batch/s]\u001B[A\n",
      "Training batches on cuda:0:  18%|█▊        | 144/801 [00:00<00:03, 194.78batch/s]\u001B[A\n",
      "Training batches on cuda:0:  20%|██        | 164/801 [00:00<00:03, 196.14batch/s]\u001B[A\n",
      "Training batches on cuda:0:  23%|██▎       | 184/801 [00:01<00:03, 197.18batch/s]\u001B[A\n",
      "Training batches on cuda:0:  25%|██▌       | 204/801 [00:01<00:03, 197.77batch/s]\u001B[A\n",
      "Training batches on cuda:0:  28%|██▊       | 224/801 [00:01<00:02, 198.14batch/s]\u001B[A\n",
      "Training batches on cuda:0:  30%|███       | 244/801 [00:01<00:02, 198.14batch/s]\u001B[A\n",
      "Training batches on cuda:0:  33%|███▎      | 264/801 [00:01<00:02, 198.19batch/s]\u001B[A\n",
      "Training batches on cuda:0:  35%|███▌      | 284/801 [00:01<00:02, 198.33batch/s]\u001B[A\n",
      "Training batches on cuda:0:  38%|███▊      | 304/801 [00:01<00:02, 198.80batch/s]\u001B[A\n",
      "Training batches on cuda:0:  40%|████      | 324/801 [00:01<00:02, 199.13batch/s]\u001B[A\n",
      "Training batches on cuda:0:  43%|████▎     | 344/801 [00:01<00:02, 199.31batch/s]\u001B[A\n",
      "Training batches on cuda:0:  45%|████▌     | 364/801 [00:01<00:02, 199.39batch/s]\u001B[A\n",
      "Training batches on cuda:0:  48%|████▊     | 384/801 [00:02<00:02, 199.29batch/s]\u001B[A\n",
      "Training batches on cuda:0:  51%|█████     | 405/801 [00:02<00:01, 200.10batch/s]\u001B[A\n",
      "Training batches on cuda:0:  53%|█████▎    | 426/801 [00:02<00:02, 180.47batch/s]\u001B[A\n",
      "Training batches on cuda:0:  56%|█████▌    | 445/801 [00:02<00:02, 158.40batch/s]\u001B[A\n",
      "Training batches on cuda:0:  58%|█████▊    | 462/801 [00:02<00:02, 148.17batch/s]\u001B[A\n",
      "Training batches on cuda:0:  60%|█████▉    | 478/801 [00:02<00:02, 141.25batch/s]\u001B[A\n",
      "Training batches on cuda:0:  62%|██████▏   | 493/801 [00:02<00:02, 137.40batch/s]\u001B[A\n",
      "Training batches on cuda:0:  63%|██████▎   | 507/801 [00:02<00:02, 133.99batch/s]\u001B[A\n",
      "Training batches on cuda:0:  65%|██████▌   | 521/801 [00:03<00:02, 130.12batch/s]\u001B[A\n",
      "Training batches on cuda:0:  67%|██████▋   | 535/801 [00:03<00:02, 127.07batch/s]\u001B[A\n",
      "Training batches on cuda:0:  68%|██████▊   | 548/801 [00:03<00:02, 122.17batch/s]\u001B[A\n",
      "Training batches on cuda:0:  70%|███████   | 563/801 [00:03<00:01, 128.70batch/s]\u001B[A\n",
      "Training batches on cuda:0:  72%|███████▏  | 576/801 [00:03<00:01, 123.14batch/s]\u001B[A\n",
      "Training batches on cuda:0:  74%|███████▎  | 589/801 [00:03<00:01, 123.68batch/s]\u001B[A\n",
      "Training batches on cuda:0:  75%|███████▌  | 602/801 [00:03<00:01, 123.75batch/s]\u001B[A\n",
      "Training batches on cuda:0:  77%|███████▋  | 615/801 [00:03<00:01, 123.25batch/s]\u001B[A\n",
      "Training batches on cuda:0:  78%|███████▊  | 628/801 [00:03<00:01, 119.28batch/s]\u001B[A\n",
      "Training batches on cuda:0:  80%|███████▉  | 640/801 [00:04<00:01, 118.45batch/s]\u001B[A\n",
      "Training batches on cuda:0:  82%|████████▏ | 654/801 [00:04<00:01, 123.97batch/s]\u001B[A\n",
      "Training batches on cuda:0:  83%|████████▎ | 667/801 [00:04<00:01, 118.11batch/s]\u001B[A\n",
      "Training batches on cuda:0:  85%|████████▌ | 684/801 [00:04<00:00, 131.41batch/s]\u001B[A\n",
      "Training batches on cuda:0:  88%|████████▊ | 705/801 [00:04<00:00, 151.62batch/s]\u001B[A\n",
      "Training batches on cuda:0:  91%|█████████ | 726/801 [00:04<00:00, 166.08batch/s]\u001B[A\n",
      "Training batches on cuda:0:  93%|█████████▎| 747/801 [00:04<00:00, 176.43batch/s]\u001B[A\n",
      "Training batches on cuda:0:  96%|█████████▌| 768/801 [00:04<00:00, 183.81batch/s]\u001B[A\n",
      "Training batches on cuda:0:  99%|█████████▊| 789/801 [00:04<00:00, 188.98batch/s]\u001B[A\n",
      "Training epochs on cuda:0:  64%|██████▍   | 32/50 [02:20<01:24,  4.72s/epoch, loss=0.346, prev_loss=0.348]\n",
      "Training batches on cuda:0:   0%|          | 0/801 [00:00<?, ?batch/s]\u001B[A\n",
      "Training batches on cuda:0:   2%|▏         | 19/801 [00:00<00:04, 188.33batch/s]\u001B[A\n",
      "Training batches on cuda:0:   5%|▍         | 40/801 [00:00<00:03, 195.77batch/s]\u001B[A\n",
      "Training batches on cuda:0:   8%|▊         | 61/801 [00:00<00:03, 197.96batch/s]\u001B[A\n",
      "Training batches on cuda:0:  10%|█         | 81/801 [00:00<00:03, 198.24batch/s]\u001B[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  13%|█▎        | 102/801 [00:00<00:03, 199.13batch/s]\u001B[A\n",
      "Training batches on cuda:0:  15%|█▌        | 123/801 [00:00<00:03, 199.72batch/s]\u001B[A\n",
      "Training batches on cuda:0:  18%|█▊        | 144/801 [00:00<00:03, 200.11batch/s]\u001B[A\n",
      "Training batches on cuda:0:  21%|██        | 165/801 [00:00<00:03, 200.22batch/s]\u001B[A\n",
      "Training batches on cuda:0:  23%|██▎       | 186/801 [00:00<00:03, 200.31batch/s]\u001B[A\n",
      "Training batches on cuda:0:  26%|██▌       | 207/801 [00:01<00:02, 200.38batch/s]\u001B[A\n",
      "Training batches on cuda:0:  28%|██▊       | 228/801 [00:01<00:02, 200.24batch/s]\u001B[A\n",
      "Training batches on cuda:0:  31%|███       | 249/801 [00:01<00:02, 200.33batch/s]\u001B[A\n",
      "Training batches on cuda:0:  34%|███▎      | 270/801 [00:01<00:02, 200.66batch/s]\u001B[A\n",
      "Training batches on cuda:0:  36%|███▋      | 291/801 [00:01<00:02, 200.27batch/s]\u001B[A\n",
      "Training batches on cuda:0:  39%|███▉      | 312/801 [00:01<00:02, 200.20batch/s]\u001B[A\n",
      "Training batches on cuda:0:  42%|████▏     | 333/801 [00:01<00:02, 200.48batch/s]\u001B[A\n",
      "Training batches on cuda:0:  44%|████▍     | 354/801 [00:01<00:02, 200.34batch/s]\u001B[A\n",
      "Training batches on cuda:0:  47%|████▋     | 375/801 [00:01<00:02, 200.66batch/s]\u001B[A\n",
      "Training batches on cuda:0:  49%|████▉     | 396/801 [00:01<00:02, 200.83batch/s]\u001B[A\n",
      "Training batches on cuda:0:  52%|█████▏    | 417/801 [00:02<00:01, 200.58batch/s]\u001B[A\n",
      "Training batches on cuda:0:  55%|█████▍    | 438/801 [00:02<00:01, 200.71batch/s]\u001B[A\n",
      "Training batches on cuda:0:  57%|█████▋    | 459/801 [00:02<00:01, 200.37batch/s]\u001B[A\n",
      "Training batches on cuda:0:  60%|█████▉    | 480/801 [00:02<00:01, 200.17batch/s]\u001B[A\n",
      "Training batches on cuda:0:  63%|██████▎   | 501/801 [00:02<00:01, 200.34batch/s]\u001B[A\n",
      "Training batches on cuda:0:  65%|██████▌   | 522/801 [00:02<00:01, 200.55batch/s]\u001B[A\n",
      "Training batches on cuda:0:  68%|██████▊   | 543/801 [00:02<00:01, 200.83batch/s]\u001B[A\n",
      "Training batches on cuda:0:  70%|███████   | 564/801 [00:02<00:01, 200.74batch/s]\u001B[A\n",
      "Training batches on cuda:0:  73%|███████▎  | 585/801 [00:02<00:01, 200.81batch/s]\u001B[A\n",
      "Training batches on cuda:0:  76%|███████▌  | 606/801 [00:03<00:00, 201.01batch/s]\u001B[A\n",
      "Training batches on cuda:0:  78%|███████▊  | 627/801 [00:03<00:00, 201.09batch/s]\u001B[A\n",
      "Training batches on cuda:0:  81%|████████  | 648/801 [00:03<00:00, 201.06batch/s]\u001B[A\n",
      "Training batches on cuda:0:  84%|████████▎ | 669/801 [00:03<00:00, 201.12batch/s]\u001B[A\n",
      "Training batches on cuda:0:  86%|████████▌ | 690/801 [00:03<00:00, 200.66batch/s]\u001B[A\n",
      "Training batches on cuda:0:  89%|████████▉ | 711/801 [00:03<00:00, 200.75batch/s]\u001B[A\n",
      "Training batches on cuda:0:  91%|█████████▏| 732/801 [00:03<00:00, 200.78batch/s]\u001B[A\n",
      "Training batches on cuda:0:  94%|█████████▍| 753/801 [00:03<00:00, 200.83batch/s]\u001B[A\n",
      "Training batches on cuda:0:  97%|█████████▋| 774/801 [00:03<00:00, 201.03batch/s]\u001B[A\n",
      "Training batches on cuda:0:  99%|█████████▉| 795/801 [00:03<00:00, 200.99batch/s]\u001B[A\n",
      "Training epochs on cuda:0:  66%|██████▌   | 33/50 [02:25<01:17,  4.55s/epoch, loss=0.345, prev_loss=0.346]\n",
      "Training batches on cuda:0:   0%|          | 0/801 [00:00<?, ?batch/s]\u001B[A\n",
      "Training batches on cuda:0:   2%|▏         | 19/801 [00:00<00:04, 186.22batch/s]\u001B[A\n",
      "Training batches on cuda:0:   5%|▍         | 39/801 [00:00<00:03, 194.23batch/s]\u001B[A\n",
      "Training batches on cuda:0:   7%|▋         | 59/801 [00:00<00:03, 196.82batch/s]\u001B[A\n",
      "Training batches on cuda:0:  10%|▉         | 79/801 [00:00<00:03, 197.00batch/s]\u001B[A\n",
      "Training batches on cuda:0:  12%|█▏        | 99/801 [00:00<00:03, 197.66batch/s]\u001B[A\n",
      "Training batches on cuda:0:  15%|█▍        | 120/801 [00:00<00:03, 198.63batch/s]\u001B[A\n",
      "Training batches on cuda:0:  17%|█▋        | 140/801 [00:00<00:03, 199.05batch/s]\u001B[A\n",
      "Training batches on cuda:0:  20%|██        | 161/801 [00:00<00:03, 199.43batch/s]\u001B[A\n",
      "Training batches on cuda:0:  23%|██▎       | 182/801 [00:00<00:03, 199.91batch/s]\u001B[A\n",
      "Training batches on cuda:0:  25%|██▌       | 203/801 [00:01<00:02, 200.46batch/s]\u001B[A\n",
      "Training batches on cuda:0:  28%|██▊       | 224/801 [00:01<00:02, 201.30batch/s]\u001B[A\n",
      "Training batches on cuda:0:  31%|███       | 245/801 [00:01<00:02, 201.81batch/s]\u001B[A\n",
      "Training batches on cuda:0:  33%|███▎      | 266/801 [00:01<00:02, 202.12batch/s]\u001B[A\n",
      "Training batches on cuda:0:  36%|███▌      | 287/801 [00:01<00:02, 202.25batch/s]\u001B[A\n",
      "Training batches on cuda:0:  38%|███▊      | 308/801 [00:01<00:02, 202.22batch/s]\u001B[A\n",
      "Training batches on cuda:0:  41%|████      | 329/801 [00:01<00:02, 202.15batch/s]\u001B[A\n",
      "Training batches on cuda:0:  44%|████▎     | 350/801 [00:01<00:02, 202.22batch/s]\u001B[A\n",
      "Training batches on cuda:0:  46%|████▋     | 371/801 [00:01<00:02, 202.62batch/s]\u001B[A\n",
      "Training batches on cuda:0:  49%|████▉     | 392/801 [00:01<00:02, 202.79batch/s]\u001B[A\n",
      "Training batches on cuda:0:  52%|█████▏    | 413/801 [00:02<00:01, 202.86batch/s]\u001B[A\n",
      "Training batches on cuda:0:  54%|█████▍    | 434/801 [00:02<00:01, 202.96batch/s]\u001B[A\n",
      "Training batches on cuda:0:  57%|█████▋    | 455/801 [00:02<00:01, 202.79batch/s]\u001B[A\n",
      "Training batches on cuda:0:  59%|█████▉    | 476/801 [00:02<00:01, 202.48batch/s]\u001B[A\n",
      "Training batches on cuda:0:  62%|██████▏   | 497/801 [00:02<00:01, 202.67batch/s]\u001B[A\n",
      "Training batches on cuda:0:  65%|██████▍   | 518/801 [00:02<00:01, 151.79batch/s]\u001B[A\n",
      "Training batches on cuda:0:  67%|██████▋   | 536/801 [00:02<00:01, 155.69batch/s]\u001B[A\n",
      "Training batches on cuda:0:  69%|██████▉   | 556/801 [00:02<00:01, 166.72batch/s]\u001B[A\n",
      "Training batches on cuda:0:  72%|███████▏  | 577/801 [00:03<00:01, 175.99batch/s]\u001B[A\n",
      "Training batches on cuda:0:  75%|███████▍  | 598/801 [00:03<00:01, 182.86batch/s]\u001B[A\n",
      "Training batches on cuda:0:  77%|███████▋  | 619/801 [00:03<00:00, 188.11batch/s]\u001B[A\n",
      "Training batches on cuda:0:  80%|███████▉  | 640/801 [00:03<00:00, 191.93batch/s]\u001B[A\n",
      "Training batches on cuda:0:  83%|████████▎ | 661/801 [00:03<00:00, 194.54batch/s]\u001B[A\n",
      "Training batches on cuda:0:  85%|████████▌ | 682/801 [00:03<00:00, 196.42batch/s]\u001B[A\n",
      "Training batches on cuda:0:  88%|████████▊ | 703/801 [00:03<00:00, 197.78batch/s]\u001B[A\n",
      "Training batches on cuda:0:  90%|█████████ | 724/801 [00:03<00:00, 198.78batch/s]\u001B[A\n",
      "Training batches on cuda:0:  93%|█████████▎| 745/801 [00:03<00:00, 199.48batch/s]\u001B[A\n",
      "Training batches on cuda:0:  96%|█████████▌| 766/801 [00:03<00:00, 199.94batch/s]\u001B[A\n",
      "Training batches on cuda:0:  98%|█████████▊| 787/801 [00:04<00:00, 200.37batch/s]\u001B[A\n",
      "Training epochs on cuda:0:  68%|██████▊   | 34/50 [02:29<01:11,  4.47s/epoch, loss=0.343, prev_loss=0.345]\n",
      "Training batches on cuda:0:   0%|          | 0/801 [00:00<?, ?batch/s]\u001B[A\n",
      "Training batches on cuda:0:   2%|▏         | 19/801 [00:00<00:04, 182.30batch/s]\u001B[A\n",
      "Training batches on cuda:0:   5%|▍         | 39/801 [00:00<00:04, 190.31batch/s]\u001B[A\n",
      "Training batches on cuda:0:   7%|▋         | 59/801 [00:00<00:03, 194.65batch/s]\u001B[A\n",
      "Training batches on cuda:0:  10%|▉         | 79/801 [00:00<00:03, 196.26batch/s]\u001B[A\n",
      "Training batches on cuda:0:  12%|█▏        | 100/801 [00:00<00:03, 197.88batch/s]\u001B[A\n",
      "Training batches on cuda:0:  15%|█▌        | 121/801 [00:00<00:03, 198.78batch/s]\u001B[A\n",
      "Training batches on cuda:0:  18%|█▊        | 142/801 [00:00<00:03, 199.29batch/s]\u001B[A\n",
      "Training batches on cuda:0:  20%|██        | 162/801 [00:00<00:03, 199.44batch/s]\u001B[A\n",
      "Training batches on cuda:0:  23%|██▎       | 182/801 [00:00<00:03, 199.60batch/s]\u001B[A\n",
      "Training batches on cuda:0:  25%|██▌       | 202/801 [00:01<00:03, 198.88batch/s]\u001B[A\n",
      "Training batches on cuda:0:  28%|██▊       | 222/801 [00:01<00:02, 197.84batch/s]\u001B[A\n",
      "Training batches on cuda:0:  30%|███       | 242/801 [00:01<00:02, 197.57batch/s]\u001B[A\n",
      "Training batches on cuda:0:  33%|███▎      | 262/801 [00:01<00:02, 198.10batch/s]\u001B[A\n",
      "Training batches on cuda:0:  35%|███▌      | 282/801 [00:01<00:02, 198.60batch/s]\u001B[A\n",
      "Training batches on cuda:0:  38%|███▊      | 302/801 [00:01<00:02, 198.82batch/s]\u001B[A\n",
      "Training batches on cuda:0:  40%|████      | 322/801 [00:01<00:02, 199.12batch/s]\u001B[A\n",
      "Training batches on cuda:0:  43%|████▎     | 342/801 [00:01<00:02, 199.24batch/s]\u001B[A\n",
      "Training batches on cuda:0:  45%|████▌     | 362/801 [00:01<00:02, 199.27batch/s]\u001B[A\n",
      "Training batches on cuda:0:  48%|████▊     | 383/801 [00:01<00:02, 199.85batch/s]\u001B[A\n",
      "Training batches on cuda:0:  50%|█████     | 403/801 [00:02<00:02, 198.53batch/s]\u001B[A\n",
      "Training batches on cuda:0:  53%|█████▎    | 423/801 [00:02<00:01, 197.54batch/s]\u001B[A\n",
      "Training batches on cuda:0:  55%|█████▌    | 443/801 [00:02<00:01, 197.74batch/s]\u001B[A\n",
      "Training batches on cuda:0:  58%|█████▊    | 463/801 [00:02<00:01, 195.49batch/s]\u001B[A\n",
      "Training batches on cuda:0:  60%|██████    | 483/801 [00:02<00:01, 196.68batch/s]\u001B[A\n",
      "Training batches on cuda:0:  63%|██████▎   | 503/801 [00:02<00:01, 197.63batch/s]\u001B[A\n",
      "Training batches on cuda:0:  65%|██████▌   | 524/801 [00:02<00:01, 198.41batch/s]\u001B[A\n",
      "Training batches on cuda:0:  68%|██████▊   | 544/801 [00:02<00:01, 198.62batch/s]\u001B[A\n",
      "Training batches on cuda:0:  70%|███████   | 564/801 [00:02<00:01, 198.74batch/s]\u001B[A\n",
      "Training batches on cuda:0:  73%|███████▎  | 584/801 [00:02<00:01, 198.55batch/s]\u001B[A\n",
      "Training batches on cuda:0:  75%|███████▌  | 604/801 [00:03<00:00, 197.73batch/s]\u001B[A\n",
      "Training batches on cuda:0:  78%|███████▊  | 624/801 [00:03<00:00, 197.28batch/s]\u001B[A\n",
      "Training batches on cuda:0:  80%|████████  | 644/801 [00:03<00:00, 197.93batch/s]\u001B[A\n",
      "Training batches on cuda:0:  83%|████████▎ | 665/801 [00:03<00:00, 198.64batch/s]\u001B[A\n",
      "Training batches on cuda:0:  86%|████████▌ | 686/801 [00:03<00:00, 199.17batch/s]\u001B[A\n",
      "Training batches on cuda:0:  88%|████████▊ | 707/801 [00:03<00:00, 199.49batch/s]\u001B[A\n",
      "Training batches on cuda:0:  91%|█████████ | 728/801 [00:03<00:00, 199.83batch/s]\u001B[A\n",
      "Training batches on cuda:0:  94%|█████████▎| 749/801 [00:03<00:00, 200.04batch/s]\u001B[A\n",
      "Training batches on cuda:0:  96%|█████████▌| 770/801 [00:03<00:00, 200.07batch/s]\u001B[A\n",
      "Training batches on cuda:0:  99%|█████████▉| 791/801 [00:03<00:00, 198.66batch/s]\u001B[A\n",
      "Training epochs on cuda:0:  70%|███████   | 35/50 [02:33<01:05,  4.39s/epoch, loss=0.341, prev_loss=0.343]\n",
      "Training batches on cuda:0:   0%|          | 0/801 [00:00<?, ?batch/s]\u001B[A\n",
      "Training batches on cuda:0:   2%|▏         | 19/801 [00:00<00:04, 185.12batch/s]\u001B[A\n",
      "Training batches on cuda:0:   5%|▍         | 40/801 [00:00<00:03, 194.08batch/s]\u001B[A\n",
      "Training batches on cuda:0:   7%|▋         | 60/801 [00:00<00:03, 196.66batch/s]\u001B[A\n",
      "Training batches on cuda:0:  10%|▉         | 80/801 [00:00<00:04, 164.70batch/s]\u001B[A\n",
      "Training batches on cuda:0:  12%|█▏        | 98/801 [00:00<00:04, 151.40batch/s]\u001B[A\n",
      "Training batches on cuda:0:  14%|█▍        | 114/801 [00:00<00:04, 140.11batch/s]\u001B[A\n",
      "Training batches on cuda:0:  16%|█▌        | 129/801 [00:00<00:04, 136.53batch/s]\u001B[A\n",
      "Training batches on cuda:0:  18%|█▊        | 143/801 [00:00<00:04, 132.84batch/s]\u001B[A\n",
      "Training batches on cuda:0:  20%|█▉        | 157/801 [00:01<00:04, 129.47batch/s]\u001B[A\n",
      "Training batches on cuda:0:  21%|██▏       | 171/801 [00:01<00:04, 128.44batch/s]\u001B[A\n",
      "Training batches on cuda:0:  23%|██▎       | 184/801 [00:01<00:04, 128.85batch/s]\u001B[A\n",
      "Training batches on cuda:0:  25%|██▍       | 197/801 [00:01<00:04, 128.23batch/s]\u001B[A\n",
      "Training batches on cuda:0:  26%|██▌       | 210/801 [00:01<00:04, 126.14batch/s]\u001B[A\n",
      "Training batches on cuda:0:  28%|██▊       | 223/801 [00:01<00:04, 123.66batch/s]\u001B[A\n",
      "Training batches on cuda:0:  30%|██▉       | 237/801 [00:01<00:04, 127.32batch/s]\u001B[A\n",
      "Training batches on cuda:0:  31%|███       | 250/801 [00:01<00:04, 126.83batch/s]\u001B[A\n",
      "Training batches on cuda:0:  33%|███▎      | 263/801 [00:01<00:04, 122.85batch/s]\u001B[A\n",
      "Training batches on cuda:0:  35%|███▍      | 277/801 [00:02<00:04, 124.88batch/s]\u001B[A\n",
      "Training batches on cuda:0:  36%|███▌      | 290/801 [00:02<00:04, 125.65batch/s]\u001B[A\n",
      "Training batches on cuda:0:  38%|███▊      | 304/801 [00:02<00:03, 124.73batch/s]\u001B[A\n",
      "Training batches on cuda:0:  40%|███▉      | 317/801 [00:02<00:03, 124.81batch/s]\u001B[A\n",
      "Training batches on cuda:0:  41%|████      | 330/801 [00:02<00:03, 125.50batch/s]\u001B[A\n",
      "Training batches on cuda:0:  43%|████▎     | 343/801 [00:02<00:03, 126.65batch/s]\u001B[A\n",
      "Training batches on cuda:0:  44%|████▍     | 356/801 [00:02<00:03, 120.43batch/s]\u001B[A\n",
      "Training batches on cuda:0:  46%|████▌     | 369/801 [00:02<00:03, 121.31batch/s]\u001B[A\n",
      "Training batches on cuda:0:  48%|████▊     | 382/801 [00:02<00:03, 122.65batch/s]\u001B[A\n",
      "Training batches on cuda:0:  49%|████▉     | 395/801 [00:03<00:03, 119.17batch/s]\u001B[A\n",
      "Training batches on cuda:0:  51%|█████     | 408/801 [00:03<00:03, 120.85batch/s]\u001B[A\n",
      "Training batches on cuda:0:  53%|█████▎    | 426/801 [00:03<00:02, 137.00batch/s]\u001B[A\n",
      "Training batches on cuda:0:  55%|█████▍    | 440/801 [00:03<00:02, 130.97batch/s]\u001B[A\n",
      "Training batches on cuda:0:  57%|█████▋    | 454/801 [00:03<00:02, 133.12batch/s]\u001B[A\n",
      "Training batches on cuda:0:  58%|█████▊    | 468/801 [00:03<00:02, 126.77batch/s]\u001B[A\n",
      "Training batches on cuda:0:  60%|██████    | 481/801 [00:03<00:02, 126.26batch/s]\u001B[A\n",
      "Training batches on cuda:0:  62%|██████▏   | 494/801 [00:03<00:02, 126.96batch/s]\u001B[A\n",
      "Training batches on cuda:0:  64%|██████▎   | 509/801 [00:03<00:02, 132.59batch/s]\u001B[A\n",
      "Training batches on cuda:0:  66%|██████▌   | 530/801 [00:03<00:01, 152.95batch/s]\u001B[A\n",
      "Training batches on cuda:0:  69%|██████▉   | 551/801 [00:04<00:01, 167.32batch/s]\u001B[A\n",
      "Training batches on cuda:0:  71%|███████▏  | 572/801 [00:04<00:01, 178.38batch/s]\u001B[A\n",
      "Training batches on cuda:0:  74%|███████▍  | 593/801 [00:04<00:01, 186.35batch/s]\u001B[A\n",
      "Training batches on cuda:0:  77%|███████▋  | 614/801 [00:04<00:00, 192.03batch/s]\u001B[A\n",
      "Training batches on cuda:0:  79%|███████▉  | 635/801 [00:04<00:00, 196.02batch/s]\u001B[A\n",
      "Training batches on cuda:0:  82%|████████▏ | 656/801 [00:04<00:00, 198.66batch/s]\u001B[A\n",
      "Training batches on cuda:0:  85%|████████▍ | 677/801 [00:04<00:00, 199.46batch/s]\u001B[A\n",
      "Training batches on cuda:0:  87%|████████▋ | 698/801 [00:04<00:00, 201.31batch/s]\u001B[A\n",
      "Training batches on cuda:0:  90%|████████▉ | 719/801 [00:04<00:00, 202.59batch/s]\u001B[A\n",
      "Training batches on cuda:0:  92%|█████████▏| 740/801 [00:04<00:00, 203.50batch/s]\u001B[A\n",
      "Training batches on cuda:0:  95%|█████████▌| 761/801 [00:05<00:00, 204.14batch/s]\u001B[A\n",
      "Training batches on cuda:0:  98%|█████████▊| 782/801 [00:05<00:00, 204.56batch/s]\u001B[A\n",
      "Training epochs on cuda:0:  72%|███████▏  | 36/50 [02:39<01:05,  4.71s/epoch, loss=0.341, prev_loss=0.341]\n",
      "Training batches on cuda:0:   0%|          | 0/801 [00:00<?, ?batch/s]\u001B[A\n",
      "Training batches on cuda:0:   2%|▏         | 13/801 [00:00<00:06, 125.04batch/s]\u001B[A\n",
      "Training batches on cuda:0:   4%|▍         | 34/801 [00:00<00:04, 169.72batch/s]\u001B[A\n",
      "Training batches on cuda:0:   7%|▋         | 55/801 [00:00<00:04, 183.83batch/s]\u001B[A\n",
      "Training batches on cuda:0:   9%|▉         | 75/801 [00:00<00:03, 189.63batch/s]\u001B[A\n",
      "Training batches on cuda:0:  12%|█▏        | 95/801 [00:00<00:03, 193.00batch/s]\u001B[A\n",
      "Training batches on cuda:0:  14%|█▍        | 115/801 [00:00<00:03, 195.17batch/s]\u001B[A\n",
      "Training batches on cuda:0:  17%|█▋        | 135/801 [00:00<00:03, 196.72batch/s]\u001B[A\n",
      "Training batches on cuda:0:  19%|█▉        | 156/801 [00:00<00:03, 197.90batch/s]\u001B[A\n",
      "Training batches on cuda:0:  22%|██▏       | 176/801 [00:00<00:03, 198.16batch/s]\u001B[A\n",
      "Training batches on cuda:0:  24%|██▍       | 196/801 [00:01<00:03, 198.17batch/s]\u001B[A\n",
      "Training batches on cuda:0:  27%|██▋       | 216/801 [00:01<00:02, 198.21batch/s]\u001B[A\n",
      "Training batches on cuda:0:  29%|██▉       | 236/801 [00:01<00:02, 198.17batch/s]\u001B[A\n",
      "Training batches on cuda:0:  32%|███▏      | 256/801 [00:01<00:02, 198.39batch/s]\u001B[A\n",
      "Training batches on cuda:0:  35%|███▍      | 277/801 [00:01<00:02, 199.08batch/s]\u001B[A\n",
      "Training batches on cuda:0:  37%|███▋      | 297/801 [00:01<00:02, 199.14batch/s]\u001B[A\n",
      "Training batches on cuda:0:  40%|███▉      | 317/801 [00:01<00:02, 199.26batch/s]\u001B[A\n",
      "Training batches on cuda:0:  42%|████▏     | 337/801 [00:01<00:02, 199.40batch/s]\u001B[A\n",
      "Training batches on cuda:0:  45%|████▍     | 358/801 [00:01<00:02, 199.75batch/s]\u001B[A\n",
      "Training batches on cuda:0:  47%|████▋     | 378/801 [00:01<00:02, 199.56batch/s]\u001B[A\n",
      "Training batches on cuda:0:  50%|████▉     | 398/801 [00:02<00:02, 199.45batch/s]\u001B[A\n",
      "Training batches on cuda:0:  52%|█████▏    | 418/801 [00:02<00:01, 199.48batch/s]\u001B[A\n",
      "Training batches on cuda:0:  55%|█████▍    | 438/801 [00:02<00:01, 199.42batch/s]\u001B[A\n",
      "Training batches on cuda:0:  57%|█████▋    | 458/801 [00:02<00:01, 199.53batch/s]\u001B[A\n",
      "Training batches on cuda:0:  60%|█████▉    | 478/801 [00:02<00:01, 199.58batch/s]\u001B[A\n",
      "Training batches on cuda:0:  62%|██████▏   | 499/801 [00:02<00:01, 199.75batch/s]\u001B[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  65%|██████▍   | 520/801 [00:02<00:01, 200.30batch/s]\u001B[A\n",
      "Training batches on cuda:0:  68%|██████▊   | 541/801 [00:02<00:01, 200.34batch/s]\u001B[A\n",
      "Training batches on cuda:0:  70%|███████   | 562/801 [00:02<00:01, 200.17batch/s]\u001B[A\n",
      "Training batches on cuda:0:  73%|███████▎  | 583/801 [00:02<00:01, 199.90batch/s]\u001B[A\n",
      "Training batches on cuda:0:  75%|███████▌  | 603/801 [00:03<00:00, 199.65batch/s]\u001B[A\n",
      "Training batches on cuda:0:  78%|███████▊  | 623/801 [00:03<00:00, 199.74batch/s]\u001B[A\n",
      "Training batches on cuda:0:  80%|████████  | 644/801 [00:03<00:00, 199.89batch/s]\u001B[A\n",
      "Training batches on cuda:0:  83%|████████▎ | 664/801 [00:03<00:00, 199.78batch/s]\u001B[A\n",
      "Training batches on cuda:0:  85%|████████▌ | 684/801 [00:03<00:00, 199.60batch/s]\u001B[A\n",
      "Training batches on cuda:0:  88%|████████▊ | 705/801 [00:03<00:00, 199.87batch/s]\u001B[A\n",
      "Training batches on cuda:0:  91%|█████████ | 725/801 [00:03<00:00, 199.65batch/s]\u001B[A\n",
      "Training batches on cuda:0:  93%|█████████▎| 745/801 [00:03<00:00, 199.33batch/s]\u001B[A\n",
      "Training batches on cuda:0:  96%|█████████▌| 765/801 [00:03<00:00, 164.76batch/s]\u001B[A\n",
      "Training batches on cuda:0:  98%|█████████▊| 784/801 [00:04<00:00, 169.18batch/s]\u001B[A\n",
      "Training epochs on cuda:0:  74%|███████▍  | 37/50 [02:43<00:59,  4.58s/epoch, loss=0.339, prev_loss=0.341]\n",
      "Training batches on cuda:0:   0%|          | 0/801 [00:00<?, ?batch/s]\u001B[A\n",
      "Training batches on cuda:0:   2%|▏         | 19/801 [00:00<00:04, 184.57batch/s]\u001B[A\n",
      "Training batches on cuda:0:   5%|▍         | 39/801 [00:00<00:03, 193.50batch/s]\u001B[A\n",
      "Training batches on cuda:0:   7%|▋         | 60/801 [00:00<00:03, 196.62batch/s]\u001B[A\n",
      "Training batches on cuda:0:  10%|▉         | 80/801 [00:00<00:03, 197.56batch/s]\u001B[A\n",
      "Training batches on cuda:0:  12%|█▏        | 100/801 [00:00<00:03, 198.13batch/s]\u001B[A\n",
      "Training batches on cuda:0:  15%|█▍        | 120/801 [00:00<00:03, 198.61batch/s]\u001B[A\n",
      "Training batches on cuda:0:  18%|█▊        | 141/801 [00:00<00:03, 199.45batch/s]\u001B[A\n",
      "Training batches on cuda:0:  20%|██        | 161/801 [00:00<00:03, 199.47batch/s]\u001B[A\n",
      "Training batches on cuda:0:  23%|██▎       | 181/801 [00:00<00:03, 199.53batch/s]\u001B[A\n",
      "Training batches on cuda:0:  25%|██▌       | 202/801 [00:01<00:02, 199.85batch/s]\u001B[A\n",
      "Training batches on cuda:0:  28%|██▊       | 222/801 [00:01<00:02, 199.79batch/s]\u001B[A\n",
      "Training batches on cuda:0:  30%|███       | 242/801 [00:01<00:02, 199.69batch/s]\u001B[A\n",
      "Training batches on cuda:0:  33%|███▎      | 262/801 [00:01<00:02, 199.73batch/s]\u001B[A\n",
      "Training batches on cuda:0:  35%|███▌      | 282/801 [00:01<00:02, 199.74batch/s]\u001B[A\n",
      "Training batches on cuda:0:  38%|███▊      | 303/801 [00:01<00:02, 199.97batch/s]\u001B[A\n",
      "Training batches on cuda:0:  40%|████      | 323/801 [00:01<00:02, 199.82batch/s]\u001B[A\n",
      "Training batches on cuda:0:  43%|████▎     | 344/801 [00:01<00:02, 200.28batch/s]\u001B[A\n",
      "Training batches on cuda:0:  46%|████▌     | 365/801 [00:01<00:02, 200.00batch/s]\u001B[A\n",
      "Training batches on cuda:0:  48%|████▊     | 385/801 [00:01<00:02, 199.91batch/s]\u001B[A\n",
      "Training batches on cuda:0:  51%|█████     | 406/801 [00:02<00:01, 200.07batch/s]\u001B[A\n",
      "Training batches on cuda:0:  53%|█████▎    | 427/801 [00:02<00:01, 199.81batch/s]\u001B[A\n",
      "Training batches on cuda:0:  56%|█████▌    | 447/801 [00:02<00:01, 199.77batch/s]\u001B[A\n",
      "Training batches on cuda:0:  58%|█████▊    | 467/801 [00:02<00:01, 199.74batch/s]\u001B[A\n",
      "Training batches on cuda:0:  61%|██████    | 488/801 [00:02<00:01, 199.91batch/s]\u001B[A\n",
      "Training batches on cuda:0:  64%|██████▎   | 509/801 [00:02<00:01, 200.12batch/s]\u001B[A\n",
      "Training batches on cuda:0:  66%|██████▌   | 530/801 [00:02<00:01, 200.10batch/s]\u001B[A\n",
      "Training batches on cuda:0:  69%|██████▉   | 551/801 [00:02<00:01, 199.87batch/s]\u001B[A\n",
      "Training batches on cuda:0:  71%|███████▏  | 572/801 [00:02<00:01, 200.03batch/s]\u001B[A\n",
      "Training batches on cuda:0:  74%|███████▍  | 593/801 [00:02<00:01, 199.77batch/s]\u001B[A\n",
      "Training batches on cuda:0:  77%|███████▋  | 613/801 [00:03<00:00, 199.65batch/s]\u001B[A\n",
      "Training batches on cuda:0:  79%|███████▉  | 633/801 [00:03<00:00, 199.51batch/s]\u001B[A\n",
      "Training batches on cuda:0:  82%|████████▏ | 654/801 [00:03<00:00, 199.78batch/s]\u001B[A\n",
      "Training batches on cuda:0:  84%|████████▍ | 675/801 [00:03<00:00, 199.93batch/s]\u001B[A\n",
      "Training batches on cuda:0:  87%|████████▋ | 696/801 [00:03<00:00, 200.20batch/s]\u001B[A\n",
      "Training batches on cuda:0:  90%|████████▉ | 717/801 [00:03<00:00, 200.15batch/s]\u001B[A\n",
      "Training batches on cuda:0:  92%|█████████▏| 738/801 [00:03<00:00, 199.91batch/s]\u001B[A\n",
      "Training batches on cuda:0:  95%|█████████▍| 758/801 [00:03<00:00, 199.77batch/s]\u001B[A\n",
      "Training batches on cuda:0:  97%|█████████▋| 779/801 [00:03<00:00, 200.00batch/s]\u001B[A\n",
      "Training batches on cuda:0: 100%|█████████▉| 799/801 [00:04<00:00, 199.79batch/s]\u001B[A\n",
      "Training epochs on cuda:0:  76%|███████▌  | 38/50 [02:47<00:53,  4.46s/epoch, loss=0.338, prev_loss=0.339]\n",
      "Training batches on cuda:0:   0%|          | 0/801 [00:00<?, ?batch/s]\u001B[A\n",
      "Training batches on cuda:0:   2%|▏         | 19/801 [00:00<00:04, 184.65batch/s]\u001B[A\n",
      "Training batches on cuda:0:   5%|▍         | 39/801 [00:00<00:03, 192.94batch/s]\u001B[A\n",
      "Training batches on cuda:0:   7%|▋         | 60/801 [00:00<00:03, 196.43batch/s]\u001B[A\n",
      "Training batches on cuda:0:  10%|▉         | 80/801 [00:00<00:03, 197.03batch/s]\u001B[A\n",
      "Training batches on cuda:0:  13%|█▎        | 101/801 [00:00<00:03, 198.27batch/s]\u001B[A\n",
      "Training batches on cuda:0:  15%|█▌        | 121/801 [00:00<00:03, 198.57batch/s]\u001B[A\n",
      "Training batches on cuda:0:  18%|█▊        | 141/801 [00:00<00:03, 198.85batch/s]\u001B[A\n",
      "Training batches on cuda:0:  20%|██        | 162/801 [00:00<00:03, 199.49batch/s]\u001B[A\n",
      "Training batches on cuda:0:  23%|██▎       | 183/801 [00:00<00:03, 199.76batch/s]\u001B[A\n",
      "Training batches on cuda:0:  25%|██▌       | 204/801 [00:01<00:02, 200.27batch/s]\u001B[A\n",
      "Training batches on cuda:0:  28%|██▊       | 225/801 [00:01<00:02, 200.30batch/s]\u001B[A\n",
      "Training batches on cuda:0:  31%|███       | 246/801 [00:01<00:02, 200.26batch/s]\u001B[A\n",
      "Training batches on cuda:0:  33%|███▎      | 267/801 [00:01<00:02, 200.15batch/s]\u001B[A\n",
      "Training batches on cuda:0:  36%|███▌      | 288/801 [00:01<00:02, 200.07batch/s]\u001B[A\n",
      "Training batches on cuda:0:  39%|███▊      | 309/801 [00:01<00:02, 200.06batch/s]\u001B[A\n",
      "Training batches on cuda:0:  41%|████      | 330/801 [00:01<00:02, 200.18batch/s]\u001B[A\n",
      "Training batches on cuda:0:  44%|████▍     | 351/801 [00:01<00:02, 200.29batch/s]\u001B[A\n",
      "Training batches on cuda:0:  46%|████▋     | 372/801 [00:01<00:02, 200.09batch/s]\u001B[A\n",
      "Training batches on cuda:0:  49%|████▉     | 393/801 [00:01<00:02, 200.01batch/s]\u001B[A\n",
      "Training batches on cuda:0:  52%|█████▏    | 414/801 [00:02<00:01, 200.15batch/s]\u001B[A\n",
      "Training batches on cuda:0:  54%|█████▍    | 435/801 [00:02<00:01, 200.23batch/s]\u001B[A\n",
      "Training batches on cuda:0:  57%|█████▋    | 456/801 [00:02<00:01, 200.21batch/s]\u001B[A\n",
      "Training batches on cuda:0:  60%|█████▉    | 477/801 [00:02<00:01, 199.99batch/s]\u001B[A\n",
      "Training batches on cuda:0:  62%|██████▏   | 497/801 [00:02<00:01, 199.75batch/s]\u001B[A\n",
      "Training batches on cuda:0:  65%|██████▍   | 518/801 [00:02<00:01, 200.21batch/s]\u001B[A\n",
      "Training batches on cuda:0:  67%|██████▋   | 539/801 [00:02<00:01, 199.94batch/s]\u001B[A\n",
      "Training batches on cuda:0:  70%|██████▉   | 560/801 [00:02<00:01, 200.11batch/s]\u001B[A\n",
      "Training batches on cuda:0:  73%|███████▎  | 581/801 [00:02<00:01, 200.02batch/s]\u001B[A\n",
      "Training batches on cuda:0:  75%|███████▌  | 602/801 [00:03<00:00, 200.15batch/s]\u001B[A\n",
      "Training batches on cuda:0:  78%|███████▊  | 623/801 [00:03<00:00, 200.02batch/s]\u001B[A\n",
      "Training batches on cuda:0:  80%|████████  | 644/801 [00:03<00:00, 199.83batch/s]\u001B[A\n",
      "Training batches on cuda:0:  83%|████████▎ | 664/801 [00:03<00:00, 199.87batch/s]\u001B[A\n",
      "Training batches on cuda:0:  85%|████████▌ | 684/801 [00:03<00:00, 199.60batch/s]\u001B[A\n",
      "Training batches on cuda:0:  88%|████████▊ | 705/801 [00:03<00:00, 199.90batch/s]\u001B[A\n",
      "Training batches on cuda:0:  91%|█████████ | 725/801 [00:03<00:00, 199.65batch/s]\u001B[A\n",
      "Training batches on cuda:0:  93%|█████████▎| 745/801 [00:03<00:00, 199.72batch/s]\u001B[A\n",
      "Training batches on cuda:0:  96%|█████████▌| 765/801 [00:03<00:00, 199.64batch/s]\u001B[A\n",
      "Training batches on cuda:0:  98%|█████████▊| 785/801 [00:03<00:00, 199.58batch/s]\u001B[A\n",
      "Training epochs on cuda:0:  78%|███████▊  | 39/50 [02:51<00:48,  4.37s/epoch, loss=0.338, prev_loss=0.338]\n",
      "Training batches on cuda:0:   0%|          | 0/801 [00:00<?, ?batch/s]\u001B[A\n",
      "Training batches on cuda:0:   2%|▏         | 19/801 [00:00<00:04, 183.15batch/s]\u001B[A\n",
      "Training batches on cuda:0:   5%|▍         | 40/801 [00:00<00:03, 193.72batch/s]\u001B[A\n",
      "Training batches on cuda:0:   8%|▊         | 61/801 [00:00<00:03, 198.24batch/s]\u001B[A\n",
      "Training batches on cuda:0:  10%|█         | 82/801 [00:00<00:03, 199.53batch/s]\u001B[A\n",
      "Training batches on cuda:0:  13%|█▎        | 103/801 [00:00<00:03, 200.43batch/s]\u001B[A\n",
      "Training batches on cuda:0:  15%|█▌        | 124/801 [00:00<00:03, 201.25batch/s]\u001B[A\n",
      "Training batches on cuda:0:  18%|█▊        | 145/801 [00:00<00:03, 202.19batch/s]\u001B[A\n",
      "Training batches on cuda:0:  21%|██        | 166/801 [00:00<00:03, 202.44batch/s]\u001B[A\n",
      "Training batches on cuda:0:  23%|██▎       | 187/801 [00:00<00:03, 202.56batch/s]\u001B[A\n",
      "Training batches on cuda:0:  26%|██▌       | 208/801 [00:01<00:02, 202.89batch/s]\u001B[A\n",
      "Training batches on cuda:0:  29%|██▊       | 229/801 [00:01<00:02, 203.29batch/s]\u001B[A\n",
      "Training batches on cuda:0:  31%|███       | 250/801 [00:01<00:02, 203.44batch/s]\u001B[A\n",
      "Training batches on cuda:0:  34%|███▍      | 271/801 [00:01<00:02, 203.61batch/s]\u001B[A\n",
      "Training batches on cuda:0:  36%|███▋      | 292/801 [00:01<00:02, 203.67batch/s]\u001B[A\n",
      "Training batches on cuda:0:  39%|███▉      | 313/801 [00:01<00:02, 202.31batch/s]\u001B[A\n",
      "Training batches on cuda:0:  42%|████▏     | 334/801 [00:01<00:02, 202.66batch/s]\u001B[A\n",
      "Training batches on cuda:0:  44%|████▍     | 355/801 [00:01<00:02, 202.84batch/s]\u001B[A\n",
      "Training batches on cuda:0:  47%|████▋     | 376/801 [00:01<00:02, 203.02batch/s]\u001B[A\n",
      "Training batches on cuda:0:  50%|████▉     | 397/801 [00:01<00:01, 202.95batch/s]\u001B[A\n",
      "Training batches on cuda:0:  52%|█████▏    | 418/801 [00:02<00:01, 203.33batch/s]\u001B[A\n",
      "Training batches on cuda:0:  55%|█████▍    | 439/801 [00:02<00:01, 203.08batch/s]\u001B[A\n",
      "Training batches on cuda:0:  57%|█████▋    | 460/801 [00:02<00:01, 203.30batch/s]\u001B[A\n",
      "Training batches on cuda:0:  60%|██████    | 481/801 [00:02<00:01, 203.60batch/s]\u001B[A\n",
      "Training batches on cuda:0:  63%|██████▎   | 502/801 [00:02<00:01, 203.72batch/s]\u001B[A\n",
      "Training batches on cuda:0:  65%|██████▌   | 523/801 [00:02<00:01, 203.75batch/s]\u001B[A\n",
      "Training batches on cuda:0:  68%|██████▊   | 544/801 [00:02<00:01, 203.90batch/s]\u001B[A\n",
      "Training batches on cuda:0:  71%|███████   | 565/801 [00:02<00:01, 203.85batch/s]\u001B[A\n",
      "Training batches on cuda:0:  73%|███████▎  | 586/801 [00:02<00:01, 203.86batch/s]\u001B[A\n",
      "Training batches on cuda:0:  76%|███████▌  | 607/801 [00:02<00:00, 204.04batch/s]\u001B[A\n",
      "Training batches on cuda:0:  78%|███████▊  | 628/801 [00:03<00:00, 204.02batch/s]\u001B[A\n",
      "Training batches on cuda:0:  81%|████████  | 649/801 [00:03<00:00, 203.92batch/s]\u001B[A\n",
      "Training batches on cuda:0:  84%|████████▎ | 670/801 [00:03<00:00, 203.84batch/s]\u001B[A\n",
      "Training batches on cuda:0:  86%|████████▋ | 691/801 [00:03<00:00, 203.69batch/s]\u001B[A\n",
      "Training batches on cuda:0:  89%|████████▉ | 712/801 [00:03<00:00, 203.71batch/s]\u001B[A\n",
      "Training batches on cuda:0:  92%|█████████▏| 733/801 [00:03<00:00, 203.85batch/s]\u001B[A\n",
      "Training batches on cuda:0:  94%|█████████▍| 754/801 [00:03<00:00, 203.75batch/s]\u001B[A\n",
      "Training batches on cuda:0:  97%|█████████▋| 775/801 [00:03<00:00, 203.69batch/s]\u001B[A\n",
      "Training batches on cuda:0:  99%|█████████▉| 796/801 [00:03<00:00, 203.67batch/s]\u001B[A\n",
      "Training epochs on cuda:0:  80%|████████  | 40/50 [02:55<00:42,  4.30s/epoch, loss=0.337, prev_loss=0.338]\n",
      "Training batches on cuda:0:   0%|          | 0/801 [00:00<?, ?batch/s]\u001B[A\n",
      "Training batches on cuda:0:   2%|▏         | 19/801 [00:00<00:04, 186.83batch/s]\u001B[A\n",
      "Training batches on cuda:0:   5%|▍         | 40/801 [00:00<00:03, 196.70batch/s]\u001B[A\n",
      "Training batches on cuda:0:   8%|▊         | 61/801 [00:00<00:03, 199.84batch/s]\u001B[A\n",
      "Training batches on cuda:0:  10%|█         | 82/801 [00:00<00:03, 200.18batch/s]\u001B[A\n",
      "Training batches on cuda:0:  13%|█▎        | 103/801 [00:00<00:03, 201.42batch/s]\u001B[A\n",
      "Training batches on cuda:0:  15%|█▌        | 124/801 [00:00<00:03, 202.39batch/s]\u001B[A\n",
      "Training batches on cuda:0:  18%|█▊        | 145/801 [00:00<00:03, 202.48batch/s]\u001B[A\n",
      "Training batches on cuda:0:  21%|██        | 166/801 [00:00<00:03, 203.03batch/s]\u001B[A\n",
      "Training batches on cuda:0:  23%|██▎       | 187/801 [00:00<00:03, 203.05batch/s]\u001B[A\n",
      "Training batches on cuda:0:  26%|██▌       | 208/801 [00:01<00:02, 202.97batch/s]\u001B[A\n",
      "Training batches on cuda:0:  29%|██▊       | 229/801 [00:01<00:02, 202.85batch/s]\u001B[A\n",
      "Training batches on cuda:0:  31%|███       | 250/801 [00:01<00:02, 203.14batch/s]\u001B[A\n",
      "Training batches on cuda:0:  34%|███▍      | 271/801 [00:01<00:02, 203.13batch/s]\u001B[A\n",
      "Training batches on cuda:0:  36%|███▋      | 292/801 [00:01<00:02, 203.24batch/s]\u001B[A\n",
      "Training batches on cuda:0:  39%|███▉      | 313/801 [00:01<00:02, 203.55batch/s]\u001B[A\n",
      "Training batches on cuda:0:  42%|████▏     | 334/801 [00:01<00:02, 203.59batch/s]\u001B[A\n",
      "Training batches on cuda:0:  44%|████▍     | 355/801 [00:01<00:02, 203.52batch/s]\u001B[A\n",
      "Training batches on cuda:0:  47%|████▋     | 376/801 [00:01<00:02, 203.50batch/s]\u001B[A\n",
      "Training batches on cuda:0:  50%|████▉     | 397/801 [00:01<00:01, 203.64batch/s]\u001B[A\n",
      "Training batches on cuda:0:  52%|█████▏    | 418/801 [00:02<00:01, 203.66batch/s]\u001B[A\n",
      "Training batches on cuda:0:  55%|█████▍    | 439/801 [00:02<00:01, 203.56batch/s]\u001B[A\n",
      "Training batches on cuda:0:  57%|█████▋    | 460/801 [00:02<00:01, 203.58batch/s]\u001B[A\n",
      "Training batches on cuda:0:  60%|██████    | 481/801 [00:02<00:01, 203.57batch/s]\u001B[A\n",
      "Training batches on cuda:0:  63%|██████▎   | 502/801 [00:02<00:01, 203.52batch/s]\u001B[A\n",
      "Training batches on cuda:0:  65%|██████▌   | 523/801 [00:02<00:01, 203.58batch/s]\u001B[A\n",
      "Training batches on cuda:0:  68%|██████▊   | 544/801 [00:02<00:01, 203.72batch/s]\u001B[A\n",
      "Training batches on cuda:0:  71%|███████   | 565/801 [00:02<00:01, 203.70batch/s]\u001B[A\n",
      "Training batches on cuda:0:  73%|███████▎  | 586/801 [00:02<00:01, 203.64batch/s]\u001B[A\n",
      "Training batches on cuda:0:  76%|███████▌  | 607/801 [00:02<00:00, 203.64batch/s]\u001B[A\n",
      "Training batches on cuda:0:  78%|███████▊  | 628/801 [00:03<00:00, 203.69batch/s]\u001B[A\n",
      "Training batches on cuda:0:  81%|████████  | 649/801 [00:03<00:00, 202.62batch/s]\u001B[A\n",
      "Training batches on cuda:0:  84%|████████▎ | 670/801 [00:03<00:00, 202.24batch/s]\u001B[A\n",
      "Training batches on cuda:0:  86%|████████▋ | 691/801 [00:03<00:00, 201.81batch/s]\u001B[A\n",
      "Training batches on cuda:0:  89%|████████▉ | 712/801 [00:03<00:00, 201.47batch/s]\u001B[A\n",
      "Training batches on cuda:0:  92%|█████████▏| 733/801 [00:03<00:00, 201.20batch/s]\u001B[A\n",
      "Training batches on cuda:0:  94%|█████████▍| 754/801 [00:03<00:00, 201.27batch/s]\u001B[A\n",
      "Training batches on cuda:0:  97%|█████████▋| 775/801 [00:03<00:00, 201.28batch/s]\u001B[A\n",
      "Training batches on cuda:0:  99%|█████████▉| 796/801 [00:03<00:00, 201.29batch/s]\u001B[A\n",
      "Training epochs on cuda:0:  82%|████████▏ | 41/50 [02:59<00:38,  4.24s/epoch, loss=0.336, prev_loss=0.337]\n",
      "Training batches on cuda:0:   0%|          | 0/801 [00:00<?, ?batch/s]\u001B[A\n",
      "Training batches on cuda:0:   2%|▏         | 19/801 [00:00<00:04, 187.69batch/s]\u001B[A\n",
      "Training batches on cuda:0:   5%|▍         | 40/801 [00:00<00:03, 197.12batch/s]\u001B[A\n",
      "Training batches on cuda:0:   8%|▊         | 61/801 [00:00<00:03, 199.65batch/s]\u001B[A\n",
      "Training batches on cuda:0:  10%|█         | 82/801 [00:00<00:03, 200.37batch/s]\u001B[A\n",
      "Training batches on cuda:0:  13%|█▎        | 103/801 [00:00<00:03, 201.65batch/s]\u001B[A\n",
      "Training batches on cuda:0:  15%|█▌        | 124/801 [00:00<00:03, 202.33batch/s]\u001B[A\n",
      "Training batches on cuda:0:  18%|█▊        | 145/801 [00:00<00:03, 202.44batch/s]\u001B[A\n",
      "Training batches on cuda:0:  21%|██        | 166/801 [00:00<00:03, 202.81batch/s]\u001B[A\n",
      "Training batches on cuda:0:  23%|██▎       | 187/801 [00:00<00:03, 203.22batch/s]\u001B[A\n",
      "Training batches on cuda:0:  26%|██▌       | 208/801 [00:01<00:02, 203.28batch/s]\u001B[A\n",
      "Training batches on cuda:0:  29%|██▊       | 229/801 [00:01<00:02, 203.49batch/s]\u001B[A\n",
      "Training batches on cuda:0:  31%|███       | 250/801 [00:01<00:02, 203.66batch/s]\u001B[A\n",
      "Training batches on cuda:0:  34%|███▍      | 271/801 [00:01<00:02, 203.74batch/s]\u001B[A\n",
      "Training batches on cuda:0:  36%|███▋      | 292/801 [00:01<00:02, 203.45batch/s]\u001B[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  39%|███▉      | 313/801 [00:01<00:02, 203.29batch/s]\u001B[A\n",
      "Training batches on cuda:0:  42%|████▏     | 334/801 [00:01<00:02, 203.48batch/s]\u001B[A\n",
      "Training batches on cuda:0:  44%|████▍     | 355/801 [00:01<00:02, 203.25batch/s]\u001B[A\n",
      "Training batches on cuda:0:  47%|████▋     | 376/801 [00:01<00:02, 203.02batch/s]\u001B[A\n",
      "Training batches on cuda:0:  50%|████▉     | 397/801 [00:01<00:01, 202.77batch/s]\u001B[A\n",
      "Training batches on cuda:0:  52%|█████▏    | 418/801 [00:02<00:01, 202.58batch/s]\u001B[A\n",
      "Training batches on cuda:0:  55%|█████▍    | 439/801 [00:02<00:01, 202.83batch/s]\u001B[A\n",
      "Training batches on cuda:0:  57%|█████▋    | 460/801 [00:02<00:01, 203.03batch/s]\u001B[A\n",
      "Training batches on cuda:0:  60%|██████    | 481/801 [00:02<00:01, 202.89batch/s]\u001B[A\n",
      "Training batches on cuda:0:  63%|██████▎   | 502/801 [00:02<00:01, 202.87batch/s]\u001B[A\n",
      "Training batches on cuda:0:  65%|██████▌   | 523/801 [00:02<00:01, 203.09batch/s]\u001B[A\n",
      "Training batches on cuda:0:  68%|██████▊   | 544/801 [00:02<00:01, 203.20batch/s]\u001B[A\n",
      "Training batches on cuda:0:  71%|███████   | 565/801 [00:02<00:01, 203.46batch/s]\u001B[A\n",
      "Training batches on cuda:0:  73%|███████▎  | 586/801 [00:02<00:01, 203.49batch/s]\u001B[A\n",
      "Training batches on cuda:0:  76%|███████▌  | 607/801 [00:02<00:00, 203.18batch/s]\u001B[A\n",
      "Training batches on cuda:0:  78%|███████▊  | 628/801 [00:03<00:00, 203.28batch/s]\u001B[A\n",
      "Training batches on cuda:0:  81%|████████  | 649/801 [00:03<00:00, 203.48batch/s]\u001B[A\n",
      "Training batches on cuda:0:  84%|████████▎ | 670/801 [00:03<00:00, 203.44batch/s]\u001B[A\n",
      "Training batches on cuda:0:  86%|████████▋ | 691/801 [00:03<00:00, 203.48batch/s]\u001B[A\n",
      "Training batches on cuda:0:  89%|████████▉ | 712/801 [00:03<00:00, 203.41batch/s]\u001B[A\n",
      "Training batches on cuda:0:  92%|█████████▏| 733/801 [00:03<00:00, 203.56batch/s]\u001B[A\n",
      "Training batches on cuda:0:  94%|█████████▍| 754/801 [00:03<00:00, 203.35batch/s]\u001B[A\n",
      "Training batches on cuda:0:  97%|█████████▋| 775/801 [00:03<00:00, 203.20batch/s]\u001B[A\n",
      "Training batches on cuda:0:  99%|█████████▉| 796/801 [00:03<00:00, 203.30batch/s]\u001B[A\n",
      "Training epochs on cuda:0:  84%|████████▍ | 42/50 [03:04<00:33,  4.20s/epoch, loss=0.335, prev_loss=0.336]\n",
      "Training batches on cuda:0:   0%|          | 0/801 [00:00<?, ?batch/s]\u001B[A\n",
      "Training batches on cuda:0:   2%|▏         | 19/801 [00:00<00:04, 186.07batch/s]\u001B[A\n",
      "Training batches on cuda:0:   5%|▍         | 40/801 [00:00<00:03, 196.46batch/s]\u001B[A\n",
      "Training batches on cuda:0:   8%|▊         | 61/801 [00:00<00:03, 199.15batch/s]\u001B[A\n",
      "Training batches on cuda:0:  10%|█         | 82/801 [00:00<00:03, 199.89batch/s]\u001B[A\n",
      "Training batches on cuda:0:  13%|█▎        | 103/801 [00:00<00:03, 201.12batch/s]\u001B[A\n",
      "Training batches on cuda:0:  15%|█▌        | 124/801 [00:00<00:03, 201.68batch/s]\u001B[A\n",
      "Training batches on cuda:0:  18%|█▊        | 145/801 [00:00<00:03, 201.97batch/s]\u001B[A\n",
      "Training batches on cuda:0:  21%|██        | 166/801 [00:00<00:03, 201.55batch/s]\u001B[A\n",
      "Training batches on cuda:0:  23%|██▎       | 187/801 [00:00<00:03, 202.10batch/s]\u001B[A\n",
      "Training batches on cuda:0:  26%|██▌       | 208/801 [00:01<00:02, 202.44batch/s]\u001B[A\n",
      "Training batches on cuda:0:  29%|██▊       | 229/801 [00:01<00:02, 202.71batch/s]\u001B[A\n",
      "Training batches on cuda:0:  31%|███       | 250/801 [00:01<00:02, 202.89batch/s]\u001B[A\n",
      "Training batches on cuda:0:  34%|███▍      | 271/801 [00:01<00:02, 202.67batch/s]\u001B[A\n",
      "Training batches on cuda:0:  36%|███▋      | 292/801 [00:01<00:02, 202.84batch/s]\u001B[A\n",
      "Training batches on cuda:0:  39%|███▉      | 313/801 [00:01<00:02, 202.87batch/s]\u001B[A\n",
      "Training batches on cuda:0:  42%|████▏     | 334/801 [00:01<00:02, 202.85batch/s]\u001B[A\n",
      "Training batches on cuda:0:  44%|████▍     | 355/801 [00:01<00:02, 202.71batch/s]\u001B[A\n",
      "Training batches on cuda:0:  47%|████▋     | 376/801 [00:01<00:02, 202.63batch/s]\u001B[A\n",
      "Training batches on cuda:0:  50%|████▉     | 397/801 [00:01<00:01, 202.46batch/s]\u001B[A\n",
      "Training batches on cuda:0:  52%|█████▏    | 418/801 [00:02<00:01, 202.68batch/s]\u001B[A\n",
      "Training batches on cuda:0:  55%|█████▍    | 439/801 [00:02<00:01, 202.74batch/s]\u001B[A\n",
      "Training batches on cuda:0:  57%|█████▋    | 460/801 [00:02<00:01, 202.56batch/s]\u001B[A\n",
      "Training batches on cuda:0:  60%|██████    | 481/801 [00:02<00:01, 202.90batch/s]\u001B[A\n",
      "Training batches on cuda:0:  63%|██████▎   | 502/801 [00:02<00:01, 202.69batch/s]\u001B[A\n",
      "Training batches on cuda:0:  65%|██████▌   | 523/801 [00:02<00:01, 202.69batch/s]\u001B[A\n",
      "Training batches on cuda:0:  68%|██████▊   | 544/801 [00:02<00:01, 202.55batch/s]\u001B[A\n",
      "Training batches on cuda:0:  71%|███████   | 565/801 [00:02<00:01, 202.49batch/s]\u001B[A\n",
      "Training batches on cuda:0:  73%|███████▎  | 586/801 [00:02<00:01, 202.87batch/s]\u001B[A\n",
      "Training batches on cuda:0:  76%|███████▌  | 607/801 [00:03<00:00, 202.86batch/s]\u001B[A\n",
      "Training batches on cuda:0:  78%|███████▊  | 628/801 [00:03<00:00, 203.00batch/s]\u001B[A\n",
      "Training batches on cuda:0:  81%|████████  | 649/801 [00:03<00:00, 202.91batch/s]\u001B[A\n",
      "Training batches on cuda:0:  84%|████████▎ | 670/801 [00:03<00:00, 202.82batch/s]\u001B[A\n",
      "Training batches on cuda:0:  86%|████████▋ | 691/801 [00:03<00:00, 202.88batch/s]\u001B[A\n",
      "Training batches on cuda:0:  89%|████████▉ | 712/801 [00:03<00:00, 202.69batch/s]\u001B[A\n",
      "Training batches on cuda:0:  92%|█████████▏| 733/801 [00:03<00:00, 202.65batch/s]\u001B[A\n",
      "Training batches on cuda:0:  94%|█████████▍| 754/801 [00:03<00:00, 202.56batch/s]\u001B[A\n",
      "Training batches on cuda:0:  97%|█████████▋| 775/801 [00:03<00:00, 202.72batch/s]\u001B[A\n",
      "Training batches on cuda:0:  99%|█████████▉| 796/801 [00:03<00:00, 202.50batch/s]\u001B[A\n",
      "Training epochs on cuda:0:  86%|████████▌ | 43/50 [03:08<00:29,  4.18s/epoch, loss=0.336, prev_loss=0.335]\n",
      "Training batches on cuda:0:   0%|          | 0/801 [00:00<?, ?batch/s]\u001B[A\n",
      "Training batches on cuda:0:   2%|▏         | 19/801 [00:00<00:04, 187.22batch/s]\u001B[A\n",
      "Training batches on cuda:0:   5%|▍         | 40/801 [00:00<00:03, 196.55batch/s]\u001B[A\n",
      "Training batches on cuda:0:   8%|▊         | 61/801 [00:00<00:03, 199.04batch/s]\u001B[A\n",
      "Training batches on cuda:0:  10%|█         | 81/801 [00:00<00:03, 199.26batch/s]\u001B[A\n",
      "Training batches on cuda:0:  13%|█▎        | 102/801 [00:00<00:03, 200.55batch/s]\u001B[A\n",
      "Training batches on cuda:0:  15%|█▌        | 123/801 [00:00<00:03, 201.58batch/s]\u001B[A\n",
      "Training batches on cuda:0:  18%|█▊        | 144/801 [00:00<00:03, 202.21batch/s]\u001B[A\n",
      "Training batches on cuda:0:  21%|██        | 165/801 [00:00<00:03, 202.64batch/s]\u001B[A\n",
      "Training batches on cuda:0:  23%|██▎       | 186/801 [00:00<00:03, 202.86batch/s]\u001B[A\n",
      "Training batches on cuda:0:  26%|██▌       | 207/801 [00:01<00:02, 202.00batch/s]\u001B[A\n",
      "Training batches on cuda:0:  28%|██▊       | 228/801 [00:01<00:02, 201.94batch/s]\u001B[A\n",
      "Training batches on cuda:0:  31%|███       | 249/801 [00:01<00:02, 201.36batch/s]\u001B[A\n",
      "Training batches on cuda:0:  34%|███▎      | 270/801 [00:01<00:02, 201.60batch/s]\u001B[A\n",
      "Training batches on cuda:0:  36%|███▋      | 291/801 [00:01<00:02, 200.20batch/s]\u001B[A\n",
      "Training batches on cuda:0:  39%|███▉      | 312/801 [00:01<00:02, 200.64batch/s]\u001B[A\n",
      "Training batches on cuda:0:  42%|████▏     | 333/801 [00:01<00:02, 199.25batch/s]\u001B[A\n",
      "Training batches on cuda:0:  44%|████▍     | 354/801 [00:01<00:02, 199.56batch/s]\u001B[A\n",
      "Training batches on cuda:0:  47%|████▋     | 375/801 [00:01<00:02, 200.13batch/s]\u001B[A\n",
      "Training batches on cuda:0:  49%|████▉     | 396/801 [00:01<00:02, 200.52batch/s]\u001B[A\n",
      "Training batches on cuda:0:  52%|█████▏    | 417/801 [00:02<00:01, 200.44batch/s]\u001B[A\n",
      "Training batches on cuda:0:  55%|█████▍    | 438/801 [00:02<00:01, 200.81batch/s]\u001B[A\n",
      "Training batches on cuda:0:  57%|█████▋    | 459/801 [00:02<00:01, 200.74batch/s]\u001B[A\n",
      "Training batches on cuda:0:  60%|█████▉    | 480/801 [00:02<00:01, 200.84batch/s]\u001B[A\n",
      "Training batches on cuda:0:  63%|██████▎   | 501/801 [00:02<00:01, 200.90batch/s]\u001B[A\n",
      "Training batches on cuda:0:  65%|██████▌   | 522/801 [00:02<00:01, 201.04batch/s]\u001B[A\n",
      "Training batches on cuda:0:  68%|██████▊   | 543/801 [00:02<00:01, 201.11batch/s]\u001B[A\n",
      "Training batches on cuda:0:  70%|███████   | 564/801 [00:02<00:01, 200.88batch/s]\u001B[A\n",
      "Training batches on cuda:0:  73%|███████▎  | 585/801 [00:02<00:01, 200.65batch/s]\u001B[A\n",
      "Training batches on cuda:0:  76%|███████▌  | 606/801 [00:03<00:00, 200.47batch/s]\u001B[A\n",
      "Training batches on cuda:0:  78%|███████▊  | 627/801 [00:03<00:00, 200.88batch/s]\u001B[A\n",
      "Training batches on cuda:0:  81%|████████  | 648/801 [00:03<00:00, 200.78batch/s]\u001B[A\n",
      "Training batches on cuda:0:  84%|████████▎ | 669/801 [00:03<00:00, 201.16batch/s]\u001B[A\n",
      "Training batches on cuda:0:  86%|████████▌ | 690/801 [00:03<00:00, 200.86batch/s]\u001B[A\n",
      "Training batches on cuda:0:  89%|████████▉ | 711/801 [00:03<00:00, 201.05batch/s]\u001B[A\n",
      "Training batches on cuda:0:  91%|█████████▏| 732/801 [00:03<00:00, 201.25batch/s]\u001B[A\n",
      "Training batches on cuda:0:  94%|█████████▍| 753/801 [00:03<00:00, 201.16batch/s]\u001B[A\n",
      "Training batches on cuda:0:  97%|█████████▋| 774/801 [00:03<00:00, 201.19batch/s]\u001B[A\n",
      "Training batches on cuda:0:  99%|█████████▉| 795/801 [00:03<00:00, 200.95batch/s]\u001B[A\n",
      "Training epochs on cuda:0:  88%|████████▊ | 44/50 [03:12<00:25,  4.17s/epoch, loss=0.333, prev_loss=0.336]\n",
      "Training batches on cuda:0:   0%|          | 0/801 [00:00<?, ?batch/s]\u001B[A\n",
      "Training batches on cuda:0:   2%|▏         | 19/801 [00:00<00:04, 186.83batch/s]\u001B[A\n",
      "Training batches on cuda:0:   5%|▍         | 39/801 [00:00<00:03, 194.39batch/s]\u001B[A\n",
      "Training batches on cuda:0:   7%|▋         | 60/801 [00:00<00:03, 198.22batch/s]\u001B[A\n",
      "Training batches on cuda:0:  10%|▉         | 80/801 [00:00<00:03, 198.87batch/s]\u001B[A\n",
      "Training batches on cuda:0:  13%|█▎        | 101/801 [00:00<00:03, 200.26batch/s]\u001B[A\n",
      "Training batches on cuda:0:  15%|█▌        | 122/801 [00:00<00:03, 201.35batch/s]\u001B[A\n",
      "Training batches on cuda:0:  18%|█▊        | 143/801 [00:00<00:03, 201.72batch/s]\u001B[A\n",
      "Training batches on cuda:0:  20%|██        | 164/801 [00:00<00:03, 201.93batch/s]\u001B[A\n",
      "Training batches on cuda:0:  23%|██▎       | 185/801 [00:00<00:03, 202.08batch/s]\u001B[A\n",
      "Training batches on cuda:0:  26%|██▌       | 206/801 [00:01<00:02, 202.51batch/s]\u001B[A\n",
      "Training batches on cuda:0:  28%|██▊       | 227/801 [00:01<00:02, 202.77batch/s]\u001B[A\n",
      "Training batches on cuda:0:  31%|███       | 248/801 [00:01<00:02, 202.97batch/s]\u001B[A\n",
      "Training batches on cuda:0:  34%|███▎      | 269/801 [00:01<00:02, 203.10batch/s]\u001B[A\n",
      "Training batches on cuda:0:  36%|███▌      | 290/801 [00:01<00:02, 203.12batch/s]\u001B[A\n",
      "Training batches on cuda:0:  39%|███▉      | 311/801 [00:01<00:02, 202.75batch/s]\u001B[A\n",
      "Training batches on cuda:0:  41%|████▏     | 332/801 [00:01<00:02, 202.76batch/s]\u001B[A\n",
      "Training batches on cuda:0:  44%|████▍     | 353/801 [00:01<00:02, 202.44batch/s]\u001B[A\n",
      "Training batches on cuda:0:  47%|████▋     | 374/801 [00:01<00:02, 202.44batch/s]\u001B[A\n",
      "Training batches on cuda:0:  49%|████▉     | 395/801 [00:01<00:02, 202.45batch/s]\u001B[A\n",
      "Training batches on cuda:0:  52%|█████▏    | 416/801 [00:02<00:01, 202.33batch/s]\u001B[A\n",
      "Training batches on cuda:0:  55%|█████▍    | 437/801 [00:02<00:01, 202.23batch/s]\u001B[A\n",
      "Training batches on cuda:0:  57%|█████▋    | 458/801 [00:02<00:01, 202.21batch/s]\u001B[A\n",
      "Training batches on cuda:0:  60%|█████▉    | 479/801 [00:02<00:01, 202.28batch/s]\u001B[A\n",
      "Training batches on cuda:0:  62%|██████▏   | 500/801 [00:02<00:01, 202.35batch/s]\u001B[A\n",
      "Training batches on cuda:0:  65%|██████▌   | 521/801 [00:02<00:01, 202.44batch/s]\u001B[A\n",
      "Training batches on cuda:0:  68%|██████▊   | 542/801 [00:02<00:01, 202.66batch/s]\u001B[A\n",
      "Training batches on cuda:0:  70%|███████   | 563/801 [00:02<00:01, 202.90batch/s]\u001B[A\n",
      "Training batches on cuda:0:  73%|███████▎  | 584/801 [00:02<00:01, 202.59batch/s]\u001B[A\n",
      "Training batches on cuda:0:  76%|███████▌  | 605/801 [00:02<00:00, 202.72batch/s]\u001B[A\n",
      "Training batches on cuda:0:  78%|███████▊  | 626/801 [00:03<00:00, 202.65batch/s]\u001B[A\n",
      "Training batches on cuda:0:  81%|████████  | 647/801 [00:03<00:00, 202.83batch/s]\u001B[A\n",
      "Training batches on cuda:0:  83%|████████▎ | 668/801 [00:03<00:00, 202.95batch/s]\u001B[A\n",
      "Training batches on cuda:0:  86%|████████▌ | 689/801 [00:03<00:00, 203.02batch/s]\u001B[A\n",
      "Training batches on cuda:0:  89%|████████▊ | 710/801 [00:03<00:00, 202.96batch/s]\u001B[A\n",
      "Training batches on cuda:0:  91%|█████████▏| 731/801 [00:03<00:00, 202.83batch/s]\u001B[A\n",
      "Training batches on cuda:0:  94%|█████████▍| 752/801 [00:03<00:00, 202.96batch/s]\u001B[A\n",
      "Training batches on cuda:0:  97%|█████████▋| 773/801 [00:03<00:00, 202.92batch/s]\u001B[A\n",
      "Training batches on cuda:0:  99%|█████████▉| 794/801 [00:03<00:00, 202.87batch/s]\u001B[A\n",
      "Training epochs on cuda:0:  90%|█████████ | 45/50 [03:16<00:20,  4.16s/epoch, loss=0.333, prev_loss=0.333]\n",
      "Training batches on cuda:0:   0%|          | 0/801 [00:00<?, ?batch/s]\u001B[A\n",
      "Training batches on cuda:0:   2%|▏         | 19/801 [00:00<00:04, 187.80batch/s]\u001B[A\n",
      "Training batches on cuda:0:   5%|▍         | 40/801 [00:00<00:03, 196.19batch/s]\u001B[A\n",
      "Training batches on cuda:0:   8%|▊         | 61/801 [00:00<00:03, 199.08batch/s]\u001B[A\n",
      "Training batches on cuda:0:  10%|█         | 82/801 [00:00<00:03, 200.07batch/s]\u001B[A\n",
      "Training batches on cuda:0:  13%|█▎        | 103/801 [00:00<00:03, 200.91batch/s]\u001B[A\n",
      "Training batches on cuda:0:  15%|█▌        | 124/801 [00:00<00:03, 201.68batch/s]\u001B[A\n",
      "Training batches on cuda:0:  18%|█▊        | 145/801 [00:00<00:03, 202.25batch/s]\u001B[A\n",
      "Training batches on cuda:0:  21%|██        | 166/801 [00:00<00:03, 202.60batch/s]\u001B[A\n",
      "Training batches on cuda:0:  23%|██▎       | 187/801 [00:00<00:03, 202.87batch/s]\u001B[A\n",
      "Training batches on cuda:0:  26%|██▌       | 208/801 [00:01<00:02, 203.10batch/s]\u001B[A\n",
      "Training batches on cuda:0:  29%|██▊       | 229/801 [00:01<00:02, 203.33batch/s]\u001B[A\n",
      "Training batches on cuda:0:  31%|███       | 250/801 [00:01<00:02, 203.48batch/s]\u001B[A\n",
      "Training batches on cuda:0:  34%|███▍      | 271/801 [00:01<00:02, 203.55batch/s]\u001B[A\n",
      "Training batches on cuda:0:  36%|███▋      | 292/801 [00:01<00:02, 203.55batch/s]\u001B[A\n",
      "Training batches on cuda:0:  39%|███▉      | 313/801 [00:01<00:02, 203.54batch/s]\u001B[A\n",
      "Training batches on cuda:0:  42%|████▏     | 334/801 [00:01<00:02, 203.68batch/s]\u001B[A\n",
      "Training batches on cuda:0:  44%|████▍     | 355/801 [00:01<00:02, 203.60batch/s]\u001B[A\n",
      "Training batches on cuda:0:  47%|████▋     | 376/801 [00:01<00:02, 203.41batch/s]\u001B[A\n",
      "Training batches on cuda:0:  50%|████▉     | 397/801 [00:01<00:01, 203.43batch/s]\u001B[A\n",
      "Training batches on cuda:0:  52%|█████▏    | 418/801 [00:02<00:01, 203.43batch/s]\u001B[A\n",
      "Training batches on cuda:0:  55%|█████▍    | 439/801 [00:02<00:01, 203.52batch/s]\u001B[A\n",
      "Training batches on cuda:0:  57%|█████▋    | 460/801 [00:02<00:01, 203.53batch/s]\u001B[A\n",
      "Training batches on cuda:0:  60%|██████    | 481/801 [00:02<00:01, 203.49batch/s]\u001B[A\n",
      "Training batches on cuda:0:  63%|██████▎   | 502/801 [00:02<00:01, 203.38batch/s]\u001B[A\n",
      "Training batches on cuda:0:  65%|██████▌   | 523/801 [00:02<00:01, 202.27batch/s]\u001B[A\n",
      "Training batches on cuda:0:  68%|██████▊   | 544/801 [00:02<00:01, 201.97batch/s]\u001B[A\n",
      "Training batches on cuda:0:  71%|███████   | 565/801 [00:02<00:01, 177.84batch/s]\u001B[A\n",
      "Training batches on cuda:0:  73%|███████▎  | 585/801 [00:02<00:01, 183.62batch/s]\u001B[A\n",
      "Training batches on cuda:0:  76%|███████▌  | 605/801 [00:03<00:01, 188.11batch/s]\u001B[A\n",
      "Training batches on cuda:0:  78%|███████▊  | 625/801 [00:03<00:00, 191.43batch/s]\u001B[A\n",
      "Training batches on cuda:0:  81%|████████  | 646/801 [00:03<00:00, 194.07batch/s]\u001B[A\n",
      "Training batches on cuda:0:  83%|████████▎ | 667/801 [00:03<00:00, 195.97batch/s]\u001B[A\n",
      "Training batches on cuda:0:  86%|████████▌ | 688/801 [00:03<00:00, 197.40batch/s]\u001B[A\n",
      "Training batches on cuda:0:  88%|████████▊ | 708/801 [00:03<00:00, 198.14batch/s]\u001B[A\n",
      "Training batches on cuda:0:  91%|█████████ | 729/801 [00:03<00:00, 198.95batch/s]\u001B[A\n",
      "Training batches on cuda:0:  94%|█████████▎| 750/801 [00:03<00:00, 199.41batch/s]\u001B[A\n",
      "Training batches on cuda:0:  96%|█████████▋| 771/801 [00:03<00:00, 199.99batch/s]\u001B[A\n",
      "Training batches on cuda:0:  99%|█████████▉| 792/801 [00:03<00:00, 200.26batch/s]\u001B[A\n",
      "Training epochs on cuda:0:  92%|█████████▏| 46/50 [03:20<00:16,  4.16s/epoch, loss=0.332, prev_loss=0.333]\n",
      "Training batches on cuda:0:   0%|          | 0/801 [00:00<?, ?batch/s]\u001B[A\n",
      "Training batches on cuda:0:   2%|▏         | 19/801 [00:00<00:04, 187.80batch/s]\u001B[A\n",
      "Training batches on cuda:0:   5%|▍         | 39/801 [00:00<00:03, 194.67batch/s]\u001B[A\n",
      "Training batches on cuda:0:   7%|▋         | 60/801 [00:00<00:03, 199.01batch/s]\u001B[A\n",
      "Training batches on cuda:0:  10%|█         | 81/801 [00:00<00:03, 200.11batch/s]\u001B[A\n",
      "Training batches on cuda:0:  13%|█▎        | 102/801 [00:00<00:03, 201.05batch/s]\u001B[A\n",
      "Training batches on cuda:0:  15%|█▌        | 123/801 [00:00<00:03, 201.74batch/s]\u001B[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches on cuda:0:  18%|█▊        | 144/801 [00:00<00:03, 202.16batch/s]\u001B[A\n",
      "Training batches on cuda:0:  21%|██        | 165/801 [00:00<00:03, 202.38batch/s]\u001B[A\n",
      "Training batches on cuda:0:  23%|██▎       | 186/801 [00:00<00:03, 202.78batch/s]\u001B[A\n",
      "Training batches on cuda:0:  26%|██▌       | 207/801 [00:01<00:02, 202.73batch/s]\u001B[A\n",
      "Training batches on cuda:0:  28%|██▊       | 228/801 [00:01<00:02, 202.80batch/s]\u001B[A\n",
      "Training batches on cuda:0:  31%|███       | 249/801 [00:01<00:02, 202.93batch/s]\u001B[A\n",
      "Training batches on cuda:0:  34%|███▎      | 270/801 [00:01<00:02, 203.00batch/s]\u001B[A\n",
      "Training batches on cuda:0:  36%|███▋      | 291/801 [00:01<00:02, 203.25batch/s]\u001B[A\n",
      "Training batches on cuda:0:  39%|███▉      | 312/801 [00:01<00:02, 203.29batch/s]\u001B[A\n",
      "Training batches on cuda:0:  42%|████▏     | 333/801 [00:01<00:02, 203.26batch/s]\u001B[A\n",
      "Training batches on cuda:0:  44%|████▍     | 354/801 [00:01<00:02, 203.06batch/s]\u001B[A\n",
      "Training batches on cuda:0:  47%|████▋     | 375/801 [00:01<00:02, 178.32batch/s]\u001B[A\n",
      "Training batches on cuda:0:  49%|████▉     | 395/801 [00:02<00:02, 183.85batch/s]\u001B[A\n",
      "Training batches on cuda:0:  52%|█████▏    | 415/801 [00:02<00:02, 188.04batch/s]\u001B[A\n",
      "Training batches on cuda:0:  54%|█████▍    | 436/801 [00:02<00:01, 191.61batch/s]\u001B[A\n",
      "Training batches on cuda:0:  57%|█████▋    | 456/801 [00:02<00:01, 193.96batch/s]\u001B[A\n",
      "Training batches on cuda:0:  60%|█████▉    | 477/801 [00:02<00:01, 195.84batch/s]\u001B[A\n",
      "Training batches on cuda:0:  62%|██████▏   | 497/801 [00:02<00:01, 196.07batch/s]\u001B[A\n",
      "Training batches on cuda:0:  65%|██████▍   | 517/801 [00:02<00:01, 196.93batch/s]\u001B[A\n",
      "Training batches on cuda:0:  67%|██████▋   | 538/801 [00:02<00:01, 198.17batch/s]\u001B[A\n",
      "Training batches on cuda:0:  70%|██████▉   | 558/801 [00:02<00:01, 198.33batch/s]\u001B[A\n",
      "Training batches on cuda:0:  72%|███████▏  | 578/801 [00:02<00:01, 198.49batch/s]\u001B[A\n",
      "Training batches on cuda:0:  75%|███████▍  | 598/801 [00:03<00:01, 198.19batch/s]\u001B[A\n",
      "Training batches on cuda:0:  77%|███████▋  | 618/801 [00:03<00:00, 198.41batch/s]\u001B[A\n",
      "Training batches on cuda:0:  80%|███████▉  | 638/801 [00:03<00:00, 198.69batch/s]\u001B[A\n",
      "Training batches on cuda:0:  82%|████████▏ | 658/801 [00:03<00:00, 198.73batch/s]\u001B[A\n",
      "Training batches on cuda:0:  85%|████████▍ | 678/801 [00:03<00:00, 198.48batch/s]\u001B[A\n",
      "Training batches on cuda:0:  87%|████████▋ | 698/801 [00:03<00:00, 198.60batch/s]\u001B[A\n",
      "Training batches on cuda:0:  90%|████████▉ | 718/801 [00:03<00:00, 198.38batch/s]\u001B[A\n",
      "Training batches on cuda:0:  92%|█████████▏| 738/801 [00:03<00:00, 178.91batch/s]\u001B[A\n",
      "Training batches on cuda:0:  95%|█████████▍| 758/801 [00:03<00:00, 184.13batch/s]\u001B[A\n",
      "Training batches on cuda:0:  97%|█████████▋| 778/801 [00:03<00:00, 188.25batch/s]\u001B[A\n",
      "Training batches on cuda:0: 100%|█████████▉| 798/801 [00:04<00:00, 191.30batch/s]\u001B[A\n",
      "Training epochs on cuda:0:  94%|█████████▍| 47/50 [03:24<00:12,  4.19s/epoch, loss=0.332, prev_loss=0.332]\n",
      "Training batches on cuda:0:   0%|          | 0/801 [00:00<?, ?batch/s]\u001B[A\n",
      "Training batches on cuda:0:   2%|▏         | 19/801 [00:00<00:04, 185.67batch/s]\u001B[A\n",
      "Training batches on cuda:0:   5%|▍         | 39/801 [00:00<00:03, 193.24batch/s]\u001B[A\n",
      "Training batches on cuda:0:   7%|▋         | 59/801 [00:00<00:03, 195.77batch/s]\u001B[A\n",
      "Training batches on cuda:0:  10%|▉         | 79/801 [00:00<00:03, 196.22batch/s]\u001B[A\n",
      "Training batches on cuda:0:  12%|█▏        | 100/801 [00:00<00:03, 197.84batch/s]\u001B[A\n",
      "Training batches on cuda:0:  15%|█▌        | 121/801 [00:00<00:03, 198.80batch/s]\u001B[A\n",
      "Training batches on cuda:0:  18%|█▊        | 142/801 [00:00<00:03, 199.59batch/s]\u001B[A\n",
      "Training batches on cuda:0:  20%|██        | 163/801 [00:00<00:03, 200.12batch/s]\u001B[A\n",
      "Training batches on cuda:0:  23%|██▎       | 184/801 [00:00<00:03, 200.43batch/s]\u001B[A\n",
      "Training batches on cuda:0:  26%|██▌       | 205/801 [00:01<00:02, 200.76batch/s]\u001B[A\n",
      "Training batches on cuda:0:  28%|██▊       | 226/801 [00:01<00:02, 201.11batch/s]\u001B[A\n",
      "Training batches on cuda:0:  31%|███       | 247/801 [00:01<00:02, 201.18batch/s]\u001B[A\n",
      "Training batches on cuda:0:  33%|███▎      | 268/801 [00:01<00:02, 201.12batch/s]\u001B[A\n",
      "Training batches on cuda:0:  36%|███▌      | 289/801 [00:01<00:02, 201.08batch/s]\u001B[A\n",
      "Training batches on cuda:0:  39%|███▊      | 310/801 [00:01<00:02, 201.13batch/s]\u001B[A\n",
      "Training batches on cuda:0:  41%|████▏     | 331/801 [00:01<00:02, 201.13batch/s]\u001B[A\n",
      "Training batches on cuda:0:  44%|████▍     | 352/801 [00:01<00:02, 201.07batch/s]\u001B[A\n",
      "Training batches on cuda:0:  47%|████▋     | 373/801 [00:01<00:02, 200.51batch/s]\u001B[A\n",
      "Training batches on cuda:0:  49%|████▉     | 394/801 [00:01<00:02, 200.54batch/s]\u001B[A\n",
      "Training batches on cuda:0:  52%|█████▏    | 415/801 [00:02<00:01, 200.64batch/s]\u001B[A\n",
      "Training batches on cuda:0:  54%|█████▍    | 436/801 [00:02<00:01, 200.68batch/s]\u001B[A\n",
      "Training batches on cuda:0:  57%|█████▋    | 457/801 [00:02<00:01, 200.42batch/s]\u001B[A\n",
      "Training batches on cuda:0:  60%|█████▉    | 478/801 [00:02<00:01, 200.53batch/s]\u001B[A\n",
      "Training batches on cuda:0:  62%|██████▏   | 499/801 [00:02<00:01, 200.63batch/s]\u001B[A\n",
      "Training batches on cuda:0:  65%|██████▍   | 520/801 [00:02<00:01, 200.80batch/s]\u001B[A\n",
      "Training batches on cuda:0:  68%|██████▊   | 541/801 [00:02<00:01, 201.60batch/s]\u001B[A\n",
      "Training batches on cuda:0:  70%|███████   | 562/801 [00:02<00:01, 202.24batch/s]\u001B[A\n",
      "Training batches on cuda:0:  73%|███████▎  | 583/801 [00:02<00:01, 202.70batch/s]\u001B[A\n",
      "Training batches on cuda:0:  75%|███████▌  | 604/801 [00:03<00:00, 202.96batch/s]\u001B[A\n",
      "Training batches on cuda:0:  78%|███████▊  | 625/801 [00:03<00:00, 203.31batch/s]\u001B[A\n",
      "Training batches on cuda:0:  81%|████████  | 646/801 [00:03<00:00, 203.47batch/s]\u001B[A\n",
      "Training batches on cuda:0:  83%|████████▎ | 667/801 [00:03<00:00, 203.52batch/s]\u001B[A\n",
      "Training batches on cuda:0:  86%|████████▌ | 688/801 [00:03<00:00, 203.53batch/s]\u001B[A\n",
      "Training batches on cuda:0:  89%|████████▊ | 709/801 [00:03<00:00, 203.56batch/s]\u001B[A\n",
      "Training batches on cuda:0:  91%|█████████ | 730/801 [00:03<00:00, 203.59batch/s]\u001B[A\n",
      "Training batches on cuda:0:  94%|█████████▍| 751/801 [00:03<00:00, 203.76batch/s]\u001B[A\n",
      "Training batches on cuda:0:  96%|█████████▋| 772/801 [00:03<00:00, 203.75batch/s]\u001B[A\n",
      "Training batches on cuda:0:  99%|█████████▉| 793/801 [00:03<00:00, 203.74batch/s]\u001B[A\n",
      "Training epochs on cuda:0:  96%|█████████▌| 48/50 [03:28<00:08,  4.18s/epoch, loss=0.331, prev_loss=0.332]\n",
      "Training batches on cuda:0:   0%|          | 0/801 [00:00<?, ?batch/s]\u001B[A\n",
      "Training batches on cuda:0:   2%|▏         | 19/801 [00:00<00:04, 187.82batch/s]\u001B[A\n",
      "Training batches on cuda:0:   5%|▍         | 40/801 [00:00<00:03, 197.31batch/s]\u001B[A\n",
      "Training batches on cuda:0:   8%|▊         | 61/801 [00:00<00:03, 200.37batch/s]\u001B[A\n",
      "Training batches on cuda:0:  10%|█         | 82/801 [00:00<00:03, 200.66batch/s]\u001B[A\n",
      "Training batches on cuda:0:  13%|█▎        | 103/801 [00:00<00:03, 202.01batch/s]\u001B[A\n",
      "Training batches on cuda:0:  15%|█▌        | 124/801 [00:00<00:03, 202.76batch/s]\u001B[A\n",
      "Training batches on cuda:0:  18%|█▊        | 145/801 [00:00<00:03, 203.19batch/s]\u001B[A\n",
      "Training batches on cuda:0:  21%|██        | 166/801 [00:00<00:03, 203.33batch/s]\u001B[A\n",
      "Training batches on cuda:0:  23%|██▎       | 187/801 [00:00<00:03, 203.66batch/s]\u001B[A\n",
      "Training batches on cuda:0:  26%|██▌       | 208/801 [00:01<00:02, 203.81batch/s]\u001B[A\n",
      "Training batches on cuda:0:  29%|██▊       | 229/801 [00:01<00:02, 203.99batch/s]\u001B[A\n",
      "Training batches on cuda:0:  31%|███       | 250/801 [00:01<00:02, 204.06batch/s]\u001B[A\n",
      "Training batches on cuda:0:  34%|███▍      | 271/801 [00:01<00:02, 204.09batch/s]\u001B[A\n",
      "Training batches on cuda:0:  36%|███▋      | 292/801 [00:01<00:02, 204.02batch/s]\u001B[A\n",
      "Training batches on cuda:0:  39%|███▉      | 313/801 [00:01<00:02, 203.98batch/s]\u001B[A\n",
      "Training batches on cuda:0:  42%|████▏     | 334/801 [00:01<00:02, 204.03batch/s]\u001B[A\n",
      "Training batches on cuda:0:  44%|████▍     | 355/801 [00:01<00:02, 203.93batch/s]\u001B[A\n",
      "Training batches on cuda:0:  47%|████▋     | 376/801 [00:01<00:02, 203.93batch/s]\u001B[A\n",
      "Training batches on cuda:0:  50%|████▉     | 397/801 [00:01<00:01, 203.92batch/s]\u001B[A\n",
      "Training batches on cuda:0:  52%|█████▏    | 418/801 [00:02<00:01, 204.02batch/s]\u001B[A\n",
      "Training batches on cuda:0:  55%|█████▍    | 439/801 [00:02<00:01, 203.95batch/s]\u001B[A\n",
      "Training batches on cuda:0:  57%|█████▋    | 460/801 [00:02<00:01, 203.91batch/s]\u001B[A\n",
      "Training batches on cuda:0:  60%|██████    | 481/801 [00:02<00:01, 203.90batch/s]\u001B[A\n",
      "Training batches on cuda:0:  63%|██████▎   | 502/801 [00:02<00:01, 203.95batch/s]\u001B[A\n",
      "Training batches on cuda:0:  65%|██████▌   | 523/801 [00:02<00:01, 203.86batch/s]\u001B[A\n",
      "Training batches on cuda:0:  68%|██████▊   | 544/801 [00:02<00:01, 203.90batch/s]\u001B[A\n",
      "Training batches on cuda:0:  71%|███████   | 565/801 [00:02<00:01, 203.96batch/s]\u001B[A\n",
      "Training batches on cuda:0:  73%|███████▎  | 586/801 [00:02<00:01, 203.98batch/s]\u001B[A\n",
      "Training batches on cuda:0:  76%|███████▌  | 607/801 [00:02<00:00, 203.87batch/s]\u001B[A\n",
      "Training batches on cuda:0:  78%|███████▊  | 628/801 [00:03<00:00, 203.90batch/s]\u001B[A\n",
      "Training batches on cuda:0:  81%|████████  | 649/801 [00:03<00:00, 203.82batch/s]\u001B[A\n",
      "Training batches on cuda:0:  84%|████████▎ | 670/801 [00:03<00:00, 203.91batch/s]\u001B[A\n",
      "Training batches on cuda:0:  86%|████████▋ | 691/801 [00:03<00:00, 203.94batch/s]\u001B[A\n",
      "Training batches on cuda:0:  89%|████████▉ | 712/801 [00:03<00:00, 203.87batch/s]\u001B[A\n",
      "Training batches on cuda:0:  92%|█████████▏| 733/801 [00:03<00:00, 204.00batch/s]\u001B[A\n",
      "Training batches on cuda:0:  94%|█████████▍| 754/801 [00:03<00:00, 203.92batch/s]\u001B[A\n",
      "Training batches on cuda:0:  97%|█████████▋| 775/801 [00:03<00:00, 203.87batch/s]\u001B[A\n",
      "Training batches on cuda:0:  99%|█████████▉| 796/801 [00:03<00:00, 203.85batch/s]\u001B[A\n",
      "Training epochs on cuda:0:  98%|█████████▊| 49/50 [03:33<00:04,  4.15s/epoch, loss=0.331, prev_loss=0.331]\n",
      "Training batches on cuda:0:   0%|          | 0/801 [00:00<?, ?batch/s]\u001B[A\n",
      "Training batches on cuda:0:   2%|▏         | 19/801 [00:00<00:04, 187.84batch/s]\u001B[A\n",
      "Training batches on cuda:0:   5%|▍         | 40/801 [00:00<00:03, 197.15batch/s]\u001B[A\n",
      "Training batches on cuda:0:   8%|▊         | 61/801 [00:00<00:03, 200.12batch/s]\u001B[A\n",
      "Training batches on cuda:0:  10%|█         | 82/801 [00:00<00:03, 200.77batch/s]\u001B[A\n",
      "Training batches on cuda:0:  13%|█▎        | 103/801 [00:00<00:03, 201.94batch/s]\u001B[A\n",
      "Training batches on cuda:0:  15%|█▌        | 124/801 [00:00<00:03, 202.63batch/s]\u001B[A\n",
      "Training batches on cuda:0:  18%|█▊        | 145/801 [00:00<00:03, 202.96batch/s]\u001B[A\n",
      "Training batches on cuda:0:  21%|██        | 166/801 [00:00<00:03, 203.37batch/s]\u001B[A\n",
      "Training batches on cuda:0:  23%|██▎       | 187/801 [00:00<00:03, 203.51batch/s]\u001B[A\n",
      "Training batches on cuda:0:  26%|██▌       | 208/801 [00:01<00:02, 203.61batch/s]\u001B[A\n",
      "Training batches on cuda:0:  29%|██▊       | 229/801 [00:01<00:02, 203.65batch/s]\u001B[A\n",
      "Training batches on cuda:0:  31%|███       | 250/801 [00:01<00:02, 203.77batch/s]\u001B[A\n",
      "Training batches on cuda:0:  34%|███▍      | 271/801 [00:01<00:02, 203.77batch/s]\u001B[A\n",
      "Training batches on cuda:0:  36%|███▋      | 292/801 [00:01<00:02, 203.76batch/s]\u001B[A\n",
      "Training batches on cuda:0:  39%|███▉      | 313/801 [00:01<00:02, 203.73batch/s]\u001B[A\n",
      "Training batches on cuda:0:  42%|████▏     | 334/801 [00:01<00:02, 203.77batch/s]\u001B[A\n",
      "Training batches on cuda:0:  44%|████▍     | 355/801 [00:01<00:02, 203.75batch/s]\u001B[A\n",
      "Training batches on cuda:0:  47%|████▋     | 376/801 [00:01<00:02, 203.74batch/s]\u001B[A\n",
      "Training batches on cuda:0:  50%|████▉     | 397/801 [00:01<00:01, 203.70batch/s]\u001B[A\n",
      "Training batches on cuda:0:  52%|█████▏    | 418/801 [00:02<00:01, 203.67batch/s]\u001B[A\n",
      "Training batches on cuda:0:  55%|█████▍    | 439/801 [00:02<00:01, 203.59batch/s]\u001B[A\n",
      "Training batches on cuda:0:  57%|█████▋    | 460/801 [00:02<00:01, 203.55batch/s]\u001B[A\n",
      "Training batches on cuda:0:  60%|██████    | 481/801 [00:02<00:01, 203.49batch/s]\u001B[A\n",
      "Training batches on cuda:0:  63%|██████▎   | 502/801 [00:02<00:01, 203.54batch/s]\u001B[A\n",
      "Training batches on cuda:0:  65%|██████▌   | 523/801 [00:02<00:01, 203.56batch/s]\u001B[A\n",
      "Training batches on cuda:0:  68%|██████▊   | 544/801 [00:02<00:01, 203.55batch/s]\u001B[A\n",
      "Training batches on cuda:0:  71%|███████   | 565/801 [00:02<00:01, 203.56batch/s]\u001B[A\n",
      "Training batches on cuda:0:  73%|███████▎  | 586/801 [00:02<00:01, 203.34batch/s]\u001B[A\n",
      "Training batches on cuda:0:  76%|███████▌  | 607/801 [00:02<00:00, 203.28batch/s]\u001B[A\n",
      "Training batches on cuda:0:  78%|███████▊  | 628/801 [00:03<00:00, 203.26batch/s]\u001B[A\n",
      "Training batches on cuda:0:  81%|████████  | 649/801 [00:03<00:00, 203.30batch/s]\u001B[A\n",
      "Training batches on cuda:0:  84%|████████▎ | 670/801 [00:03<00:00, 203.32batch/s]\u001B[A\n",
      "Training batches on cuda:0:  86%|████████▋ | 691/801 [00:03<00:00, 203.38batch/s]\u001B[A\n",
      "Training batches on cuda:0:  89%|████████▉ | 712/801 [00:03<00:00, 203.42batch/s]\u001B[A\n",
      "Training batches on cuda:0:  92%|█████████▏| 733/801 [00:03<00:00, 203.44batch/s]\u001B[A\n",
      "Training batches on cuda:0:  94%|█████████▍| 754/801 [00:03<00:00, 203.50batch/s]\u001B[A\n",
      "Training batches on cuda:0:  97%|█████████▋| 775/801 [00:03<00:00, 203.46batch/s]\u001B[A\n",
      "Training batches on cuda:0:  99%|█████████▉| 796/801 [00:03<00:00, 203.49batch/s]\u001B[A\n",
      "Training epochs on cuda:0: 100%|██████████| 50/50 [03:37<00:00,  4.34s/epoch, loss=0.33, prev_loss=0.331] \n",
      "INFO:pykeen.evaluation.evaluator:Starting batch_size search for evaluation now...\n",
      "INFO:pykeen.evaluation.evaluator:Concluded batch_size search with batch_size=512.\n",
      "Evaluating on cuda:0: 100%|██████████| 2.20k/2.20k [00:01<00:00, 1.86ktriple/s]\n",
      "INFO:pykeen.evaluation.evaluator:Evaluation took 1.91s seconds\n"
     ]
    }
   ],
   "source": [
    "result = pipeline(\n",
    "    training='../data/corpus_graphs/trex_triples_filtered_100_hop_1_sim_0.2845.txt',\n",
    "    testing='../data/corpus_graphs/inference_test_filtered_ilpc.txt',\n",
    "    model='DistMult',\n",
    "    #stopper='early',  # todo causes an issue for some reason when the evaluation starts, therefore, check entitiy and relation overlap between train and test!\n",
    "    epochs=50,\n",
    "    device='gpu',\n",
    "    model_kwargs=dict(embedding_dim=200),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0888766422867775"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.get_metric('mrr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.metric_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No random seed is specified. Setting to 3672080562.\n",
      "Training epochs on cpu:   0%|          | 0/100 [00:00<?, ?epoch/s]\n",
      "Training batches on cpu:   0%|          | 0/80525 [00:00<?, ?batch/s]\u001B[A\n",
      "Training batches on cpu:   0%|          | 1/80525 [00:14<314:33:04, 14.06s/batch]\u001B[A\n",
      "Training batches on cpu:   0%|          | 2/80525 [00:25<281:59:14, 12.61s/batch]\u001B[A\n",
      "Training batches on cpu:   0%|          | 3/80525 [00:37<269:57:44, 12.07s/batch]\u001B[A\n",
      "Training batches on cpu:   0%|          | 4/80525 [00:48<264:42:15, 11.83s/batch]\u001B[A\n",
      "Training batches on cpu:   0%|          | 5/80525 [01:00<261:41:01, 11.70s/batch]\u001B[A\n",
      "Training batches on cpu:   0%|          | 6/80525 [01:11<260:19:14, 11.64s/batch]\u001B[A\n",
      "Training batches on cpu:   0%|          | 7/80525 [01:22<258:43:27, 11.57s/batch]\u001B[A\n",
      "Training batches on cpu:   0%|          | 8/80525 [01:34<259:17:58, 11.59s/batch]\u001B[A\n",
      "Training batches on cpu:   0%|          | 9/80525 [01:46<258:33:49, 11.56s/batch]\u001B[A\n",
      "Training batches on cpu:   0%|          | 10/80525 [01:57<258:18:33, 11.55s/batch]\u001B[A\n",
      "Training batches on cpu:   0%|          | 11/80525 [02:09<257:54:59, 11.53s/batch]\u001B[A\n",
      "Training batches on cpu:   0%|          | 12/80525 [02:20<257:09:33, 11.50s/batch]\u001B[A\n",
      "Training batches on cpu:   0%|          | 13/80525 [02:31<255:56:46, 11.44s/batch]\u001B[A\n",
      "Training batches on cpu:   0%|          | 14/80525 [02:43<253:58:28, 11.36s/batch]\u001B[A\n",
      "Training batches on cpu:   0%|          | 15/80525 [02:54<252:33:59, 11.29s/batch]\u001B[A\n",
      "Training epochs on cpu:   0%|          | 0/100 [02:59<?, ?epoch/s]                \u001B[A\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43mpipeline\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      2\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdataset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mWikidata5M\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mDistMult\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstopper\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mearly\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcpu\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mdict\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43membedding_dim\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m512\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      8\u001B[0m \u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/lp/lib/python3.10/site-packages/pykeen/pipeline/api.py:1546\u001B[0m, in \u001B[0;36mpipeline\u001B[0;34m(dataset, dataset_kwargs, training, testing, validation, evaluation_entity_whitelist, evaluation_relation_whitelist, model, model_kwargs, interaction, interaction_kwargs, dimensions, loss, loss_kwargs, regularizer, regularizer_kwargs, optimizer, optimizer_kwargs, clear_optimizer, lr_scheduler, lr_scheduler_kwargs, training_loop, training_loop_kwargs, negative_sampler, negative_sampler_kwargs, epochs, training_kwargs, stopper, stopper_kwargs, evaluator, evaluator_kwargs, evaluation_kwargs, result_tracker, result_tracker_kwargs, metadata, device, random_seed, use_testing_data, evaluation_fallback, filter_validation_when_testing, use_tqdm)\u001B[0m\n\u001B[1;32m   1525\u001B[0m training_loop_instance \u001B[38;5;241m=\u001B[39m _handle_training_loop(\n\u001B[1;32m   1526\u001B[0m     _result_tracker\u001B[38;5;241m=\u001B[39m_result_tracker,\n\u001B[1;32m   1527\u001B[0m     model_instance\u001B[38;5;241m=\u001B[39mmodel_instance,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1536\u001B[0m     negative_sampler_kwargs\u001B[38;5;241m=\u001B[39mnegative_sampler_kwargs,\n\u001B[1;32m   1537\u001B[0m )\n\u001B[1;32m   1539\u001B[0m evaluator_instance, evaluation_kwargs \u001B[38;5;241m=\u001B[39m _handle_evaluator(\n\u001B[1;32m   1540\u001B[0m     _result_tracker\u001B[38;5;241m=\u001B[39m_result_tracker,\n\u001B[1;32m   1541\u001B[0m     evaluator\u001B[38;5;241m=\u001B[39mevaluator,\n\u001B[1;32m   1542\u001B[0m     evaluator_kwargs\u001B[38;5;241m=\u001B[39mevaluator_kwargs,\n\u001B[1;32m   1543\u001B[0m     evaluation_kwargs\u001B[38;5;241m=\u001B[39mevaluation_kwargs,\n\u001B[1;32m   1544\u001B[0m )\n\u001B[0;32m-> 1546\u001B[0m stopper_instance, configuration, losses, train_seconds \u001B[38;5;241m=\u001B[39m \u001B[43m_handle_training\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1547\u001B[0m \u001B[43m    \u001B[49m\u001B[43m_result_tracker\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m_result_tracker\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1548\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtraining\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtraining\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1549\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalidation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidation\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1550\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel_instance\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel_instance\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1551\u001B[0m \u001B[43m    \u001B[49m\u001B[43mevaluator_instance\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mevaluator_instance\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1552\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtraining_loop_instance\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtraining_loop_instance\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1553\u001B[0m \u001B[43m    \u001B[49m\u001B[43mclear_optimizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mclear_optimizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1554\u001B[0m \u001B[43m    \u001B[49m\u001B[43mevaluation_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mevaluation_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1555\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1556\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtraining_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtraining_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1557\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstopper\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstopper\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1558\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstopper_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstopper_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1559\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_tqdm\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_tqdm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1560\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1562\u001B[0m metric_results, evaluate_seconds \u001B[38;5;241m=\u001B[39m _handle_evaluation(\n\u001B[1;32m   1563\u001B[0m     _result_tracker\u001B[38;5;241m=\u001B[39m_result_tracker,\n\u001B[1;32m   1564\u001B[0m     model_instance\u001B[38;5;241m=\u001B[39mmodel_instance,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1575\u001B[0m     use_tqdm\u001B[38;5;241m=\u001B[39muse_tqdm,\n\u001B[1;32m   1576\u001B[0m )\n\u001B[1;32m   1577\u001B[0m _result_tracker\u001B[38;5;241m.\u001B[39mend_run()\n",
      "File \u001B[0;32m~/miniconda3/envs/lp/lib/python3.10/site-packages/pykeen/pipeline/api.py:1190\u001B[0m, in \u001B[0;36m_handle_training\u001B[0;34m(_result_tracker, training, validation, model_instance, evaluator_instance, training_loop_instance, clear_optimizer, evaluation_kwargs, epochs, training_kwargs, stopper, stopper_kwargs, use_tqdm)\u001B[0m\n\u001B[1;32m   1188\u001B[0m \u001B[38;5;66;03m# Train like Cristiano Ronaldo\u001B[39;00m\n\u001B[1;32m   1189\u001B[0m training_start_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m-> 1190\u001B[0m losses \u001B[38;5;241m=\u001B[39m \u001B[43mtraining_loop_instance\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1191\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtriples_factory\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtraining\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1192\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstopper\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstopper_instance\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1193\u001B[0m \u001B[43m    \u001B[49m\u001B[43mclear_optimizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mclear_optimizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1194\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mtraining_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1195\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1196\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m losses \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m  \u001B[38;5;66;03m# losses is only none if it's doing search mode\u001B[39;00m\n\u001B[1;32m   1197\u001B[0m training_end_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m training_start_time\n",
      "File \u001B[0;32m~/miniconda3/envs/lp/lib/python3.10/site-packages/pykeen/training/training_loop.py:378\u001B[0m, in \u001B[0;36mTrainingLoop.train\u001B[0;34m(self, triples_factory, num_epochs, batch_size, slice_size, label_smoothing, sampler, continue_training, only_size_probing, use_tqdm, use_tqdm_batch, tqdm_kwargs, stopper, sub_batch_size, num_workers, clear_optimizer, checkpoint_directory, checkpoint_name, checkpoint_frequency, checkpoint_on_failure, drop_last, callbacks, callback_kwargs, gradient_clipping_max_norm, gradient_clipping_norm_type, gradient_clipping_max_abs_value, pin_memory)\u001B[0m\n\u001B[1;32m    375\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    376\u001B[0m     \u001B[38;5;66;03m# send model to device before going into the internal training loop\u001B[39;00m\n\u001B[1;32m    377\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mto(get_preferred_device(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel, allow_ambiguity\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m))\n\u001B[0;32m--> 378\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_train\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    379\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnum_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_epochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    380\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    381\u001B[0m \u001B[43m        \u001B[49m\u001B[43mslice_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mslice_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    382\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlabel_smoothing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlabel_smoothing\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    383\u001B[0m \u001B[43m        \u001B[49m\u001B[43msampler\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msampler\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    384\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcontinue_training\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcontinue_training\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    385\u001B[0m \u001B[43m        \u001B[49m\u001B[43monly_size_probing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43monly_size_probing\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    386\u001B[0m \u001B[43m        \u001B[49m\u001B[43muse_tqdm\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_tqdm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    387\u001B[0m \u001B[43m        \u001B[49m\u001B[43muse_tqdm_batch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_tqdm_batch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    388\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtqdm_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtqdm_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    389\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstopper\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstopper\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    390\u001B[0m \u001B[43m        \u001B[49m\u001B[43msub_batch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msub_batch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    391\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnum_workers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_workers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    392\u001B[0m \u001B[43m        \u001B[49m\u001B[43msave_checkpoints\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msave_checkpoints\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    393\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcheckpoint_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcheckpoint_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    394\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcheckpoint_frequency\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcheckpoint_frequency\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    395\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcheckpoint_on_failure_file_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcheckpoint_on_failure_file_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    396\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbest_epoch_model_file_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbest_epoch_model_file_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    397\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlast_best_epoch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlast_best_epoch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    398\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdrop_last\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdrop_last\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    399\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    400\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcallback_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallback_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    401\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgradient_clipping_max_norm\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgradient_clipping_max_norm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    402\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgradient_clipping_norm_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgradient_clipping_norm_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    403\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgradient_clipping_max_abs_value\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgradient_clipping_max_abs_value\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    404\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtriples_factory\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtriples_factory\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    405\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpin_memory\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpin_memory\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    406\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    408\u001B[0m \u001B[38;5;66;03m# Ensure the release of memory\u001B[39;00m\n\u001B[1;32m    409\u001B[0m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mempty_cache()\n",
      "File \u001B[0;32m~/miniconda3/envs/lp/lib/python3.10/site-packages/pykeen/training/training_loop.py:643\u001B[0m, in \u001B[0;36mTrainingLoop._train\u001B[0;34m(self, triples_factory, num_epochs, batch_size, slice_size, label_smoothing, sampler, continue_training, only_size_probing, use_tqdm, use_tqdm_batch, tqdm_kwargs, stopper, sub_batch_size, num_workers, save_checkpoints, checkpoint_path, checkpoint_frequency, checkpoint_on_failure_file_path, best_epoch_model_file_path, last_best_epoch, drop_last, callbacks, callback_kwargs, gradient_clipping_max_norm, gradient_clipping_norm_type, gradient_clipping_max_abs_value, pin_memory)\u001B[0m\n\u001B[1;32m    640\u001B[0m stop \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mmin\u001B[39m(start \u001B[38;5;241m+\u001B[39m _sub_batch_size, current_batch_size)\n\u001B[1;32m    642\u001B[0m \u001B[38;5;66;03m# forward pass call\u001B[39;00m\n\u001B[0;32m--> 643\u001B[0m batch_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_forward_pass\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    644\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    645\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstart\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    646\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    647\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcurrent_batch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    648\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlabel_smoothing\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    649\u001B[0m \u001B[43m    \u001B[49m\u001B[43mslice_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    650\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    651\u001B[0m current_epoch_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m batch_loss\n\u001B[1;32m    652\u001B[0m num_training_instances \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m stop \u001B[38;5;241m-\u001B[39m start\n",
      "File \u001B[0;32m~/miniconda3/envs/lp/lib/python3.10/site-packages/pykeen/training/training_loop.py:828\u001B[0m, in \u001B[0;36mTrainingLoop._forward_pass\u001B[0;34m(self, batch, start, stop, current_batch_size, label_smoothing, slice_size)\u001B[0m\n\u001B[1;32m    825\u001B[0m     loss \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m=\u001B[39m this_sub_batch_size \u001B[38;5;241m/\u001B[39m current_batch_size\n\u001B[1;32m    827\u001B[0m \u001B[38;5;66;03m# backward pass\u001B[39;00m\n\u001B[0;32m--> 828\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    829\u001B[0m current_epoch_loss \u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mitem()\n\u001B[1;32m    831\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mpost_forward_pass()\n",
      "File \u001B[0;32m~/miniconda3/envs/lp/lib/python3.10/site-packages/torch/_tensor.py:487\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    477\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    478\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    479\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    480\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    485\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[1;32m    486\u001B[0m     )\n\u001B[0;32m--> 487\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    488\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[1;32m    489\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/lp/lib/python3.10/site-packages/torch/autograd/__init__.py:200\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    195\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    197\u001B[0m \u001B[38;5;66;03m# The reason we repeat same the comment below is that\u001B[39;00m\n\u001B[1;32m    198\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    199\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 200\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    201\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    202\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "result = pipeline(\n",
    "    dataset=\"Wikidata5M\",\n",
    "    model='DistMult',\n",
    "    stopper='early',\n",
    "    epochs=100,\n",
    "    device='cpu',\n",
    "    model_kwargs=dict(embedding_dim=512),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'device'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch_geometric\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m degree\n\u001B[1;32m      3\u001B[0m edge_index \u001B[38;5;241m=\u001B[39m [[\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m1\u001B[39m], [\u001B[38;5;241m2\u001B[39m,\u001B[38;5;241m2\u001B[39m,\u001B[38;5;241m2\u001B[39m]]\n\u001B[0;32m----> 4\u001B[0m deg \u001B[38;5;241m=\u001B[39m \u001B[43mdegree\u001B[49m\u001B[43m(\u001B[49m\u001B[43medge_index\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/lp/lib/python3.10/site-packages/torch_geometric/utils/degree.py:30\u001B[0m, in \u001B[0;36mdegree\u001B[0;34m(index, num_nodes, dtype)\u001B[0m\n\u001B[1;32m     11\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Computes the (unweighted) degree of a given one-dimensional index\u001B[39;00m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;124;03mtensor.\u001B[39;00m\n\u001B[1;32m     13\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     27\u001B[0m \u001B[38;5;124;03m    tensor([3, 1, 1])\u001B[39;00m\n\u001B[1;32m     28\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     29\u001B[0m N \u001B[38;5;241m=\u001B[39m maybe_num_nodes(index, num_nodes)\n\u001B[0;32m---> 30\u001B[0m out \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mzeros((N, ), dtype\u001B[38;5;241m=\u001B[39mdtype, device\u001B[38;5;241m=\u001B[39m\u001B[43mindex\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevice\u001B[49m)\n\u001B[1;32m     31\u001B[0m one \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mones((index\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m), ), dtype\u001B[38;5;241m=\u001B[39mout\u001B[38;5;241m.\u001B[39mdtype, device\u001B[38;5;241m=\u001B[39mout\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[1;32m     32\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m out\u001B[38;5;241m.\u001B[39mscatter_add_(\u001B[38;5;241m0\u001B[39m, index, one)\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'list' object has no attribute 'device'"
     ]
    }
   ],
   "source": [
    "from torch_geometric.utils import degree\n",
    "\n",
    "edge_index = [[1,1,1], [2,2,2]]\n",
    "deg = degree(edge_index[0], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 69141/3708248 [00:04<03:31, 17246.24it/s]\n"
     ]
    }
   ],
   "source": [
    "embeddings_dict = {}\n",
    "with open('../data/corpus_graphs/trex_triples_filtered_100_hop_1_ilpc_train_embeddings.txt', 'r') as embeddings_in:\n",
    "    for line in tqdm(embeddings_in, total=3708248):\n",
    "        line = line[:-1]\n",
    "        entitiy = line.split(' ')[0]\n",
    "        embedding = line.split(' ')[1:]\n",
    "        embeddings_dict[entitiy] = embedding\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykeen.triples import TriplesFactory\n",
    "from pykeen.pipeline import pipeline\n",
    "from pykeen.datasets.nations import NATIONS_TRAIN_PATH, NATIONS_TEST_PATH\n",
    "training = TriplesFactory.from_path(\n",
    "    '../data/corpus_graphs/trex_triples_filtered_100_hop_1_ilpc_train.txt',\n",
    "    create_inverse_triples=True)\n",
    "\n",
    "testing = TriplesFactory.from_path(\n",
    "    '../data/corpus_graphs/inference_test_filtered_ilpc.txt',\n",
    "    entity_to_id=training.entity_to_id,\n",
    "    relation_to_id=training.relation_to_id,\n",
    "    create_inverse_triples=True,\n",
    ")\n",
    "\n",
    "result = pipeline(\n",
    "    training=training,\n",
    "    testing=testing,\n",
    "    model='TransE',\n",
    "    epochs=5,  # short epochs for testing - you should go higher\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No random seed is specified. Setting to 4167099614.\n",
      "Training epochs on cuda:0:   0%|          | 0/5 [00:00<?, ?epoch/s]\n",
      "Training batches on cuda:0:   0%|          | 0/80525 [00:00<?, ?batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 1/80525 [00:01<34:35:29,  1.55s/batch]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 3/80525 [00:01<10:00:17,  2.24batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 5/80525 [00:01<5:35:09,  4.00batch/s] \u001B[A\n",
      "Training batches on cuda:0:   0%|          | 7/80525 [00:01<3:49:16,  5.85batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 9/80525 [00:02<2:54:41,  7.68batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 11/80525 [00:02<2:23:08,  9.37batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 13/80525 [00:02<2:03:35, 10.86batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 15/80525 [00:02<1:51:12, 12.07batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 17/80525 [00:02<1:42:49, 13.05batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 19/80525 [00:02<1:37:08, 13.81batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 21/80525 [00:02<1:33:15, 14.39batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 23/80525 [00:02<1:30:35, 14.81batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 25/80525 [00:03<1:28:45, 15.12batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 27/80525 [00:03<1:46:22, 12.61batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 29/80525 [00:03<1:39:54, 13.43batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 31/80525 [00:03<1:35:18, 14.08batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 33/80525 [00:03<1:32:04, 14.57batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 35/80525 [00:03<1:30:00, 14.90batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 37/80525 [00:03<1:28:23, 15.18batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 39/80525 [00:04<1:27:13, 15.38batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 41/80525 [00:04<1:26:24, 15.52batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 43/80525 [00:04<1:25:51, 15.62batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 45/80525 [00:04<1:25:28, 15.69batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 47/80525 [00:04<1:25:11, 15.75batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 49/80525 [00:04<1:24:59, 15.78batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 51/80525 [00:04<1:24:50, 15.81batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 53/80525 [00:04<1:24:58, 15.78batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 55/80525 [00:05<1:24:50, 15.81batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 57/80525 [00:05<1:24:44, 15.83batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 59/80525 [00:05<1:24:58, 15.78batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 61/80525 [00:05<1:24:54, 15.79batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 63/80525 [00:05<1:24:47, 15.81batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 65/80525 [00:05<1:24:42, 15.83batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 67/80525 [00:05<1:24:38, 15.84batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 69/80525 [00:05<1:24:35, 15.85batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 71/80525 [00:06<1:24:33, 15.86batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 73/80525 [00:06<1:24:32, 15.86batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 75/80525 [00:06<1:24:40, 15.84batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 77/80525 [00:06<1:24:36, 15.85batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 79/80525 [00:06<1:24:34, 15.85batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 81/80525 [00:06<1:24:34, 15.85batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 83/80525 [00:06<1:24:42, 15.83batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 85/80525 [00:06<1:24:39, 15.84batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 87/80525 [00:07<1:24:36, 15.85batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 89/80525 [00:07<1:24:33, 15.85batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 91/80525 [00:07<1:24:31, 15.86batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 93/80525 [00:07<1:24:31, 15.86batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 95/80525 [00:07<1:24:30, 15.86batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 97/80525 [00:07<1:24:43, 15.82batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 99/80525 [00:07<1:24:39, 15.83batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 101/80525 [00:07<1:24:36, 15.84batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 103/80525 [00:08<1:24:34, 15.85batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 105/80525 [00:08<1:24:42, 15.82batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 107/80525 [00:08<1:24:39, 15.83batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 109/80525 [00:08<1:24:35, 15.84batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 111/80525 [00:08<1:24:34, 15.85batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 113/80525 [00:08<1:24:32, 15.85batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 115/80525 [00:08<1:24:30, 15.86batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 117/80525 [00:08<1:24:29, 15.86batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 119/80525 [00:09<1:24:37, 15.84batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 121/80525 [00:09<1:24:36, 15.84batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 123/80525 [00:09<1:24:32, 15.85batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 125/80525 [00:09<1:24:31, 15.85batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 127/80525 [00:09<1:24:48, 15.80batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 129/80525 [00:09<1:24:40, 15.82batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 131/80525 [00:09<1:24:36, 15.84batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 133/80525 [00:09<1:24:32, 15.85batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 135/80525 [00:10<1:24:31, 15.85batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 137/80525 [00:10<1:24:29, 15.86batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 139/80525 [00:10<1:24:28, 15.86batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 141/80525 [00:10<1:24:28, 15.86batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 143/80525 [00:10<1:24:42, 15.82batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 145/80525 [00:10<1:24:38, 15.83batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 147/80525 [00:10<1:24:34, 15.84batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 149/80525 [00:10<1:24:46, 15.80batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 151/80525 [00:11<1:24:40, 15.82batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 153/80525 [00:11<1:24:35, 15.84batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 155/80525 [00:11<1:24:33, 15.84batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 157/80525 [00:11<1:24:31, 15.85batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 159/80525 [00:11<1:24:29, 15.85batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 161/80525 [00:11<1:24:29, 15.85batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 163/80525 [00:11<1:24:28, 15.85batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 165/80525 [00:11<1:24:27, 15.86batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 167/80525 [00:12<1:24:39, 15.82batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 169/80525 [00:12<1:24:34, 15.84batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 171/80525 [00:12<1:24:31, 15.84batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 173/80525 [00:12<1:24:55, 15.77batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 175/80525 [00:12<1:24:44, 15.80batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 177/80525 [00:12<1:24:37, 15.82batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 179/80525 [00:12<1:24:33, 15.84batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 181/80525 [00:13<1:24:30, 15.85batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 183/80525 [00:13<1:24:26, 15.86batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 185/80525 [00:13<1:24:25, 15.86batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 187/80525 [00:13<1:24:23, 15.87batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 189/80525 [00:13<1:24:33, 15.83batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 191/80525 [00:13<1:24:31, 15.84batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 193/80525 [00:13<1:24:28, 15.85batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 195/80525 [00:13<1:24:48, 15.79batch/s]\u001B[A\n",
      "Training batches on cuda:0:   0%|          | 197/80525 [00:14<1:24:41, 15.81batch/s]\u001B[A\n",
      "Training epochs on cuda:0:   0%|          | 0/5 [00:14<?, ?epoch/s]                 \u001B[A\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pykeen.pipeline import pipeline\n",
    "\n",
    "\n",
    "#num_entities = 14\n",
    "#pretrained_embedding_tensor = torch.rand(num_entities, 128)\n",
    "\n",
    "\n",
    "#def initialize_from_pretrained(x: torch.FloatTensor) -> torch.FloatTensor:\n",
    "#    print(x)\n",
    "#    return pretrained_embedding_tensor\n",
    "\n",
    "\n",
    "result = pipeline(\n",
    "    dataset=\"wikidata5m\",\n",
    "    model=\"DistMult\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "head = torch.tensor([1,2,3,4,5,6,7,8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 2, 3, 4, 5]), tensor([6, 7, 8]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.split(head, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = [torch.tensor([1,2,3]), torch.tensor([1,2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 1, 2])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3, 1, 2, 3],\n",
       "        [4, 5, 6, 4, 5, 6]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[1,2,3],[4,5,6]])\n",
    "b = torch.tensor([[1,2,3],[4,5,6]])\n",
    "torch.cat((a,b), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'easydict'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[27], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01measydict\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m EasyDict\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'easydict'"
     ]
    }
   ],
   "source": [
    "from easydict import EasyDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"../data/wikidata5m_inductive/distmult_wikidata5m.pkl\", \"rb\") as fin:\n",
    "    model = pickle.load(fin)\n",
    "entity2id = model.graph.entity2id\n",
    "relation2id = model.graph.relation2id\n",
    "entity_embeddings = model.solver.entity_embeddings\n",
    "relation_embeddings = model.solver.relation_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Q29387131': 0,\n",
       " 'Q5': 1,\n",
       " 'Q326660': 2,\n",
       " 'Q652': 3,\n",
       " 'Q7339549': 4,\n",
       " 'Q1365729': 5,\n",
       " 'Q554335': 6,\n",
       " 'Q29999': 7,\n",
       " 'Q20641639': 8,\n",
       " 'Q80955': 9,\n",
       " 'Q14946683': 10,\n",
       " 'Q4221140': 11,\n",
       " 'Q399': 12,\n",
       " 'Q6925786': 13,\n",
       " 'Q488653': 14,\n",
       " 'Q4890993': 15,\n",
       " 'Q931116': 16,\n",
       " 'Q3198638': 17,\n",
       " 'Q2859200': 18,\n",
       " 'Q24905727': 19,\n",
       " 'Q88139': 20,\n",
       " 'Q710987': 21,\n",
       " 'Q674095': 22,\n",
       " 'Q7173419': 23,\n",
       " 'Q1434796': 24,\n",
       " 'Q465806': 25,\n",
       " 'Q3391415': 26,\n",
       " 'Q11469296': 27,\n",
       " 'Q26600': 28,\n",
       " 'Q14573913': 29,\n",
       " 'Q189290': 30,\n",
       " 'Q28051650': 31,\n",
       " 'Q1778168': 32,\n",
       " 'Q3302612': 33,\n",
       " 'Q1069071': 34,\n",
       " 'Q7827136': 35,\n",
       " 'Q36074': 36,\n",
       " 'Q16030681': 37,\n",
       " 'Q4117588': 38,\n",
       " 'Q6076643': 39,\n",
       " 'Q876191': 40,\n",
       " 'Q4935581': 41,\n",
       " 'Q6608367': 42,\n",
       " 'Q1046542': 43,\n",
       " 'Q34740': 44,\n",
       " 'Q17015941': 45,\n",
       " 'Q1190554': 46,\n",
       " 'Q5915589': 47,\n",
       " 'Q739': 48,\n",
       " 'Q4102888': 49,\n",
       " 'Q2631868': 50,\n",
       " 'Q3445500': 51,\n",
       " 'Q4430810': 52,\n",
       " 'Q16766': 53,\n",
       " 'Q3946132': 54,\n",
       " 'Q19490': 55,\n",
       " 'Q7523417': 56,\n",
       " 'Q5375': 57,\n",
       " 'Q4380937': 58,\n",
       " 'Q571': 59,\n",
       " 'Q7361422': 60,\n",
       " 'Q532': 61,\n",
       " 'Q1232862': 62,\n",
       " 'Q7524793': 63,\n",
       " 'Q6958806': 64,\n",
       " 'Q668': 65,\n",
       " 'Q2919116': 66,\n",
       " 'Q1321': 67,\n",
       " 'Q15858907': 68,\n",
       " 'Q16521': 69,\n",
       " 'Q1395481': 70,\n",
       " 'Q185351': 71,\n",
       " 'Q5576500': 72,\n",
       " 'Q16707842': 73,\n",
       " 'Q1159017': 74,\n",
       " 'Q1018280': 75,\n",
       " 'Q239487': 76,\n",
       " 'Q157217': 77,\n",
       " 'Q525636': 78,\n",
       " 'Q6723': 79,\n",
       " 'Q6860925': 80,\n",
       " 'Q1550680': 81,\n",
       " 'Q1089794': 82,\n",
       " 'Q1303231': 83,\n",
       " 'Q3354797': 84,\n",
       " 'Q1336954': 85,\n",
       " 'Q188771': 86,\n",
       " 'Q138146': 87,\n",
       " 'Q13406463': 88,\n",
       " 'Q1283928': 89,\n",
       " 'Q18179743': 90,\n",
       " 'Q9004856': 91,\n",
       " 'Q4989906': 92,\n",
       " 'Q1348269': 93,\n",
       " 'Q71707': 94,\n",
       " 'Q192213': 95,\n",
       " 'Q2013767': 96,\n",
       " 'Q15409303': 97,\n",
       " 'Q1860': 98,\n",
       " 'Q15429093': 99,\n",
       " 'Q3337969': 100,\n",
       " 'Q1148233': 101,\n",
       " 'Q26702618': 102,\n",
       " 'Q898840': 103,\n",
       " 'Q450109': 104,\n",
       " 'Q5051616': 105,\n",
       " 'Q8502': 106,\n",
       " 'Q41036': 107,\n",
       " 'Q40494': 108,\n",
       " 'Q6138545': 109,\n",
       " 'Q1193195': 110,\n",
       " 'Q502348': 111,\n",
       " 'Q501766': 112,\n",
       " 'Q3540784': 113,\n",
       " 'Q561484': 114,\n",
       " 'Q6293413': 115,\n",
       " 'Q30': 116,\n",
       " 'Q6253945': 117,\n",
       " 'Q82955': 118,\n",
       " 'Q946028': 119,\n",
       " 'Q49210': 120,\n",
       " 'Q3842385': 121,\n",
       " 'Q942467': 122,\n",
       " 'Q2530270': 123,\n",
       " 'Q317358': 124,\n",
       " 'Q2469139': 125,\n",
       " 'Q134556': 126,\n",
       " 'Q16211553': 127,\n",
       " 'Q2736': 128,\n",
       " 'Q1086530': 129,\n",
       " 'Q1084472': 130,\n",
       " 'Q389885': 131,\n",
       " 'Q18508449': 132,\n",
       " 'Q18786781': 133,\n",
       " 'Q482994': 134,\n",
       " 'Q503612': 135,\n",
       " 'Q20': 136,\n",
       " 'Q2225262': 137,\n",
       " 'Q1115575': 138,\n",
       " 'Q1867': 139,\n",
       " 'Q1475': 140,\n",
       " 'Q2337923': 141,\n",
       " 'Q1089889': 142,\n",
       " 'Q7496862': 143,\n",
       " 'Q6828': 144,\n",
       " 'Q5403903': 145,\n",
       " 'Q7432': 146,\n",
       " 'Q5373767': 147,\n",
       " 'Q3787003': 148,\n",
       " 'Q282167': 149,\n",
       " 'Q7030495': 150,\n",
       " 'Q5950260': 151,\n",
       " 'Q2893939': 152,\n",
       " 'Q5250457': 153,\n",
       " 'Q4657759': 154,\n",
       " 'Q836726': 155,\n",
       " 'Q914416': 156,\n",
       " 'Q107761': 157,\n",
       " 'Q9402': 158,\n",
       " 'Q2347914': 159,\n",
       " 'Q5302484': 160,\n",
       " 'Q2081591': 161,\n",
       " 'Q118967': 162,\n",
       " 'Q2414363': 163,\n",
       " 'Q193592': 164,\n",
       " 'Q15854543': 165,\n",
       " 'Q644687': 166,\n",
       " 'Q18589259': 167,\n",
       " 'Q822146': 168,\n",
       " 'Q7412848': 169,\n",
       " 'Q483501': 170,\n",
       " 'Q7117336': 171,\n",
       " 'Q3511966': 172,\n",
       " 'Q7707': 173,\n",
       " 'Q1459518': 174,\n",
       " 'Q544823': 175,\n",
       " 'Q1898309': 176,\n",
       " 'Q962183': 177,\n",
       " 'Q8678': 178,\n",
       " 'Q601531': 179,\n",
       " 'Q1387896': 180,\n",
       " 'Q21621747': 181,\n",
       " 'Q167296': 182,\n",
       " 'Q375364': 183,\n",
       " 'Q22003852': 184,\n",
       " 'Q8418': 185,\n",
       " 'Q4738644': 186,\n",
       " 'Q6779': 187,\n",
       " 'Q719439': 188,\n",
       " 'Q5400204': 189,\n",
       " 'Q5324876': 190,\n",
       " 'Q180861': 191,\n",
       " 'Q879722': 192,\n",
       " 'Q34': 193,\n",
       " 'Q15979560': 194,\n",
       " 'Q202088': 195,\n",
       " 'Q362138': 196,\n",
       " 'Q37226': 197,\n",
       " 'Q16137876': 198,\n",
       " 'Q499451': 199,\n",
       " 'Q2904113': 200,\n",
       " 'Q6976517': 201,\n",
       " 'Q5300742': 202,\n",
       " 'Q168756': 203,\n",
       " 'Q950106': 204,\n",
       " 'Q1610017': 205,\n",
       " 'Q18712183': 206,\n",
       " 'Q1317816': 207,\n",
       " 'Q6305418': 208,\n",
       " 'Q5571558': 209,\n",
       " 'Q5236746': 210,\n",
       " 'Q362': 211,\n",
       " 'Q7253352': 212,\n",
       " 'Q36': 213,\n",
       " 'Q2203451': 214,\n",
       " 'Q1543268': 215,\n",
       " 'Q7155607': 216,\n",
       " 'Q1242655': 217,\n",
       " 'Q17015517': 218,\n",
       " 'Q214917': 219,\n",
       " 'Q7184217': 220,\n",
       " 'Q827311': 221,\n",
       " 'Q669675': 222,\n",
       " 'Q11424': 223,\n",
       " 'Q805507': 224,\n",
       " 'Q189912': 225,\n",
       " 'Q2937484': 226,\n",
       " 'Q196527': 227,\n",
       " 'Q1074243': 228,\n",
       " 'Q31': 229,\n",
       " 'Q609531': 230,\n",
       " 'Q2634': 231,\n",
       " 'Q5866798': 232,\n",
       " 'Q794': 233,\n",
       " 'Q14076596': 234,\n",
       " 'Q7026': 235,\n",
       " 'Q2791289': 236,\n",
       " 'Q8429': 237,\n",
       " 'Q19572955': 238,\n",
       " 'Q6984132': 239,\n",
       " 'Q165482': 240,\n",
       " 'Q11255': 241,\n",
       " 'Q207170': 242,\n",
       " 'Q2425753': 243,\n",
       " 'Q159': 244,\n",
       " 'Q268080': 245,\n",
       " 'Q16': 246,\n",
       " 'Q152824': 247,\n",
       " 'Q7292921': 248,\n",
       " 'Q937857': 249,\n",
       " 'Q60472': 250,\n",
       " 'Q4024': 251,\n",
       " 'Q439081': 252,\n",
       " 'Q329464': 253,\n",
       " 'Q6921756': 254,\n",
       " 'Q6263346': 255,\n",
       " 'Q22': 256,\n",
       " 'Q14620819': 257,\n",
       " 'Q17194517': 258,\n",
       " 'Q1097619': 259,\n",
       " 'Q6078563': 260,\n",
       " 'Q1507513': 261,\n",
       " 'Q4005797': 262,\n",
       " 'Q16820367': 263,\n",
       " 'Q3226510': 264,\n",
       " 'Q2848142': 265,\n",
       " 'Q2392956': 266,\n",
       " 'Q392': 267,\n",
       " 'Q4729826': 268,\n",
       " 'Q699757': 269,\n",
       " 'Q1126005': 270,\n",
       " 'Q378777': 271,\n",
       " 'Q7069882': 272,\n",
       " 'Q1871376': 273,\n",
       " 'Q220': 274,\n",
       " 'Q3003753': 275,\n",
       " 'Q8646': 276,\n",
       " 'Q1486459': 277,\n",
       " 'Q7301099': 278,\n",
       " 'Q840706': 279,\n",
       " 'Q2415633': 280,\n",
       " 'Q284085': 281,\n",
       " 'Q225': 282,\n",
       " 'Q5981317': 283,\n",
       " 'Q18336315': 284,\n",
       " 'Q4988217': 285,\n",
       " 'Q3245245': 286,\n",
       " 'Q7386146': 287,\n",
       " 'Q5618753': 288,\n",
       " 'Q5708194': 289,\n",
       " 'Q19309507': 290,\n",
       " 'Q183': 291,\n",
       " 'Q524530': 292,\n",
       " 'Q7960524': 293,\n",
       " 'Q39639': 294,\n",
       " 'Q13969584': 295,\n",
       " 'Q6829153': 296,\n",
       " 'Q153376': 297,\n",
       " 'Q6259081': 298,\n",
       " 'Q483949': 299,\n",
       " 'Q20934': 300,\n",
       " 'Q12154591': 301,\n",
       " 'Q188094': 302,\n",
       " 'Q4291469': 303,\n",
       " 'Q2268261': 304,\n",
       " 'Q468142': 305,\n",
       " 'Q145': 306,\n",
       " 'Q3266268': 307,\n",
       " 'Q86206': 308,\n",
       " 'Q8651': 309,\n",
       " 'Q830079': 310,\n",
       " 'Q4754830': 311,\n",
       " 'Q155': 312,\n",
       " 'Q664300': 313,\n",
       " 'Q268': 314,\n",
       " 'Q377384': 315,\n",
       " 'Q472331': 316,\n",
       " 'Q1346428': 317,\n",
       " 'Q41207': 318,\n",
       " 'Q383853': 319,\n",
       " 'Q486748': 320,\n",
       " 'Q5169767': 321,\n",
       " 'Q1076490': 322,\n",
       " 'Q219': 323,\n",
       " 'Q5860619': 324,\n",
       " 'Q960994': 325,\n",
       " 'Q838261': 326,\n",
       " 'Q7754035': 327,\n",
       " 'Q2975559': 328,\n",
       " 'Q2464000': 329,\n",
       " 'Q2052892': 330,\n",
       " 'Q11962231': 331,\n",
       " 'Q7456738': 332,\n",
       " 'Q2671219': 333,\n",
       " 'Q2589261': 334,\n",
       " 'Q315026': 335,\n",
       " 'Q5360339': 336,\n",
       " 'Q1158605': 337,\n",
       " 'Q13634387': 338,\n",
       " 'Q829665': 339,\n",
       " 'Q5821594': 340,\n",
       " 'Q7063266': 341,\n",
       " 'Q4396190': 342,\n",
       " 'Q366910': 343,\n",
       " 'Q15890282': 344,\n",
       " 'Q544478': 345,\n",
       " 'Q22252012': 346,\n",
       " 'Q18125001': 347,\n",
       " 'Q14847029': 348,\n",
       " 'Q3854758': 349,\n",
       " 'Q550493': 350,\n",
       " 'Q12022443': 351,\n",
       " 'Q1085': 352,\n",
       " 'Q3869062': 353,\n",
       " 'Q632006': 354,\n",
       " 'Q6701233': 355,\n",
       " 'Q2535659': 356,\n",
       " 'Q729640': 357,\n",
       " 'Q627398': 358,\n",
       " 'Q1346006': 359,\n",
       " 'Q1840277': 360,\n",
       " 'Q123705': 361,\n",
       " 'Q508319': 362,\n",
       " 'Q90': 363,\n",
       " 'Q6319368': 364,\n",
       " 'Q1633818': 365,\n",
       " 'Q105304': 366,\n",
       " 'Q1190630': 367,\n",
       " 'Q275934': 368,\n",
       " 'Q4678665': 369,\n",
       " 'Q896965': 370,\n",
       " 'Q503002': 371,\n",
       " 'Q82595': 372,\n",
       " 'Q890144': 373,\n",
       " 'Q3354498': 374,\n",
       " 'Q15040077': 375,\n",
       " 'Q466640': 376,\n",
       " 'Q527695': 377,\n",
       " 'Q1130487': 378,\n",
       " 'Q5538958': 379,\n",
       " 'Q2961059': 380,\n",
       " 'Q2915465': 381,\n",
       " 'Q1497061': 382,\n",
       " 'Q905043': 383,\n",
       " 'Q41871': 384,\n",
       " 'Q6125332': 385,\n",
       " 'Q585': 386,\n",
       " 'Q75186': 387,\n",
       " 'Q49750': 388,\n",
       " 'Q2608990': 389,\n",
       " 'Q657865': 390,\n",
       " 'Q6146821': 391,\n",
       " 'Q3809587': 392,\n",
       " 'Q20998385': 393,\n",
       " 'Q101352': 394,\n",
       " 'Q28124218': 395,\n",
       " 'Q3711': 396,\n",
       " 'Q25104700': 397,\n",
       " 'Q5456': 398,\n",
       " 'Q1119958': 399,\n",
       " 'Q6289176': 400,\n",
       " 'Q7976115': 401,\n",
       " 'Q981537': 402,\n",
       " 'Q16965292': 403,\n",
       " 'Q29': 404,\n",
       " 'Q6209389': 405,\n",
       " 'Q18729': 406,\n",
       " 'Q1363730': 407,\n",
       " 'Q274894': 408,\n",
       " 'Q4723017': 409,\n",
       " 'Q6183351': 410,\n",
       " 'Q753110': 411,\n",
       " 'Q8053291': 412,\n",
       " 'Q128390': 413,\n",
       " 'Q16892132': 414,\n",
       " 'Q8884557': 415,\n",
       " 'Q503027': 416,\n",
       " 'Q64395': 417,\n",
       " 'Q2018484': 418,\n",
       " 'Q6962668': 419,\n",
       " 'Q299772': 420,\n",
       " 'Q38': 421,\n",
       " 'Q5222160': 422,\n",
       " 'Q5223067': 423,\n",
       " 'Q498922': 424,\n",
       " 'Q913438': 425,\n",
       " 'Q60542': 426,\n",
       " 'Q12215498': 427,\n",
       " 'Q40357': 428,\n",
       " 'Q7456459': 429,\n",
       " 'Q1391': 430,\n",
       " 'Q1237249': 431,\n",
       " 'Q865291': 432,\n",
       " 'Q4577566': 433,\n",
       " 'Q847768': 434,\n",
       " 'Q7356189': 435,\n",
       " 'Q162602': 436,\n",
       " 'Q1140723': 437,\n",
       " 'Q831375': 438,\n",
       " 'Q3414209': 439,\n",
       " 'Q486972': 440,\n",
       " 'Q205772': 441,\n",
       " 'Q36180': 442,\n",
       " 'Q1377825': 443,\n",
       " 'Q1003845': 444,\n",
       " 'Q463397': 445,\n",
       " 'Q7781285': 446,\n",
       " 'Q1153898': 447,\n",
       " 'Q1726351': 448,\n",
       " 'Q215582': 449,\n",
       " 'Q152554': 450,\n",
       " 'Q4449171': 451,\n",
       " 'Q6533600': 452,\n",
       " 'Q5109865': 453,\n",
       " 'Q7414948': 454,\n",
       " 'Q2554047': 455,\n",
       " 'Q749': 456,\n",
       " 'Q16193217': 457,\n",
       " 'Q1241954': 458,\n",
       " 'Q4604235': 459,\n",
       " 'Q542': 460,\n",
       " 'Q25983111': 461,\n",
       " 'Q17244811': 462,\n",
       " 'Q273922': 463,\n",
       " 'Q183551': 464,\n",
       " 'Q6506693': 465,\n",
       " 'Q142': 466,\n",
       " 'Q3568093': 467,\n",
       " 'Q956509': 468,\n",
       " 'Q1035067': 469,\n",
       " 'Q321288': 470,\n",
       " 'Q20487071': 471,\n",
       " 'Q700980': 472,\n",
       " 'Q438350': 473,\n",
       " 'Q4804575': 474,\n",
       " 'Q494511': 475,\n",
       " 'Q608472': 476,\n",
       " 'Q5994': 477,\n",
       " 'Q19865982': 478,\n",
       " 'Q577981': 479,\n",
       " 'Q7539602': 480,\n",
       " 'Q169930': 481,\n",
       " 'Q19578386': 482,\n",
       " 'Q7889850': 483,\n",
       " 'Q3272873': 484,\n",
       " 'Q150': 485,\n",
       " 'Q5756465': 486,\n",
       " 'Q148': 487,\n",
       " 'Q478463': 488,\n",
       " 'Q8261': 489,\n",
       " 'Q553673': 490,\n",
       " 'Q8150': 491,\n",
       " 'Q401092': 492,\n",
       " 'Q2481452': 493,\n",
       " 'Q1912256': 494,\n",
       " 'Q16231318': 495,\n",
       " 'Q18328013': 496,\n",
       " 'Q730417': 497,\n",
       " 'Q44897': 498,\n",
       " 'Q1343683': 499,\n",
       " 'Q809218': 500,\n",
       " 'Q803': 501,\n",
       " 'Q557740': 502,\n",
       " 'Q58960': 503,\n",
       " 'Q671284': 504,\n",
       " 'Q2876': 505,\n",
       " 'Q7911948': 506,\n",
       " 'Q7107051': 507,\n",
       " 'Q17364595': 508,\n",
       " 'Q970677': 509,\n",
       " 'Q443850': 510,\n",
       " 'Q60': 511,\n",
       " 'Q4695410': 512,\n",
       " 'Q5228776': 513,\n",
       " 'Q16275316': 514,\n",
       " 'Q1032793': 515,\n",
       " 'Q1781': 516,\n",
       " 'Q1432838': 517,\n",
       " 'Q1072269': 518,\n",
       " 'Q4748823': 519,\n",
       " 'Q7366': 520,\n",
       " 'Q1277833': 521,\n",
       " 'Q43812': 522,\n",
       " 'Q511290': 523,\n",
       " 'Q8072869': 524,\n",
       " 'Q206748': 525,\n",
       " 'Q8006493': 526,\n",
       " 'Q25000393': 527,\n",
       " 'Q262799': 528,\n",
       " 'Q45776': 529,\n",
       " 'Q6626764': 530,\n",
       " 'Q587090': 531,\n",
       " 'Q650760': 532,\n",
       " 'Q1096827': 533,\n",
       " 'Q1649': 534,\n",
       " 'Q2296293': 535,\n",
       " 'Q26704465': 536,\n",
       " 'Q280658': 537,\n",
       " 'Q4797410': 538,\n",
       " 'Q900': 539,\n",
       " 'Q2440121': 540,\n",
       " 'Q217': 541,\n",
       " 'Q17068382': 542,\n",
       " 'Q2968385': 543,\n",
       " 'Q23413': 544,\n",
       " 'Q333630': 545,\n",
       " 'Q270532': 546,\n",
       " 'Q5677427': 547,\n",
       " 'Q484188': 548,\n",
       " 'Q16142774': 549,\n",
       " 'Q59853': 550,\n",
       " 'Q7095129': 551,\n",
       " 'Q7680437': 552,\n",
       " 'Q362322': 553,\n",
       " 'Q688790': 554,\n",
       " 'Q584545': 555,\n",
       " 'Q14832327': 556,\n",
       " 'Q4039294': 557,\n",
       " 'Q19896190': 558,\n",
       " 'Q1443220': 559,\n",
       " 'Q19864059': 560,\n",
       " 'Q674327': 561,\n",
       " 'Q8068965': 562,\n",
       " 'Q7889': 563,\n",
       " 'Q1825227': 564,\n",
       " 'Q128196': 565,\n",
       " 'Q1637200': 566,\n",
       " 'Q734944': 567,\n",
       " 'Q6157471': 568,\n",
       " 'Q164234': 569,\n",
       " 'Q6844984': 570,\n",
       " 'Q1021': 571,\n",
       " 'Q5189545': 572,\n",
       " 'Q5032881': 573,\n",
       " 'Q12820': 574,\n",
       " 'Q272066': 575,\n",
       " 'Q6365985': 576,\n",
       " 'Q1137838': 577,\n",
       " 'Q6828134': 578,\n",
       " 'Q43123660': 579,\n",
       " 'Q5435990': 580,\n",
       " 'Q4620692': 581,\n",
       " 'Q1210267': 582,\n",
       " 'Q3301122': 583,\n",
       " 'Q74664': 584,\n",
       " 'Q571627': 585,\n",
       " 'Q2611956': 586,\n",
       " 'Q1325591': 587,\n",
       " 'Q7867304': 588,\n",
       " 'Q11220': 589,\n",
       " 'Q8065446': 590,\n",
       " 'Q2439926': 591,\n",
       " 'Q1232881': 592,\n",
       " 'Q17167': 593,\n",
       " 'Q713945': 594,\n",
       " 'Q738236': 595,\n",
       " 'Q3066855': 596,\n",
       " 'Q1361809': 597,\n",
       " 'Q801': 598,\n",
       " 'Q2213368': 599,\n",
       " 'Q2839402': 600,\n",
       " 'Q196086': 601,\n",
       " 'Q3265983': 602,\n",
       " 'Q2415066': 603,\n",
       " 'Q7283228': 604,\n",
       " 'Q11141211': 605,\n",
       " 'Q55488': 606,\n",
       " 'Q4901871': 607,\n",
       " 'Q5432': 608,\n",
       " 'Q616120': 609,\n",
       " 'Q872136': 610,\n",
       " 'Q3499808': 611,\n",
       " 'Q3922520': 612,\n",
       " 'Q7587141': 613,\n",
       " 'Q1336842': 614,\n",
       " 'Q194393': 615,\n",
       " 'Q830747': 616,\n",
       " 'Q980': 617,\n",
       " 'Q4712576': 618,\n",
       " 'Q16735696': 619,\n",
       " 'Q575289': 620,\n",
       " 'Q10559': 621,\n",
       " 'Q1855688': 622,\n",
       " 'Q2993299': 623,\n",
       " 'Q65943': 624,\n",
       " 'Q15072865': 625,\n",
       " 'Q43380': 626,\n",
       " 'Q1306393': 627,\n",
       " 'Q8015989': 628,\n",
       " 'Q388824': 629,\n",
       " 'Q3377': 630,\n",
       " 'Q7606349': 631,\n",
       " 'Q49122': 632,\n",
       " 'Q19745949': 633,\n",
       " 'Q4076760': 634,\n",
       " 'Q18940': 635,\n",
       " 'Q185029': 636,\n",
       " 'Q393422': 637,\n",
       " 'Q10429346': 638,\n",
       " 'Q1990864': 639,\n",
       " 'Q1949405': 640,\n",
       " 'Q20983938': 641,\n",
       " 'Q654283': 642,\n",
       " 'Q16893498': 643,\n",
       " 'Q6484670': 644,\n",
       " 'Q20090316': 645,\n",
       " 'Q15930574': 646,\n",
       " 'Q4799975': 647,\n",
       " 'Q123885': 648,\n",
       " 'Q2364547': 649,\n",
       " 'Q12344159': 650,\n",
       " 'Q18685581': 651,\n",
       " 'Q4565695': 652,\n",
       " 'Q27020041': 653,\n",
       " 'Q3301685': 654,\n",
       " 'Q694005': 655,\n",
       " 'Q6477257': 656,\n",
       " 'Q483110': 657,\n",
       " 'Q14689164': 658,\n",
       " 'Q5540111': 659,\n",
       " 'Q4435872': 660,\n",
       " 'Q3201194': 661,\n",
       " 'Q33999': 662,\n",
       " 'Q6832418': 663,\n",
       " 'Q4927524': 664,\n",
       " 'Q1413538': 665,\n",
       " 'Q847': 666,\n",
       " 'Q2736801': 667,\n",
       " 'Q597': 668,\n",
       " 'Q4597847': 669,\n",
       " 'Q2696963': 670,\n",
       " 'Q2148686': 671,\n",
       " 'Q2512868': 672,\n",
       " 'Q5829385': 673,\n",
       " 'Q5923562': 674,\n",
       " 'Q1230741': 675,\n",
       " 'Q5073400': 676,\n",
       " 'Q16555': 677,\n",
       " 'Q1027723': 678,\n",
       " 'Q7619726': 679,\n",
       " 'Q43229': 680,\n",
       " 'Q5023872': 681,\n",
       " 'Q26703643': 682,\n",
       " 'Q1051862': 683,\n",
       " 'Q4994308': 684,\n",
       " 'Q2899998': 685,\n",
       " 'Q169889': 686,\n",
       " 'Q1627206': 687,\n",
       " 'Q1933451': 688,\n",
       " 'Q1092552': 689,\n",
       " 'Q11998': 690,\n",
       " 'Q6154151': 691,\n",
       " 'Q28911': 692,\n",
       " 'Q100190': 693,\n",
       " 'Q48': 694,\n",
       " 'Q17423797': 695,\n",
       " 'Q84': 696,\n",
       " 'Q15894010': 697,\n",
       " 'Q3534173': 698,\n",
       " 'Q437832': 699,\n",
       " 'Q2958359': 700,\n",
       " 'Q8038986': 701,\n",
       " 'Q1333406': 702,\n",
       " 'Q140': 703,\n",
       " 'Q8870888': 704,\n",
       " 'Q59503': 705,\n",
       " 'Q3308285': 706,\n",
       " 'Q82594': 707,\n",
       " 'Q4786242': 708,\n",
       " 'Q222595': 709,\n",
       " 'Q690359': 710,\n",
       " 'Q131681': 711,\n",
       " 'Q4861869': 712,\n",
       " 'Q6424432': 713,\n",
       " 'Q835577': 714,\n",
       " 'Q168886': 715,\n",
       " 'Q7083212': 716,\n",
       " 'Q5437300': 717,\n",
       " 'Q2706666': 718,\n",
       " 'Q7972343': 719,\n",
       " 'Q1921652': 720,\n",
       " 'Q2727598': 721,\n",
       " 'Q8015390': 722,\n",
       " 'Q2944360': 723,\n",
       " 'Q7736576': 724,\n",
       " 'Q7613882': 725,\n",
       " 'Q5078790': 726,\n",
       " 'Q761534': 727,\n",
       " 'Q1114742': 728,\n",
       " 'Q270794': 729,\n",
       " 'Q470725': 730,\n",
       " 'Q134241': 731,\n",
       " 'Q16255727': 732,\n",
       " 'Q27673457': 733,\n",
       " 'Q8420': 734,\n",
       " 'Q6778466': 735,\n",
       " 'Q9826': 736,\n",
       " 'Q6755782': 737,\n",
       " 'Q58900': 738,\n",
       " 'Q777699': 739,\n",
       " 'Q6596679': 740,\n",
       " 'Q1983062': 741,\n",
       " 'Q7292151': 742,\n",
       " 'Q510487': 743,\n",
       " 'Q6074716': 744,\n",
       " 'Q824': 745,\n",
       " 'Q7447538': 746,\n",
       " 'Q5701982': 747,\n",
       " 'Q13376892': 748,\n",
       " 'Q246593': 749,\n",
       " 'Q8789': 750,\n",
       " 'Q7978222': 751,\n",
       " 'Q2378843': 752,\n",
       " 'Q4635515': 753,\n",
       " 'Q11223': 754,\n",
       " 'Q1134750': 755,\n",
       " 'Q364444': 756,\n",
       " 'Q7985890': 757,\n",
       " 'Q1094226': 758,\n",
       " 'Q536894': 759,\n",
       " 'Q13473501': 760,\n",
       " 'Q1353414': 761,\n",
       " 'Q755745': 762,\n",
       " 'Q418529': 763,\n",
       " 'Q11173': 764,\n",
       " 'Q3138959': 765,\n",
       " 'Q17': 766,\n",
       " 'Q41817': 767,\n",
       " 'Q484170': 768,\n",
       " 'Q5735392': 769,\n",
       " 'Q371522': 770,\n",
       " 'Q5444191': 771,\n",
       " 'Q9301693': 772,\n",
       " 'Q6769613': 773,\n",
       " 'Q213439': 774,\n",
       " 'Q2279587': 775,\n",
       " 'Q208850': 776,\n",
       " 'Q10018973': 777,\n",
       " 'Q215980': 778,\n",
       " 'Q7767225': 779,\n",
       " 'Q1549708': 780,\n",
       " 'Q4682151': 781,\n",
       " 'Q4022': 782,\n",
       " 'Q1143792': 783,\n",
       " 'Q12538': 784,\n",
       " 'Q16200717': 785,\n",
       " 'Q3785750': 786,\n",
       " 'Q6600444': 787,\n",
       " 'Q1023635': 788,\n",
       " 'Q1021315': 789,\n",
       " 'Q5038104': 790,\n",
       " 'Q215380': 791,\n",
       " 'Q770747': 792,\n",
       " 'Q1161694': 793,\n",
       " 'Q159987': 794,\n",
       " 'Q131329': 795,\n",
       " 'Q317933': 796,\n",
       " 'Q462132': 797,\n",
       " 'Q905035': 798,\n",
       " 'Q1140565': 799,\n",
       " 'Q5664210': 800,\n",
       " 'Q5486209': 801,\n",
       " 'Q1802239': 802,\n",
       " 'Q3184121': 803,\n",
       " 'Q660579': 804,\n",
       " 'Q65347': 805,\n",
       " 'Q2589831': 806,\n",
       " 'Q41417': 807,\n",
       " 'Q5824274': 808,\n",
       " 'Q1368577': 809,\n",
       " 'Q258': 810,\n",
       " 'Q3572984': 811,\n",
       " 'Q494753': 812,\n",
       " 'Q171558': 813,\n",
       " 'Q17016243': 814,\n",
       " 'Q7251429': 815,\n",
       " 'Q15962459': 816,\n",
       " 'Q804541': 817,\n",
       " 'Q6051696': 818,\n",
       " 'Q218506': 819,\n",
       " 'Q338372': 820,\n",
       " 'Q184644': 821,\n",
       " 'Q17984452': 822,\n",
       " 'Q736917': 823,\n",
       " 'Q16105300': 824,\n",
       " 'Q183412': 825,\n",
       " 'Q3880070': 826,\n",
       " 'Q7175721': 827,\n",
       " 'Q20306926': 828,\n",
       " 'Q414': 829,\n",
       " 'Q535367': 830,\n",
       " 'Q215122': 831,\n",
       " 'Q1930187': 832,\n",
       " 'Q1061359': 833,\n",
       " 'Q589114': 834,\n",
       " 'Q3419499': 835,\n",
       " 'Q3808': 836,\n",
       " 'Q6911987': 837,\n",
       " 'Q16885836': 838,\n",
       " 'Q278835': 839,\n",
       " 'Q16866302': 840,\n",
       " 'Q4792927': 841,\n",
       " 'Q247212': 842,\n",
       " 'Q16767079': 843,\n",
       " 'Q3762801': 844,\n",
       " 'Q6152698': 845,\n",
       " 'Q1682564': 846,\n",
       " 'Q27983368': 847,\n",
       " 'Q336286': 848,\n",
       " 'Q555268': 849,\n",
       " 'Q2373919': 850,\n",
       " 'Q973289': 851,\n",
       " 'Q152499': 852,\n",
       " 'Q5233298': 853,\n",
       " 'Q6270871': 854,\n",
       " 'Q570989': 855,\n",
       " 'Q3840451': 856,\n",
       " 'Q1474848': 857,\n",
       " 'Q5184107': 858,\n",
       " 'Q197743': 859,\n",
       " 'Q1040761': 860,\n",
       " 'Q13378': 861,\n",
       " 'Q52073': 862,\n",
       " 'Q27805386': 863,\n",
       " 'Q189': 864,\n",
       " 'Q5943937': 865,\n",
       " 'Q7692360': 866,\n",
       " 'Q5240434': 867,\n",
       " 'Q1321880': 868,\n",
       " 'Q1187416': 869,\n",
       " 'Q18154853': 870,\n",
       " 'Q6765984': 871,\n",
       " 'Q7932073': 872,\n",
       " 'Q3157174': 873,\n",
       " 'Q2874472': 874,\n",
       " 'Q19599833': 875,\n",
       " 'Q355201': 876,\n",
       " 'Q349055': 877,\n",
       " 'Q192827': 878,\n",
       " 'Q6655': 879,\n",
       " 'Q16887005': 880,\n",
       " 'Q200350': 881,\n",
       " 'Q640674': 882,\n",
       " 'Q5283863': 883,\n",
       " 'Q11399': 884,\n",
       " 'Q7166118': 885,\n",
       " 'Q3914': 886,\n",
       " 'Q7954095': 887,\n",
       " 'Q222910': 888,\n",
       " 'Q537660': 889,\n",
       " 'Q1725366': 890,\n",
       " 'Q535066': 891,\n",
       " 'Q5538086': 892,\n",
       " 'Q2542741': 893,\n",
       " 'Q3163215': 894,\n",
       " 'Q4026918': 895,\n",
       " 'Q36186': 896,\n",
       " 'Q3188994': 897,\n",
       " 'Q2487961': 898,\n",
       " 'Q7925509': 899,\n",
       " 'Q5760075': 900,\n",
       " 'Q5681306': 901,\n",
       " 'Q7977056': 902,\n",
       " 'Q5009281': 903,\n",
       " 'Q985860': 904,\n",
       " 'Q2811627': 905,\n",
       " 'Q17050527': 906,\n",
       " 'Q819425': 907,\n",
       " 'Q152011': 908,\n",
       " 'Q94081': 909,\n",
       " 'Q924592': 910,\n",
       " 'Q11394': 911,\n",
       " 'Q3119567': 912,\n",
       " 'Q5141539': 913,\n",
       " 'Q973223': 914,\n",
       " 'Q165862': 915,\n",
       " 'Q7158890': 916,\n",
       " 'Q7158889': 917,\n",
       " 'Q18637789': 918,\n",
       " 'Q1489': 919,\n",
       " 'Q4035807': 920,\n",
       " 'Q4316217': 921,\n",
       " 'Q4611470': 922,\n",
       " 'Q6384752': 923,\n",
       " 'Q1159033': 924,\n",
       " 'Q4753721': 925,\n",
       " 'Q814067': 926,\n",
       " 'Q469925': 927,\n",
       " 'Q1478723': 928,\n",
       " 'Q677055': 929,\n",
       " 'Q1016746': 930,\n",
       " 'Q428565': 931,\n",
       " 'Q594796': 932,\n",
       " 'Q2799576': 933,\n",
       " 'Q1971967': 934,\n",
       " 'Q1670154': 935,\n",
       " 'Q2008567': 936,\n",
       " 'Q2653658': 937,\n",
       " 'Q5994377': 938,\n",
       " 'Q1878830': 939,\n",
       " 'Q6382716': 940,\n",
       " 'Q6574': 941,\n",
       " 'Q3750182': 942,\n",
       " 'Q5269302': 943,\n",
       " 'Q36834': 944,\n",
       " 'Q5000873': 945,\n",
       " 'Q3947': 946,\n",
       " 'Q3667051': 947,\n",
       " 'Q134386': 948,\n",
       " 'Q244467': 949,\n",
       " 'Q71476': 950,\n",
       " 'Q4710870': 951,\n",
       " 'Q6870609': 952,\n",
       " 'Q35497': 953,\n",
       " 'Q6657897': 954,\n",
       " 'Q209939': 955,\n",
       " 'Q6846725': 956,\n",
       " 'Q766904': 957,\n",
       " 'Q309945': 958,\n",
       " 'Q535457': 959,\n",
       " 'Q520299': 960,\n",
       " 'Q816607': 961,\n",
       " 'Q904530': 962,\n",
       " 'Q7356623': 963,\n",
       " 'Q1075339': 964,\n",
       " 'Q7865175': 965,\n",
       " 'Q7397': 966,\n",
       " 'Q2738660': 967,\n",
       " 'Q2400673': 968,\n",
       " 'Q7087378': 969,\n",
       " 'Q3282637': 970,\n",
       " 'Q17465765': 971,\n",
       " 'Q177342': 972,\n",
       " 'Q629': 973,\n",
       " 'Q9262085': 974,\n",
       " 'Q228': 975,\n",
       " 'Q2046571': 976,\n",
       " 'Q47064': 977,\n",
       " 'Q2880615': 978,\n",
       " 'Q4946360': 979,\n",
       " 'Q285829': 980,\n",
       " 'Q57719': 981,\n",
       " 'Q7146629': 982,\n",
       " 'Q84773': 983,\n",
       " 'Q680690': 984,\n",
       " 'Q19631156': 985,\n",
       " 'Q5318515': 986,\n",
       " 'Q20963489': 987,\n",
       " 'Q495366': 988,\n",
       " 'Q3827918': 989,\n",
       " 'Q5637013': 990,\n",
       " 'Q15462': 991,\n",
       " 'Q6678919': 992,\n",
       " 'Q252038': 993,\n",
       " 'Q1627390': 994,\n",
       " 'Q980620': 995,\n",
       " 'Q3047936': 996,\n",
       " 'Q193391': 997,\n",
       " 'Q4974339': 998,\n",
       " 'Q203005': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(entity_embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "ENTITY_2_ID_FILE = '../data/wikidata5m_inductive/uri_to_id.json'\n",
    "with open(ENTITY_2_ID_FILE) as uri_to_id_in:\n",
    "    uri_to_id = json.load(uri_to_id_in)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "x = torch.zeros((len(uri_to_id.keys()), 512))\n",
    "our_entities = set(uri_to_id.keys())\n",
    "for e in entity2id.keys():\n",
    "    if e in our_entities:\n",
    "        x[uri_to_id[e]] = torch.tensor(entity_embeddings[entity2id[e]])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(x, f'../data/wikidata5m_inductive/distmult_pretrained.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
