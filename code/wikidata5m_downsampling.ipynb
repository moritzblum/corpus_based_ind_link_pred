{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "\n",
    "ENTITY_FEATURES_FILE = '../data/wikidata5m_inductive/entity_description_first_sentence_embedding.pt'\n",
    "ENTITY_2_ID_FILE = '../data/wikidata5m_inductive/uri_to_id.json'\n",
    "RELATION_2_ID_FILE = '../data/wikidata5m_inductive/relation_uri_to_id.json'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "with open(ENTITY_2_ID_FILE) as uri_to_id_in:\n",
    "    uri_to_id = json.load(uri_to_id_in)\n",
    "\n",
    "with open(RELATION_2_ID_FILE) as uri_to_id_in:\n",
    "    relation_uri_to_id = json.load(uri_to_id_in)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "all_uris = list(uri_to_id.keys())\n",
    "random.shuffle(all_uris)\n",
    "sampled_uris = set(all_uris[:500000])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "for sample in ['train', 'valid', 'test']:\n",
    "    sampled_triples = []\n",
    "    with open(f'../data/wikidata5m_inductive/wikidata5m_inductive_{sample}.txt') as triples_in:\n",
    "            for line in triples_in:\n",
    "                head, relation, tail = line[:-1].split('\\t')\n",
    "                if head in sampled_uris and tail in sampled_uris:\n",
    "                    sampled_triples.append([head, relation, tail])\n",
    "\n",
    "    with open(f'../data/wikidata5m_inductive/wikidata5m_inductive_exp_{sample}.txt', 'w') as triples_out:\n",
    "        for triple in sampled_triples:\n",
    "            triples_out.write('\\t'.join(triple) + '\\n')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def read_lp_data(file_path, uri_to_id, relation_uri_to_id, data_sample):\n",
    "    print('Preprocessing:', data_sample)\n",
    "\n",
    "    edge_index = []\n",
    "    edge_type = []\n",
    "    with open(file_path) as triples_in:\n",
    "        for line in triples_in:\n",
    "            head, relation, tail = line[:-1].split('\\t')\n",
    "            edge_index.append([uri_to_id[head], uri_to_id[tail]])\n",
    "            edge_type.append(relation_uri_to_id[relation])\n",
    "\n",
    "    return Data(edge_index=torch.tensor(edge_index).t(),\n",
    "                edge_type=torch.tensor(edge_type))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
